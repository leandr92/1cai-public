# üìä Monitoring & Observability Guide

**Complete guide to monitoring 1C AI Stack**

---

## üéØ Overview

Monitoring stack –≤–∫–ª—é—á–∞–µ—Ç:
- **Prometheus** - –º–µ—Ç—Ä–∏–∫–∏
- **Grafana** - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- **ELK Stack** - –ª–æ–≥–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- **Health checks** - –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è

---

## üöÄ Quick Start

### –ó–∞–ø—É—Å–∫ monitoring stack:

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å Prometheus + Grafana
docker-compose -f docker-compose.monitoring.yml up -d

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å
docker ps | grep -E "prometheus|grafana"
```

**–î–æ—Å—Ç—É–ø:**
- **Prometheus:** http://localhost:9090
- **Grafana:** http://localhost:3000 (admin/admin)

---

## üìà Prometheus Setup

### Configuration

```yaml
# monitoring/prometheus/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: '1c-ai-api'
    static_configs:
      - targets: ['host.docker.internal:8000']
  
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
  
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
```

### Key Metrics

**Application metrics:**
```promql
# Request rate
rate(http_requests_total[5m])

# Response time
histogram_quantile(0.95, http_request_duration_seconds)

# Error rate
rate(http_requests_total{status=~"5.."}[5m])
```

**Database metrics:**
```promql
# PostgreSQL connections
pg_stat_database_numbackends

# Query time
rate(pg_stat_statements_total_time[5m])

# Redis memory
redis_memory_used_bytes
```

---

## üìä Grafana Dashboards

### Pre-configured Dashboards

1. **System Overview** - –æ–±—â–∏–π –æ–±–∑–æ—Ä —Å–∏—Å—Ç–µ–º—ã
   - Request rate, response time
   - Error rate, uptime
   - Resource usage (CPU, RAM)

2. **AI Agents Performance**
   - Agent utilization
   - Response times –ø–æ –∞–≥–µ–Ω—Ç–∞–º
   - Success rates

3. **Database Performance**
   - Connections, queries/sec
   - Query latency
   - Cache hit rates

4. **Telegram Bot**
   - Active users
   - Messages processed
   - Response times

### Accessing Dashboards

```bash
# 1. –û—Ç–∫—Ä—ã—Ç—å Grafana
open http://localhost:3000

# 2. Login: admin / admin
# 3. Dashboards ‚Üí Browse
# 4. –í—ã–±—Ä–∞—Ç—å dashboard
```

### Creating Custom Dashboard

```bash
# 1. Grafana UI: Create ‚Üí Dashboard
# 2. Add Panel
# 3. Query: –≤—ã–±–µ—Ä–∏—Ç–µ Prometheus
# 4. Metric: –Ω–∞—á–Ω–∏—Ç–µ –≤–≤–æ–¥–∏—Ç—å (autocomplete)
```

---

## üè• Health Checks

### Application Health

```bash
# FastAPI
curl http://localhost:8000/health

# Response:
{
  "status": "healthy",
  "version": "5.1.0",
  "uptime": 3600,
  "checks": {
    "database": "ok",
    "redis": "ok",
    "ai_services": "ok"
  }
}
```

### Database Health

```bash
# PostgreSQL
docker exec 1c-ai-postgres pg_isready
# postgres is accepting connections

# Redis
docker exec 1c-ai-redis redis-cli PING
# PONG

# Neo4j
curl http://localhost:7474/db/neo4j/tx/commit
```

---

## üìù Logging

### Log Levels

```bash
# .env
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT=json # json –∏–ª–∏ text
```

### Viewing Logs

```bash
# Docker logs
docker-compose logs -f api

# –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–µ—Ä–≤–∏—Å
docker-compose logs telegram-bot --tail=100

# –í—Å–µ –ª–æ–≥–∏
docker-compose logs --tail=1000 > all_logs.txt
```

### Log Aggregation

**Structured Logging (JSON):**
```json
{
  "timestamp": "2025-11-06T12:00:00Z",
  "level": "INFO",
  "service": "telegram-bot",
  "message": "Message processed",
  "user_id": 123456,
  "duration_ms": 234
}
```

**ELK Stack (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):**
```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å ELK
docker-compose -f docker-compose.monitoring.yml \
  --profile elk up -d

# Kibana: http://localhost:5601
```

---

## üîî Alerting

### Prometheus Alerts

```yaml
# monitoring/prometheus/alerts/system_alerts.yml
groups:
  - name: 1c-ai-alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        annotations:
          summary: "High error rate detected"
      
      - alert: DatabaseDown
        expr: up{job="postgres"} == 0
        for: 1m
        annotations:
          summary: "PostgreSQL is down"
```

### Alertmanager

```yaml
# monitoring/alertmanager/alertmanager.yml
receivers:
  - name: 'telegram'
    telegram_configs:
      - bot_token: 'your_bot_token'
        chat_id: your_chat_id
```

---

## üìâ Performance Monitoring

### Key Performance Indicators (KPIs)

```yaml
Availability: >99.5%
Response Time (p95): <2s
Error Rate: <0.1%
Cache Hit Rate: >70%
```

### Tracking in Grafana

**SLA Dashboard:**
- Uptime (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π)
- Average response time
- Error rate trend
- SLA compliance (%)

**Queries:**
```promql
# Uptime
avg_over_time(up{job="1c-ai-api"}[30d])

# P95 response time
histogram_quantile(0.95,
  rate(http_request_duration_seconds_bucket[5m])
)
```

---

## üîç Debugging with Metrics

### Slow Requests

```promql
# –ù–∞–π—Ç–∏ –º–µ–¥–ª–µ–Ω–Ω—ã–µ endpoints
topk(10, 
  histogram_quantile(0.95,
    rate(http_request_duration_seconds_bucket[5m])
  )
) by (endpoint)
```

### High Memory Usage

```promql
# Memory usage trend
container_memory_usage_bytes{name="1c-ai-api"}

# Alert if >80%
container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.8
```

### Database Issues

```promql
# Long-running queries
pg_stat_activity_max_tx_duration > 30

# Connection pool saturation
pg_stat_database_numbackends / pg_settings_max_connections > 0.8
```

---

## üì± Application Metrics

### Custom Metrics (Python)

```python
from prometheus_client import Counter, Histogram

# Counter example
telegram_messages = Counter(
    'telegram_messages_total',
    'Total Telegram messages',
    ['user_type']  # labels
)

# Usage
telegram_messages.labels(user_type='premium').inc()

# Histogram example
request_duration = Histogram(
    'request_duration_seconds',
    'Request duration'
)

# Usage
with request_duration.time():
    process_request()
```

### Exposing Metrics

```python
# src/main.py
from prometheus_client import make_asgi_app

# Mount metrics endpoint
metrics_app = make_asgi_app()
app.mount("/metrics", metrics_app)
```

**Access:** http://localhost:8000/metrics

---

## üéØ Monitoring Scenarios

### Scenario 1: System is slow

**Check:**
```promql
# 1. Response time spike?
rate(http_request_duration_seconds_sum[5m])

# 2. Database slow?
rate(pg_stat_statements_total_time[5m])

# 3. Memory issues?
container_memory_usage_bytes

# 4. CPU throttling?
rate(container_cpu_usage_seconds_total[5m])
```

---

### Scenario 2: Errors increasing

**Check:**
```promql
# 1. Which endpoint?
topk(5, rate(http_requests_total{status="500"}[5m])) by (endpoint)

# 2. Which service?
rate(http_requests_total{status="500"}[5m]) by (service)

# 3. Error types
logs search: level:ERROR | last 1h
```

---

### Scenario 3: High load

**Check:**
```promql
# 1. Request spike?
rate(http_requests_total[5m])

# 2. Legitimate traffic?
rate(http_requests_total[5m]) by (user_agent)

# 3. DDoS?
rate(http_requests_total[1m]) > 1000
```

---

## üîó Integration with External Services

### Sentry (Error Tracking)

```bash
# .env
SENTRY_DSN=https://key@sentry.io/project

# Python
import sentry_sdk
sentry_sdk.init(dsn=os.getenv("SENTRY_DSN"))
```

### DataDog (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

```bash
# .env
DATADOG_API_KEY=your_datadog_key

# Agent
docker run -d --name datadog \
  -e DD_API_KEY=$DATADOG_API_KEY \
  -e DD_SITE="datadoghq.com" \
  datadog/agent:latest
```

---

## üìö Dashboard Gallery

### Screenshots –∏ –ø—Ä–∏–º–µ—Ä—ã:

–°–º. [monitoring/grafana/dashboards/](../monitoring/grafana/dashboards/)

- `overview.json` - ??? (–Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å)
- `system_overview.json` - –≥–ª–∞–≤–Ω—ã–π dashboard
- `business_metrics.json` - –±–∏–∑–Ω–µ—Å –º–µ—Ç—Ä–∏–∫–∏
- `celery_monitoring.json` - –æ—á–µ—Ä–µ–¥–∏ –∑–∞–¥–∞—á
- `system_monitoring.json` - –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã

### System Overview

–î–∞—à–±–æ—Ä–¥ `system_overview.json` —Å–ª—É–∂–∏—Ç –±—ã—Å—Ç—Ä—ã–º health-check‚Äô–æ–º –ø–ª–æ—â–∞–¥–∫–∏:

- **Request Rate / Success Rate** ‚Äî `http_requests_total` c —Ç–µ–º–ø–ª–µ–π—Ç–∞–º–∏ `$job`, `$endpoint` –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º clamping –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å.
- **HTTP latency p95 / 5xx rate** ‚Äî `histogram_quantile` –ø–æ `http_request_duration_seconds_bucket` –∏ `rate` –¥–ª—è –æ—à–∏–±–æ–∫.
- **Active Users / Tenants** ‚Äî Gauge `active_users`, `active_tenants{status="active"}`.
- **AI Queries / Latency** ‚Äî `ai_queries_total`, `ai_response_duration_seconds_bucket` –ø–æ —Ñ–∏–ª—å—Ç—Ä—É `$agent`.
- **Cache hit % / DB pool** ‚Äî —Ä–∞—Å—á—ë—Ç –Ω–∞ –±–∞–∑–µ `cache_operations_total`, `db_pool_size`, `db_pool_available_connections`.
- **System CPU usage** ‚Äî Gauge `system_cpu_usage_percent` –æ—Ç –∞–≥–µ–Ω—Ç–∞.

–¢–µ–º–ø–ª–µ–π—Ç—ã `$datasource`, `$job`, `$endpoint`, `$agent`, `$cache_layer` –ø–æ–∑–≤–æ–ª—è—é—Ç –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å —Å–µ—Ä–≤–∏—Å—ã –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –±–µ–∑ –ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤.

### Business & Adoption Metrics

`business_metrics.json` –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ AI:

- **Active Users / Tenants** ‚Äî Gauge `active_users` –∏ `active_tenants{status="active"}` —Å —Ü–≤–µ—Ç–æ–≤—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏.
- **Tenants by Status / Projects by Status** ‚Äî piechart —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º `active_tenants` –∏ `projects_total` –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º.
- **AI Queries / Tokens** ‚Äî –º–µ—Ç—Ä–∏–∫–∏ `ai_queries_total`, `ai_tokens_used_total` —á–µ—Ä–µ–∑ `rate`/`increase` –∏ —Ñ–∏–ª—å—Ç—Ä `$agent`.
- **Code Reviews / Tests Generated** ‚Äî `code_reviews_total`, `tests_generated_total` —Å –≤—ã–±–æ—Ä–æ–º `$language`.
- **Projects** ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å—Ç–∞—Ç-–ø–∞–Ω–µ–ª–∏ `projects_total{status="active"|"review"}`.

–¢–µ–º–ø–ª–µ–π—Ç—ã `$datasource`, `$agent`, `$language` –ø–æ–∑–≤–æ–ª—è—é—Ç –±—ã—Å—Ç—Ä–æ –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å —Å—Ä–µ–∑—ã. –î–∞—à–±–æ—Ä–¥ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω –Ω–∞ –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–µ —Å—á—ë—Ç—á–∏–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º `increase()`/`rate()`), –ø–æ—ç—Ç–æ–º—É –≤–∞–∂–µ–Ω —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π retention –≤ Prometheus.

### System Monitoring

`system_monitoring.json` –æ–±–Ω–æ–≤–ª—ë–Ω –ø–æ–¥ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ Prometheus –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –∞–≥–µ–Ω—Ç–∞:

- **–ê–∫—Ç–∏–≤–Ω—ã–µ —Ç–∞—Ä–≥–µ—Ç—ã / –ê–ª–µ—Ä—Ç—ã** ‚Äî –±—ã—Å—Ç—Ä—ã–µ —Å—Ç–∞—Ç-–ø–∞–Ω–µ–ª–∏ –ø–æ `up{}` –∏ `ALERTS{alertstate="firing"}`.
- **–°—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–æ–≤** ‚Äî —Ç–∞–±–ª–∏—Ü–∞ —Å —Ü–≤–µ—Ç–æ–≤—ã–º –º–∞–ø–ø–∏–Ω–≥–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è `instance` –∏ `job` (—Ñ–∏–ª—å—Ç—Ä—ã —á–µ—Ä–µ–∑ —Ç–µ–º–ø–ª–µ–π—Ç—ã).
- **–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞** ‚Äî CPU, RAM, –¥–∏—Å–∫–∏ c `node_exporter`, –ø–ª—é—Å –æ—Ç–¥–µ–ª—å–Ω–∞—è –ª–∏–Ω–∏—è `system_cpu_usage_percent` –∏–∑ –Ω–∞—à–µ–≥–æ –∞–≥–µ–Ω—Ç–∞.
- **HTTP & —Å–µ—Ä–≤–∏—Å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏** ‚Äî `http_requests_total`, `http_request_duration_seconds_bucket` —Å p95/p50 –∏ –æ—Ç–¥–µ–ª—å–Ω–∞—è —Å–µ—Ä–∏—è –¥–ª—è 5xx.
- **–¢–µ–º–ø–ª–µ–π—Ç—ã**: `$datasource`, `$instance`, `$job`, `$endpoint` ‚Äî –ø–æ–º–æ–≥–∞—é—Ç —Å—É–∑–∏—Ç—å –≤—ã–±–æ—Ä–∫—É –±–µ–∑ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤.

–í–∞–∂–Ω–æ: –¥–∞—à–±–æ—Ä–¥ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –Ω–∞–ª–∏—á–∏–µ Node Exporter –∏ –≤–∫–ª—é—á—ë–Ω–Ω–æ–≥–æ `/metrics` —Å–µ—Ä–≤–∏—Å–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è. –ï—Å–ª–∏ —á–∞—Å—Ç—å —Ç–∞—Ä–≥–µ—Ç–æ–≤ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, —É–±–µ–¥–∏—Ç–µ—Å—å –≤ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ scrape-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π.

### Celery Tasks Monitoring

Dashboard `celery_monitoring.json` —Ç–µ–ø–µ—Ä—å –ø—Ä–∏–≤—è–∑–∞–Ω –∫ –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º `celery-exporter` –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –≥–æ—Ç–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ –æ—á–µ—Ä–µ–¥—è–º –∏ –∑–∞–¥–∞—á–∞–º. –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞–Ω–µ–ª–∏:

- **Active Workers** ‚Äî `sum(celery_workers)`, —Ü–≤–µ—Ç–æ–≤—ã–µ –ø–æ—Ä–æ–≥–∏ –ø–æ–º–æ–≥–∞—é—Ç –∑–∞–º–µ—Ç–∏—Ç—å –ø–æ—Ç–µ—Ä—é –≤–æ—Ä–∫–µ—Ä–æ–≤.
- **Tasks Received/Failed (5m)** ‚Äî –ø—Ä–∏—Ä–æ—Å—Ç —Å—á—ë—Ç—á–∏–∫–æ–≤ `celery_tasks_total` –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º `received` –∏ `failed` –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –º–∏–Ω—É—Ç.
- **Success Rate %** ‚Äî –æ—Ç–Ω–æ—à–µ–Ω–∏–µ `succeeded` –∫ `received` —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å (`clamp_min`).
- **Task Throughput / Duration p95** ‚Äî –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–∏ `histogram_quantile` –ø–æ –ª–µ–π–±–ª—É `name` (—Ñ–∏–ª—å—Ç—Ä `$task`).
- **Queue Length** ‚Äî `sum by (queue) (celery_queue_length)` —Å —Ñ–∏–ª—å—Ç—Ä–æ–º `$queue`.
- **Worker Availability** ‚Äî `max_over_time(up{job=~"celery.*"}[5m])`, –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ç–∞—Ä–≥–µ—Ç–æ–≤ –≤ Prometheus.
- **Failures & Retries per minute** ‚Äî —Å–∫–æ—Ä–æ—Å—Ç—å –æ—à–∏–±–æ–∫/–ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤ –¥–ª—è –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—è.
- **Top Failed Tasks / Queue Share (6h)** ‚Äî —Ç–∞–±–ª–∏—Ü–∞ –∏ –∫—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –ø–æ `increase(...[6h])` –¥–ª—è —Ä–µ—Ç—Ä–æ—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.

–¢–µ–º–ø–ª–µ–π—Ç—ã `$queue`