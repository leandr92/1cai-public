# ü§ñ ML Dataset Generator

> **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—É—á–∞—é—â–∏—Ö dataset –¥–ª—è fine-tuning –º–æ–¥–µ–ª–µ–π –Ω–∞ –∫–æ–¥–µ 1–°**

---

## üéØ –ß—Ç–æ —ç—Ç–æ —Ç–∞–∫–æ–µ?

**ML Dataset Generator** ‚Äî —ç—Ç–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ–±—É—á–∞—é—â–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞ 1–°:Enterprise –¥–ª—è fine-tuning —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π.

### –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:

- üìä **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è** - 7 —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á
- üîç **–û–±–æ–≥–∞—â–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º** - –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, –ø–∞—Ç—Ç–µ—Ä–Ω—ã
- üìà **–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è** - —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π –∫–æ–¥
- üíæ **–ú–Ω–æ–∂–µ—Å—Ç–≤–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤** - JSON, JSONL, CSV, Parquet
- üéì **–ì–æ—Ç–æ–≤ –∫ –æ–±—É—á–µ–Ω–∏—é** - —Å–æ–≤–º–µ—Å—Ç–∏–º —Å OpenAI, HuggingFace, LoRA

### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:

```
–°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤:        24,000+
–ö–∞—Ç–µ–≥–æ—Ä–∏–π –∫–æ–¥–∞:          7
–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä:          ~250 —Ç–æ–∫–µ–Ω–æ–≤
–ö–∞—á–µ—Å—Ç–≤–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:     95%+
```

---

## üöÄ Quick Start

### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

–°–Ω–∞—á–∞–ª–∞ –Ω—É–∂–Ω–æ —Å–ø–∞—Ä—Å–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é EDT:

```bash
# –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
python scripts/parsers/edt/edt_parser_with_metadata.py \
    --source /path/to/configuration \
    --output output/edt_parser/ \
    --include-code \
    --extract-dependencies
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** `output/edt_parser/full_parse_with_metadata.json`

### 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è dataset

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ ML dataset
python scripts/dataset/create_ml_dataset.py \
    --input output/edt_parser/full_parse_with_metadata.json \
    --output output/ml_dataset/
```

### 3. –†–µ–∑—É–ª—å—Ç–∞—Ç

```
output/ml_dataset/
‚îú‚îÄ‚îÄ training_dataset.jsonl        # –û—Å–Ω–æ–≤–Ω–æ–π dataset (JSONL)
‚îú‚îÄ‚îÄ training_dataset.json         # JSON —Ñ–æ—Ä–º–∞—Ç
‚îú‚îÄ‚îÄ dataset_statistics.json       # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ dataset
‚îî‚îÄ‚îÄ category_examples.json        # –ü—Ä–∏–º–µ—Ä—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
```

---

## üìä –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫–æ–¥–∞ (7 —Ç–∏–ø–æ–≤)

Dataset –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ—Ç –∫–æ–¥ –Ω–∞ 7 —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á:

### 1. **–ó–∞–ø—Ä–æ—Å—ã –∫ –¥–∞–Ω–Ω—ã–º (Query)**

–§—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏, –≤—ã–±–æ—Ä–∫–∞–º–∏, –∞–≥—Ä–µ–≥–∞—Ü–∏–µ–π:

```bsl
–§—É–Ω–∫—Ü–∏—è –ü–æ–ª—É—á–∏—Ç—å–û—Å—Ç–∞—Ç–∫–∏–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã(–î–∞—Ç–∞, –°–∫–ª–∞–¥)
    –ó–∞–ø—Ä–æ—Å = –ù–æ–≤—ã–π –ó–∞–ø—Ä–æ—Å;
    –ó–∞–ø—Ä–æ—Å.–¢–µ–∫—Å—Ç = "
        |–í–´–ë–†–ê–¢–¨
        |    –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞,
        |    –°–£–ú(–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ) –ö–ê–ö –û—Å—Ç–∞—Ç–æ–∫
        |–ò–ó –†–µ–≥–∏—Å—Ç—Ä–ù–∞–∫–æ–ø–ª–µ–Ω–∏—è.–û—Å—Ç–∞—Ç–∫–∏–¢–æ–≤–∞—Ä–æ–≤.–û—Å—Ç–∞—Ç–∫–∏(&–î–∞—Ç–∞, –°–∫–ª–∞–¥ = &–°–∫–ª–∞–¥)
        |–°–ì–†–£–ü–ü–ò–†–û–í–ê–¢–¨ –ü–û –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞";
    –ó–∞–ø—Ä–æ—Å.–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å–ü–∞—Ä–∞–º–µ—Ç—Ä("–î–∞—Ç–∞", –î–∞—Ç–∞);
    –ó–∞–ø—Ä–æ—Å.–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å–ü–∞—Ä–∞–º–µ—Ç—Ä("–°–∫–ª–∞–¥", –°–∫–ª–∞–¥);
    –í–æ–∑–≤—Ä–∞—Ç –ó–∞–ø—Ä–æ—Å.–í—ã–ø–æ–ª–Ω–∏—Ç—å().–í—ã–≥—Ä—É–∑–∏—Ç—å();
–ö–æ–Ω–µ—Ü–§—É–Ω–∫—Ü–∏–∏
```

### 2. **–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (Document Processing)**

–†–∞–±–æ—Ç–∞ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ - –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ, –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ, –ø—Ä–æ–≤–µ—Ä–∫–∏:

```bsl
–ü—Ä–æ—Ü–µ–¥—É—Ä–∞ –û–±—Ä–∞–±–æ—Ç–∫–∞–ü—Ä–æ–≤–µ–¥–µ–Ω–∏—è(–û—Ç–∫–∞–∑, –†–µ–∂–∏–º–ü—Ä–æ–≤–µ–¥–µ–Ω–∏—è)
    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
    –ï—Å–ª–∏ –ù–ï –ó–Ω–∞—á–µ–Ω–∏–µ–ó–∞–ø–æ–ª–Ω–µ–Ω–æ(–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç) –¢–æ–≥–¥–∞
        –û—Ç–∫–∞–∑ = –ò—Å—Ç–∏–Ω–∞;
        –°–æ–æ–±—â–∏—Ç—å("–ù–µ —É–∫–∞–∑–∞–Ω –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç");
        –í–æ–∑–≤—Ä–∞—Ç;
    –ö–æ–Ω–µ—Ü–ï—Å–ª–∏;
    
    // –î–≤–∏–∂–µ–Ω–∏—è –ø–æ —Ä–µ–≥–∏—Å—Ç—Ä–∞–º
    –î–≤–∏–∂–µ–Ω–∏—è.–í–∑–∞–∏–º–æ—Ä–∞—Å—á–µ—Ç—ã–°–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞–º–∏.–ó–∞–ø–∏—Å—ã–≤–∞—Ç—å = –ò—Å—Ç–∏–Ω–∞;
    –î–ª—è –ö–∞–∂–¥–æ–≥–æ –°—Ç—Ä–æ–∫–∞–¢–ß –ò–∑ –¢–æ–≤–∞—Ä—ã –¶–∏–∫–ª
        –î–≤–∏–∂–µ–Ω–∏–µ = –î–≤–∏–∂–µ–Ω–∏—è.–í–∑–∞–∏–º–æ—Ä–∞—Å—á–µ—Ç—ã–°–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞–º–∏.–î–æ–±–∞–≤–∏—Ç—å();
        –î–≤–∏–∂–µ–Ω–∏–µ.–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç = –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç;
        –î–≤–∏–∂–µ–Ω–∏–µ.–°—É–º–º–∞ = –°—Ç—Ä–æ–∫–∞–¢–ß.–°—É–º–º–∞;
    –ö–æ–Ω–µ—Ü–¶–∏–∫–ª–∞;
–ö–æ–Ω–µ—Ü–ü—Ä–æ—Ü–µ–¥—É—Ä—ã
```

### 3. **–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ (Validation)**

–§—É–Ω–∫—Ü–∏–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –≤–∞–ª–∏–¥–∞—Ü–∏–∏:

```bsl
–§—É–Ω–∫—Ü–∏—è –ü—Ä–æ–≤–µ—Ä–∏—Ç—å–ò–ù–ù(–ò–ù–ù) –≠–∫—Å–ø–æ—Ä—Ç
    –ï—Å–ª–∏ –°—Ç—Ä–î–ª–∏–Ω–∞(–ò–ù–ù) <> 10 –ò –°—Ç—Ä–î–ª–∏–Ω–∞(–ò–ù–ù) <> 12 –¢–æ–≥–¥–∞
        –í–æ–∑–≤—Ä–∞—Ç –õ–æ–∂—å;
    –ö–æ–Ω–µ—Ü–ï—Å–ª–∏;
    
    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Å—É–º–º
    –ï—Å–ª–∏ –°—Ç—Ä–î–ª–∏–Ω–∞(–ò–ù–ù) = 10 –¢–æ–≥–¥–∞
        –í–æ–∑–≤—Ä–∞—Ç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é–°—É–º–º—É–ò–ù–ù10(–ò–ù–ù);
    –ò–Ω–∞—á–µ
        –í–æ–∑–≤—Ä–∞—Ç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é–°—É–º–º—É–ò–ù–ù12(–ò–ù–ù);
    –ö–æ–Ω–µ—Ü–ï—Å–ª–∏;
–ö–æ–Ω–µ—Ü–§—É–Ω–∫—Ü–∏–∏
```

### 4. **–†–∞–±–æ—Ç–∞ —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞–º–∏ (Reference Processing)**

CRUD –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞–º–∏:

```bsl
–§—É–Ω–∫—Ü–∏—è –°–æ–∑–¥–∞—Ç—å–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—É(–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ, –ê—Ä—Ç–∏–∫—É–ª, –ï–¥–∏–Ω–∏—Ü–∞–ò–∑–º–µ—Ä–µ–Ω–∏—è)
    –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞–û–±—ä–µ–∫—Ç = –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏.–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞.–°–æ–∑–¥–∞—Ç—å–≠–ª–µ–º–µ–Ω—Ç();
    –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞–û–±—ä–µ–∫—Ç.–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ = –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ;
    –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞–û–±—ä–µ–∫—Ç.–ê—Ä—Ç–∏–∫—É–ª = –ê—Ä—Ç–∏–∫—É–ª;
    –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞–û–±—ä–µ–∫—Ç.–ë–∞–∑–æ–≤–∞—è–ï–¥–∏–Ω–∏—Ü–∞–ò–∑–º–µ—Ä–µ–Ω–∏—è = –ï–¥–∏–Ω–∏—Ü–∞–ò–∑–º–µ—Ä–µ–Ω–∏—è;
    
    –ü–æ–ø—ã—Ç–∫–∞
        –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞–û–±—ä–µ–∫—Ç.–ó–∞–ø–∏—Å–∞—Ç—å();
        –í–æ–∑–≤—Ä–∞—Ç –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞–û–±—ä–µ–∫—Ç.–°—Å—ã–ª–∫–∞;
    –ò—Å–∫–ª—é—á–µ–Ω–∏–µ
        –°–æ–æ–±—â–∏—Ç—å(–û–ø–∏—Å–∞–Ω–∏–µ–û—à–∏–±–∫–∏());
        –í–æ–∑–≤—Ä–∞—Ç –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ;
    –ö–æ–Ω–µ—Ü–ü–æ–ø—ã—Ç–∫–∏;
–ö–æ–Ω–µ—Ü–§—É–Ω–∫—Ü–∏–∏
```

### 5. **–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (Data Transformation)**

–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –∞–≥—Ä–µ–≥–∞—Ü–∏—è, –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞:

```bsl
–§—É–Ω–∫—Ü–∏—è –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å–¢–∞–±–ª–∏—Ü—É–í–î–µ—Ä–µ–≤–æ(–¢–∞–±–ª–∏—Ü–∞–ó–Ω–∞—á–µ–Ω–∏–π)
    –î–µ—Ä–µ–≤–æ–ó–Ω–∞—á–µ–Ω–∏–π = –ù–æ–≤—ã–π –î–µ—Ä–µ–≤–æ–ó–Ω–∞—á–µ–Ω–∏–π;
    –î–µ—Ä–µ–≤–æ–ó–Ω–∞—á–µ–Ω–∏–π.–ö–æ–ª–æ–Ω–∫–∏.–î–æ–±–∞–≤–∏—Ç—å("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ");
    –î–µ—Ä–µ–≤–æ–ó–Ω–∞—á–µ–Ω–∏–π.–ö–æ–ª–æ–Ω–∫–∏.–î–æ–±–∞–≤–∏—Ç—å("–ó–Ω–∞—á–µ–Ω–∏–µ");
    
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ = –ù–æ–≤—ã–π –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ;
    
    –î–ª—è –ö–∞–∂–¥–æ–≥–æ –°—Ç—Ä–æ–∫–∞ –ò–∑ –¢–∞–±–ª–∏—Ü–∞–ó–Ω–∞—á–µ–Ω–∏–π –¶–∏–∫–ª
        –†–æ–¥–∏—Ç–µ–ª—å = –°—Ç—Ä—É–∫—Ç—É—Ä–∞–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏[–°—Ç—Ä–æ–∫–∞.–ì—Ä—É–ø–ø–∞];
        –ï—Å–ª–∏ –†–æ–¥–∏—Ç–µ–ª—å = –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –¢–æ–≥–¥–∞
            –†–æ–¥–∏—Ç–µ–ª—å = –î–µ—Ä–µ–≤–æ–ó–Ω–∞—á–µ–Ω–∏–π.–°—Ç—Ä–æ–∫–∏.–î–æ–±–∞–≤–∏—Ç—å();
            –†–æ–¥–∏—Ç–µ–ª—å.–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ = –°—Ç—Ä–æ–∫–∞.–ì—Ä—É–ø–ø–∞;
            –°—Ç—Ä—É–∫—Ç—É—Ä–∞–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏.–í—Å—Ç–∞–≤–∏—Ç—å(–°—Ç—Ä–æ–∫–∞.–ì—Ä—É–ø–ø–∞, –†–æ–¥–∏—Ç–µ–ª—å);
        –ö–æ–Ω–µ—Ü–ï—Å–ª–∏;
        
        –î–æ—á–µ—Ä–Ω–∏–π–≠–ª–µ–º–µ–Ω—Ç = –†–æ–¥–∏—Ç–µ–ª—å.–°—Ç—Ä–æ–∫–∏.–î–æ–±–∞–≤–∏—Ç—å();
        –î–æ—á–µ—Ä–Ω–∏–π–≠–ª–µ–º–µ–Ω—Ç.–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ = –°—Ç—Ä–æ–∫–∞.–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ;
        –î–æ—á–µ—Ä–Ω–∏–π–≠–ª–µ–º–µ–Ω—Ç.–ó–Ω–∞—á–µ–Ω–∏–µ = –°—Ç—Ä–æ–∫–∞.–ó–Ω–∞—á–µ–Ω–∏–µ;
    –ö–æ–Ω–µ—Ü–¶–∏–∫–ª–∞;
    
    –í–æ–∑–≤—Ä–∞—Ç –î–µ—Ä–µ–≤–æ–ó–Ω–∞—á–µ–Ω–∏–π;
–ö–æ–Ω–µ—Ü–§—É–Ω–∫—Ü–∏–∏
```

### 6. **–†–∞—Å—á–µ—Ç—ã –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã (Calculation)**

–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—á–µ—Ç—ã, –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞:

```bsl
–§—É–Ω–∫—Ü–∏—è –†–∞—Å—Å—á–∏—Ç–∞—Ç—å–ù–î–°(–°—É–º–º–∞, –°—Ç–∞–≤–∫–∞–ù–î–°)
    –ï—Å–ª–∏ –°—Ç–∞–≤–∫–∞–ù–î–° = –ü–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è.–°—Ç–∞–≤–∫–∏–ù–î–°.–ù–î–°20 –¢–æ–≥–¥–∞
        –í–æ–∑–≤—Ä–∞—Ç –û–∫—Ä(–°—É–º–º–∞ * 0.20, 2);
    –ò–Ω–∞—á–µ–ï—Å–ª–∏ –°—Ç–∞–≤–∫–∞–ù–î–° = –ü–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è.–°—Ç–∞–≤–∫–∏–ù–î–°.–ù–î–°10 –¢–æ–≥–¥–∞
        –í–æ–∑–≤—Ä–∞—Ç –û–∫—Ä(–°—É–º–º–∞ * 0.10, 2);
    –ò–Ω–∞—á–µ
        –í–æ–∑–≤—Ä–∞—Ç 0;
    –ö–æ–Ω–µ—Ü–ï—Å–ª–∏;
–ö–æ–Ω–µ—Ü–§—É–Ω–∫—Ü–∏–∏

–§—É–Ω–∫—Ü–∏—è –†–∞—Å—Å—á–∏—Ç–∞—Ç—å–°–∫–∏–¥–∫—É(–°—É–º–º–∞, –ü—Ä–æ—Ü–µ–Ω—Ç–°–∫–∏–¥–∫–∏)
    –°—É–º–º–∞–°–∫–∏–¥–∫–∏ = –û–∫—Ä(–°—É–º–º–∞ * –ü—Ä–æ—Ü–µ–Ω—Ç–°–∫–∏–¥–∫–∏ / 100, 2);
    –í–æ–∑–≤—Ä–∞—Ç –°—É–º–º–∞ - –°—É–º–º–∞–°–∫–∏–¥–∫–∏;
–ö–æ–Ω–µ—Ü–§—É–Ω–∫—Ü–∏–∏
```

### 7. **–†–∞–±–æ—Ç–∞ —Å —Ñ–æ—Ä–º–∞–º–∏ (Form Processing)**

–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–±—ã—Ç–∏–π —Ñ–æ—Ä–º, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º:

```bsl
&–ù–∞–ö–ª–∏–µ–Ω—Ç–µ
–ü—Ä–æ—Ü–µ–¥—É—Ä–∞ –ü—Ä–∏–û—Ç–∫—Ä—ã—Ç–∏–∏(–û—Ç–∫–∞–∑)
    –û–±–Ω–æ–≤–∏—Ç—å–°–ø–∏—Å–æ–∫–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã();
    –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å–≠–ª–µ–º–µ–Ω—Ç–æ–≤();
–ö–æ–Ω–µ—Ü–ü—Ä–æ—Ü–µ–¥—É—Ä—ã

&–ù–∞–°–µ—Ä–≤–µ—Ä–µ
–ü—Ä–æ—Ü–µ–¥—É—Ä–∞ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å–≠–ª–µ–º–µ–Ω—Ç–æ–≤()
    –≠–ª–µ–º–µ–Ω—Ç—ã.–¢–æ–≤–∞—Ä—ã–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ.–¢–æ–ª—å–∫–æ–ü—Ä–æ—Å–º–æ—Ç—Ä = –ù–ï –†–∞–∑—Ä–µ—à–µ–Ω–æ–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ;
    –≠–ª–µ–º–µ–Ω—Ç—ã.–¢–æ–≤–∞—Ä—ã–¶–µ–Ω–∞.–í–∏–¥–∏–º–æ—Å—Ç—å = –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å–¶–µ–Ω—ã;
–ö–æ–Ω–µ—Ü–ü—Ä–æ—Ü–µ–¥—É—Ä—ã
```

---

## üìñ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ë–∞–∑–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è

```bash
python scripts/dataset/create_ml_dataset.py \
    --input output/edt_parser/full_parse_with_metadata.json \
    --output output/ml_dataset/
```

### –° —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π

```bash
# –¢–æ–ª—å–∫–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
python scripts/dataset/create_ml_dataset.py \
    --input output/edt_parser/full_parse_with_metadata.json \
    --output output/ml_dataset/ \
    --categories Query,Calculation,Validation

# –° —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
python scripts/dataset/create_ml_dataset.py \
    --input output/edt_parser/full_parse_with_metadata.json \
    --output output/ml_dataset/ \
    --min-tokens 50 \
    --max-tokens 500

# –° —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
python scripts/dataset/create_ml_dataset.py \
    --input output/edt_parser/full_parse_with_metadata.json \
    --output output/ml_dataset/ \
    --min-quality-score 0.8
```

### Python API

```python
from scripts.dataset.create_ml_dataset import MLDatasetGenerator

# –°–æ–∑–¥–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
generator = MLDatasetGenerator(
    input_path="output/edt_parser/full_parse_with_metadata.json",
    output_path="output/ml_dataset/",
    options={
        'categories': ['Query', 'Document Processing', 'Validation'],
        'min_tokens': 50,
        'max_tokens': 500,
        'min_quality_score': 0.8,
        'include_context': True,
        'deduplicate': True
    }
)

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è dataset
stats = generator.generate()

print(f"–°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {stats['total_examples']}")
print(f"–ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: {stats['by_category']}")
```

---

## üìä –§–æ—Ä–º–∞—Ç dataset

### JSONL (–¥–ª—è –æ–±—É—á–µ–Ω–∏—è)

```jsonl
{"prompt": "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Å—Ç–∞—Ç–∫–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å–∫–ª–∞–¥–µ", "completion": "–§—É–Ω–∫—Ü–∏—è –ü–æ–ª—É—á–∏—Ç—å–û—Å—Ç–∞—Ç–∫–∏(–°–∫–ª–∞–¥)\n    –ó–∞–ø—Ä–æ—Å = –ù–æ–≤—ã–π –ó–∞–ø—Ä–æ—Å;\n    ...\n–ö–æ–Ω–µ—Ü–§—É–Ω–∫—Ü–∏–∏", "category": "Query", "metadata": {"complexity": 5, "lines": 15}}
{"prompt": "–°–æ–∑–¥–∞–π –ø—Ä–æ—Ü–µ–¥—É—Ä—É –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏", "completion": "–ü—Ä–æ—Ü–µ–¥—É—Ä–∞ –û–±—Ä–∞–±–æ—Ç–∫–∞–ü—Ä–æ–≤–µ–¥–µ–Ω–∏—è(–û—Ç–∫–∞–∑)\n    ...\n–ö–æ–Ω–µ—Ü–ü—Ä–æ—Ü–µ–¥—É—Ä—ã", "category": "Document Processing", "metadata": {"complexity": 8, "lines": 45}}
```

### JSON (–¥–µ—Ç–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)

```json
{
  "examples": [
    {
      "id": "example_001",
      "category": "Query",
      "prompt": "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Å—Ç–∞—Ç–∫–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å–∫–ª–∞–¥–µ –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—é –Ω–∞ –¥–∞—Ç—É",
      "completion": "–§—É–Ω–∫—Ü–∏—è –ü–æ–ª—É—á–∏—Ç—å–û—Å—Ç–∞—Ç–∫–∏–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã(–î–∞—Ç–∞, –°–∫–ª–∞–¥)\n    –ó–∞–ø—Ä–æ—Å = –ù–æ–≤—ã–π –ó–∞–ø—Ä–æ—Å;\n    –ó–∞–ø—Ä–æ—Å.–¢–µ–∫—Å—Ç = \"\n        |–í–´–ë–†–ê–¢–¨\n        |    –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞,\n        |    –°–£–ú(–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ) –ö–ê–ö –û—Å—Ç–∞—Ç–æ–∫\n        |–ò–ó –†–µ–≥–∏—Å—Ç—Ä–ù–∞–∫–æ–ø–ª–µ–Ω–∏—è.–û—Å—Ç–∞—Ç–∫–∏–¢–æ–≤–∞—Ä–æ–≤.–û—Å—Ç–∞—Ç–∫–∏(&–î–∞—Ç–∞, –°–∫–ª–∞–¥ = &–°–∫–ª–∞–¥)\n        |–°–ì–†–£–ü–ü–ò–†–û–í–ê–¢–¨ –ü–û –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞\";\n    –ó–∞–ø—Ä–æ—Å.–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å–ü–∞—Ä–∞–º–µ—Ç—Ä(\"–î–∞—Ç–∞\", –î–∞—Ç–∞);\n    –ó–∞–ø—Ä–æ—Å.–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å–ü–∞—Ä–∞–º–µ—Ç—Ä(\"–°–∫–ª–∞–¥\", –°–∫–ª–∞–¥);\n    –í–æ–∑–≤—Ä–∞—Ç –ó–∞–ø—Ä–æ—Å.–í—ã–ø–æ–ª–Ω–∏—Ç—å().–í—ã–≥—Ä—É–∑–∏—Ç—å();\n–ö–æ–Ω–µ—Ü–§—É–Ω–∫—Ü–∏–∏",
      "metadata": {
        "source_object": "CommonModule.–†–∞–±–æ—Ç–∞–°–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–æ–π",
        "function_name": "–ü–æ–ª—É—á–∏—Ç—å–û—Å—Ç–∞—Ç–∫–∏–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã",
        "complexity": 5,
        "lines_of_code": 12,
        "api_calls": ["–ó–∞–ø—Ä–æ—Å", "–†–µ–≥–∏—Å—Ç—Ä–ù–∞–∫–æ–ø–ª–µ–Ω–∏—è"],
        "parameters": ["–î–∞—Ç–∞", "–°–∫–ª–∞–¥"],
        "return_type": "–¢–∞–±–ª–∏—Ü–∞–ó–Ω–∞—á–µ–Ω–∏–π"
      },
      "context": {
        "object_type": "CommonModule",
        "module_purpose": "–†–∞–±–æ—Ç–∞ —Å –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–æ–π –∏ –æ—Å—Ç–∞—Ç–∫–∞–º–∏",
        "related_objects": ["–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏.–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞", "–†–µ–≥–∏—Å—Ç—Ä–ù–∞–∫–æ–ø–ª–µ–Ω–∏—è.–û—Å—Ç–∞—Ç–∫–∏–¢–æ–≤–∞—Ä–æ–≤"]
      },
      "quality_score": 0.95,
      "tokens": 247
    }
  ],
  "metadata": {
    "total_examples": 24156,
    "generation_date": "2025-11-06T23:59:59",
    "source_configuration": "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ–º v3.0",
    "categories": {
      "Query": 4820,
      "Document Processing": 5240,
      "Validation": 3100,
      "Reference Processing": 2890,
      "Data Transformation": 3640,
      "Calculation": 2466,
      "Form Processing": 2000
    }
  }
}
```

---

## üéì –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

### OpenAI Fine-tuning

```bash
# 1. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ OpenAI —Ñ–æ—Ä–º–∞—Ç
python scripts/dataset/convert_to_openai.py \
    --input output/ml_dataset/training_dataset.jsonl \
    --output output/ml_dataset/openai_format.jsonl

# 2. –ó–∞–≥—Ä—É–∑–∫–∞ –≤ OpenAI
openai api fine_tunes.create \
    -t output/ml_dataset/openai_format.jsonl \
    -m davinci \
    --suffix "1c-bsl-code"
```

### HuggingFace

```python
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments

# –ó–∞–≥—Ä—É–∑–∫–∞ dataset
dataset = load_dataset('json', data_files='output/ml_dataset/training_dataset.jsonl')

# –ú–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
model_name = "microsoft/CodeGPT-small-py"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
def tokenize_function(examples):
    return tokenizer(
        examples["prompt"] + " " + examples["completion"],
        truncation=True,
        max_length=512
    )

tokenized_dataset = dataset.map(tokenize_function, batched=True)

# –û–±—É—á–µ–Ω–∏–µ
training_args = TrainingArguments(
    output_dir="./models/1c-bsl-finetuned",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    save_steps=1000,
    save_total_limit=2,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
)

trainer.train()
```

### LoRA Fine-tuning

```python
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from trl import SFTTrainer

# –ú–æ–¥–µ–ª—å
model_name = "Qwen/Qwen2.5-Coder-7B"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    load_in_8bit=True,
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ–±—É—á–µ–Ω–∏—é
model = prepare_model_for_kbit_training(model)

# LoRA –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

model = get_peft_model(model, lora_config)

# –ó–∞–≥—Ä—É–∑–∫–∞ dataset
dataset = load_dataset('json', data_files='output/ml_dataset/training_dataset.jsonl')

# –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
trainer = SFTTrainer(
    model=model,
    train_dataset=dataset["train"],
    dataset_text_field="completion",
    max_seq_length=512,
    tokenizer=tokenizer,
    args=TrainingArguments(
        output_dir="./models/1c-lora",
        num_train_epochs=3,
        per_device_train_batch_size=4,
        gradient_accumulation_steps=4,
        learning_rate=2e-4,
        fp16=True,
        save_total_limit=2,
        logging_steps=10,
    ),
)

trainer.train()
```

---

## üîß –û–ø—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞

### –ö–æ–º–∞–Ω–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞

```bash
python scripts/dataset/create_ml_dataset.py \
    --input PATH                      # –í—Ö–æ–¥–Ω–æ–π JSON –æ—Ç EDT –ø–∞—Ä—Å–µ—Ä–∞
    --output PATH                     # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    --categories CAT1,CAT2            # –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    --min-tokens N                    # –ú–∏–Ω–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 50)
    --max-tokens N                    # –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1000)
    --min-quality-score F             # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π quality score (0-1)
    --include-context                 # –í–∫–ª—é—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—ä–µ–∫—Ç–∞
    --deduplicate                     # –£–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
    --split-ratio TRAIN:VAL:TEST      # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val/test
    --format FORMAT                   # json, jsonl, csv, parquet
    --verbose                         # –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥
```

### Python API

```python
generator = MLDatasetGenerator(
    input_path="output/edt_parser/full_parse_with_metadata.json",
    output_path="output/ml_dataset/",
    options={
        # –§–∏–ª—å—Ç—Ä—ã
        'categories': ['Query', 'Calculation'],
        'min_tokens': 50,
        'max_tokens': 500,
        'min_quality_score': 0.8,
        'min_complexity': 3,
        'max_complexity': 15,
        
        # –û–±–æ–≥–∞—â–µ–Ω–∏–µ
        'include_context': True,
        'include_metadata': True,
        'include_dependencies': True,
        'add_comments': True,
        
        # –ö–∞—á–µ—Å—Ç–≤–æ
        'deduplicate': True,
        'remove_test_code': True,
        'remove_empty_functions': True,
        'validate_syntax': True,
        
        # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è
        'augment_data': True,
        'augmentation_factor': 2,
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
        'split_ratio': (0.8, 0.1, 0.1),  # train, val, test
        
        # –§–æ—Ä–º–∞—Ç
        'output_format': 'jsonl',
        'encoding': 'utf-8',
        
        # –ü—Ä–æ—á–µ–µ
        'verbose': True,
        'random_seed': 42
    }
)
```

---

## üìà –ö–∞—á–µ—Å—Ç–≤–æ dataset

### Quality Score

–ö–∞–∂–¥—ã–π –ø—Ä–∏–º–µ—Ä –ø–æ–ª—É—á–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ (0-1) –Ω–∞ –æ—Å–Ω–æ–≤–µ:

1. **–ü–æ–ª–Ω–æ—Ç–∞ –∫–æ–¥–∞** (0-0.3)
   - –ù–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
   - –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –±–ª–æ–∫–æ–≤

2. **–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å** (0-0.2)
   - –ù–∞–ª–∏—á–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
   - –ü–æ–Ω—è—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö

3. **–°–ª–æ–∂–Ω–æ—Å—Ç—å** (0-0.2)
   - –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å (–Ω–µ —Å–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç–æ–π, –Ω–µ —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω—ã–π)
   - Cyclomatic complexity 3-15

4. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ API** (0-0.15)
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö API 1–°
   - –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

5. **–ö–æ–Ω—Ç–µ–∫—Å—Ç** (0-0.15)
   - –ù–∞–ª–∏—á–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
   - –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

### –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è—é—Ç—Å—è:
- ‚ùå –ü—É—Å—Ç—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
- ‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –∫–æ–¥ (Test*, *Demo)
- ‚ùå –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—ã)
- ‚ùå –î—É–±–ª–∏–∫–∞—Ç—ã
- ‚ùå –ö–æ–¥ —Å —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏
- ‚ùå –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–¥ (<20 —Ç–æ–∫–µ–Ω–æ–≤)
- ‚ùå –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –∫–æ–¥ (>2000 —Ç–æ–∫–µ–Ω–æ–≤)

---

## üé® –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å dataset —á–µ—Ä–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é:

```python
generator = MLDatasetGenerator(
    input_path="input.json",
    output_path="output/",
    options={
        'augment_data': True,
        'augmentation_factor': 2,  # –£–≤–µ–ª–∏—á–∏—Ç—å –≤ 2 —Ä–∞–∑–∞
        'augmentation_methods': [
            'rename_variables',      # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            'reorder_parameters',    # –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            'add_comments',          # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
            'simplify_conditions',   # –£–ø—Ä–æ—â–µ–Ω–∏–µ —É—Å–ª–æ–≤–∏–π
        ]
    }
)
```

---

## üêõ Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–∞–ª–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ dataset

**–†–µ—à–µ–Ω–∏–µ:**

```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã
python create_ml_dataset.py \
    --input input.json \
    --output output/ \
    --min-tokens 30 \          # –ë—ã–ª–æ 50
    --min-quality-score 0.6    # –ë—ã–ª–æ 0.8

# –ò–ª–∏ –≤–∫–ª—é—á–∏—Ç–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é
python create_ml_dataset.py \
    --input input.json \
    --output output/ \
    --augment-data \
    --augmentation-factor 3
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏

**–†–µ—à–µ–Ω–∏–µ:**

```python
# –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
generator = MLDatasetGenerator(
    options={
        'balance_categories': True,
        'samples_per_category': 3000
    }
)
```

---

## üìö –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ dataset

```python
# Dataset —Ç–æ–ª—å–∫–æ –¥–ª—è query –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
generator = MLDatasetGenerator(
    input_path="input.json",
    output_path="output/query_optimization/",
    options={
        'categories': ['Query'],
        'min_complexity': 5,
        'include_dependencies': True,
        'custom_prompts': [
            "–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å:",
            "–ö–∞–∫ —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:",
            "–ü–µ—Ä–µ–ø–∏—à–∏ –∑–∞–ø—Ä–æ—Å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ:"
        ]
    }
)
```

---

## üìñ –°–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã

- [EDT Parser Guide](EDT_PARSER_GUIDE.md) - –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
- [BSL Fine-tuning Guide](BSL_FINETUNING_GUIDE.md) - –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- [Architecture Overview](../02-architecture/ARCHITECTURE_OVERVIEW.md) - –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

---

*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: 6 –Ω–æ—è–±—Ä—è 2025*

