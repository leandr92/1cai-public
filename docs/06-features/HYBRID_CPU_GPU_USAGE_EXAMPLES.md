# –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ CPU+GPU

**–í–µ—Ä—Å–∏—è:** 1.0.0  
**–î–∞—Ç–∞:** 2025-01-18  
**–°—Ç–∞—Ç—É—Å:** –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

---

## üìã –û–±–∑–æ—Ä

–î–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π –¥–ª—è Embedding Service.

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –ë–∞–∑–æ–≤–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

```python
from src.services.embedding_service import EmbeddingService

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞ —Å –±–∞–∑–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
service = EmbeddingService(
    model_name="sentence-transformers/all-MiniLM-L6-v2",
    hybrid_mode=True
)

# –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
embeddings = service.encode("—Ç–µ–∫—Å—Ç –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏")
```

---

## üìä –ü—Ä–∏–º–µ—Ä 1: SLO/SLI Tracking

### –í–∫–ª—é—á–µ–Ω–∏–µ SLO Tracking

```python
import os
os.environ["EMBEDDING_SLO_TRACKING"] = "true"

from src.services.embedding_service import EmbeddingService

service = EmbeddingService(hybrid_mode=True)

# –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å—ã
for i in range(100):
    service.encode(f"—Ç–µ–∫—Å—Ç {i}")

# –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É SLO
stats = service.get_advanced_stats()
slo_stats = stats["slo_tracking"]

print("SLO Status:")
for slo_name, status in slo_stats["sli_status"].items():
    print(f"  {slo_name}:")
    print(f"    SLI: {status['sli']:.4f}")
    print(f"    Target: {status['target']:.4f}")
    print(f"    Error Budget: {status['error_budget']:.4f}")
    print(f"    Violation: {status['violation']}")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–π
violations = slo_stats["violations"]
if any(violations.values()):
    print("\n‚ö†Ô∏è SLO Violations detected!")
    for slo_name, violated in violations.items():
        if violated:
            print(f"  - {slo_name}")
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ SLO targets

```python
from src.services.advanced_optimizations import SLOTracker

# –°–æ–∑–¥–∞—ë–º –∫–∞—Å—Ç–æ–º–Ω—ã–π SLO tracker
slo_tracker = SLOTracker()

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º targets (–º–æ–∂–Ω–æ —á–µ—Ä–µ–∑ –∫–æ–¥ –∏–ª–∏ env)
# –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é:
# - latency_p95: 0.1 (100ms)
# - error_rate: 0.001 (0.1%)
# - availability: 0.999 (99.9%)
# - cache_hit_rate: 0.7 (70%)

# –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
slo_tracker.record_metric('latency_p95', 0.085)  # 85ms
slo_tracker.record_metric('availability', 1.0)  # Success

# –ü–æ–ª—É—á–∞–µ–º error budgets
budgets = slo_tracker.get_error_budgets()
print(f"Error budgets: {budgets}")
```

---

## üéØ –ü—Ä–∏–º–µ—Ä 2: Adaptive Quantization

### –í–∫–ª—é—á–µ–Ω–∏–µ Adaptive Quantization

```python
import os
os.environ["EMBEDDING_QUANTIZATION_ENABLED"] = "true"
os.environ["EMBEDDING_ADAPTIVE_QUANTIZATION"] = "true"
os.environ["EMBEDDING_QUANTIZATION_DTYPE"] = "int8"

from src.services.embedding_service import EmbeddingService

service = EmbeddingService(hybrid_mode=True)

# –ü–µ—Ä–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã - –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
embeddings = service.encode(["—Ç–µ–∫—Å—Ç 1", "—Ç–µ–∫—Å—Ç 2", "—Ç–µ–∫—Å—Ç 3"])

# –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏
stats = service.get_advanced_stats()
quant_stats = stats["adaptive_quantization"]

print(f"Quantization Stats:")
print(f"  Calibrated: {quant_stats['calibrated']}")
print(f"  Scale: {quant_stats['scale']:.6f}")
print(f"  Dtype: {quant_stats['dtype']}")

# –†—É—á–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
from src.services.advanced_optimizations import AdaptiveQuantizer

quantizer = AdaptiveQuantizer(dtype="int8")

# –ö–∞–ª–∏–±—Ä—É–µ–º –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö embeddings
sample_embeddings = [
    [0.1, 0.2, 0.3, ...],  # –ü—Ä–∏–º–µ—Ä embedding
    [0.2, 0.3, 0.4, ...],
    # ... –±–æ–ª—å—à–µ –ø—Ä–∏–º–µ—Ä–æ–≤
]

scale = quantizer.calibrate(sample_embeddings, percentile=99.9)
print(f"Calibrated scale: {scale:.6f}")

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
embedding = [0.15, 0.25, 0.35, ...]
quantized, scale = quantizer.quantize(embedding)
dequantized = quantizer.dequantize(quantized, scale)
```

---

## üîç –ü—Ä–∏–º–µ—Ä 3: Semantic Cache —Å ANN

### –í–∫–ª—é—á–µ–Ω–∏–µ Semantic Cache ANN

```python
import os
os.environ["EMBEDDING_SEMANTIC_CACHE"] = "true"
os.environ["EMBEDDING_SEMANTIC_CACHE_ANN"] = "true"
os.environ["EMBEDDING_SEMANTIC_CACHE_ANN_TYPE"] = "faiss"  # –∏–ª–∏ "hnswlib", "linear"

from src.services.embedding_service import EmbeddingService

service = EmbeddingService(hybrid_mode=True)

# –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ ANN
embeddings1 = service.encode("—Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")

# –ü–æ—Ö–æ–∂–∏–π –∑–∞–ø—Ä–æ—Å - –Ω–∞–π–¥—ë—Ç—Å—è —á–µ—Ä–µ–∑ ANN –ø–æ–∏—Å–∫
embeddings2 = service.encode("–º–µ—Ç–æ–¥ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")  # Cache hit!

# –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É ANN
stats = service.get_advanced_stats()
ann_stats = stats["semantic_cache_ann"]

print(f"ANN Stats:")
print(f"  Index Type: {ann_stats['index_type']}")
print(f"  Size: {ann_stats['size']}")
print(f"  Dimension: {ann_stats['dimension']}")

# –†—É—á–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ANN
from src.services.advanced_optimizations import SemanticCacheANN

ann_cache = SemanticCacheANN(index_type="faiss", dimension=384)

# –î–æ–±–∞–≤–ª—è–µ–º embeddings
ann_cache.add([0.1, 0.2, ...], "—Ç–µ–∫—Å—Ç 1")
ann_cache.add([0.2, 0.3, ...], "—Ç–µ–∫—Å—Ç 2")

# –ü–æ–∏—Å–∫
query_embedding = [0.15, 0.25, ...]
result = ann_cache.search(query_embedding, k=1, threshold=0.95)

if result:
    embedding, similarity, text = result
    print(f"Found: {text} (similarity: {similarity:.3f})")
```

---

## ü§ñ –ü—Ä–∏–º–µ—Ä 4: Predictive Batch Size Optimization

### –í–∫–ª—é—á–µ–Ω–∏–µ Predictive Batch Optimizer

```python
import os
os.environ["EMBEDDING_PREDICTIVE_BATCH"] = "true"

from src.services.embedding_service import EmbeddingService

service = EmbeddingService(hybrid_mode=True)

# –ü–µ—Ä–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã - –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏
for i in range(200):
    texts = [f"—Ç–µ–∫—Å—Ç {j}" for j in range(50)]
    service.encode(texts, batch_size=32)

# –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π batch size
texts = [f"—Ç–µ–∫—Å—Ç {i}" for i in range(100)]
embeddings = service.encode(texts)  # Batch size –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç—Å—è

# –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
stats = service.get_advanced_stats()
predictive_stats = stats["predictive_batch"]

print(f"Predictive Batch Stats:")
print(f"  History Size: {predictive_stats['history_size']}")
print(f"  Model Trained: {predictive_stats['model_trained']}")
print(f"  Avg Efficiency: {predictive_stats['avg_efficiency']:.2f}")

# –†—É—á–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
from src.services.advanced_optimizations import PredictiveBatchOptimizer

optimizer = PredictiveBatchOptimizer()

# –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π batch size
optimal_batch = optimizer.predict_optimal_batch_size(
    text_length=1000,
    available_memory=1024.0  # MB
)
print(f"Optimal batch size: {optimal_batch}")

# –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
optimizer.update_model(
    text_length=1000,
    batch_size=64,
    actual_time=0.5,
    memory_used=512.0
)
```

---

## üíæ –ü—Ä–∏–º–µ—Ä 5: Memory-Aware Batching

### –í–∫–ª—é—á–µ–Ω–∏–µ Memory-Aware Batching

```python
import os
os.environ["EMBEDDING_MEMORY_AWARE_BATCHING"] = "true"
os.environ["EMBEDDING_MAX_MEMORY_MB"] = "1024"

from src.services.embedding_service import EmbeddingService

service = EmbeddingService(hybrid_mode=True)

# –°–µ—Ä–≤–∏—Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –±–∞—Ç—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞–º—è—Ç–∏
texts = ["–æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç " * 1000 for _ in range(100)]
embeddings = service.encode(texts)  # –ë–∞—Ç—á–∏ —Ñ–æ—Ä–º–∏—Ä—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

# –†—É—á–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
from src.services.advanced_optimizations import MemoryAwareBatcher

batcher = MemoryAwareBatcher(max_memory_mb=1024)

texts_to_process = ["—Ç–µ–∫—Å—Ç 1", "—Ç–µ–∫—Å—Ç 2", ...]
batches = []

for text in texts_to_process:
    batch = batcher.add_text(text)
    if batch:
        batches.append(batch)

# –ó–∞–≤–µ—Ä—à–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–∞—Ç—á
final_batch = batcher.flush()
if final_batch:
    batches.append(final_batch)

# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∏
for batch in batches:
    embeddings = service.encode(batch)
```

---

## üìà –ü—Ä–∏–º–µ—Ä 6: –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –í—Å–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–º–µ—Å—Ç–µ

```python
import os

# –í–∫–ª—é—á–∞–µ–º –≤—Å–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
os.environ["EMBEDDING_HYBRID_MODE"] = "true"
os.environ["EMBEDDING_SLO_TRACKING"] = "true"
os.environ["EMBEDDING_ADAPTIVE_QUANTIZATION"] = "true"
os.environ["EMBEDDING_SEMANTIC_CACHE_ANN"] = "true"
os.environ["EMBEDDING_SEMANTIC_CACHE_ANN_TYPE"] = "faiss"
os.environ["EMBEDDING_PREDICTIVE_BATCH"] = "true"
os.environ["EMBEDDING_MEMORY_AWARE_BATCHING"] = "true"

from src.services.embedding_service import EmbeddingService

service = EmbeddingService(hybrid_mode=True)

# –ú–∞—Å—Å–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
texts = [f"—Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ {i}" for i in range(1000)]

# –í—Å–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
# - Predictive Batch Optimizer –≤—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π batch size
# - Memory-Aware Batcher —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –±–∞—Ç—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞–º—è—Ç–∏
# - Semantic Cache ANN —É—Å–∫–æ—Ä—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
# - Adaptive Quantization —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å
# - SLO Tracking –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏

embeddings = service.encode(texts, batch_size=64)

# –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
stats = service.get_advanced_stats()

print("=== Advanced Stats ===")
print(f"SLO Tracking: {stats['slo_tracking']}")
print(f"Adaptive Quantization: {stats['adaptive_quantization']}")
print(f"Semantic Cache ANN: {stats['semantic_cache_ann']}")
print(f"Predictive Batch: {stats['predictive_batch']}")
print(f"Memory-Aware Batching: {stats['memory_aware_batching']}")
```

---

## üîß –ü—Ä–∏–º–µ—Ä 7: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —á–µ—Ä–µ–∑ Prometheus

### –î–æ—Å—Ç—É–ø –∫ –º–µ—Ç—Ä–∏–∫–∞–º

```python
from src.monitoring.prometheus_metrics import (
    embedding_slo_latency_p95,
    embedding_slo_error_budget,
    embedding_adaptive_quantization_calibrated,
    embedding_semantic_cache_ann_size,
    embedding_predictive_batch_history_size,
    embedding_weighted_gpu_weights
)

# –ß—Ç–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
from prometheus_client import REGISTRY

# –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏
for metric in REGISTRY.collect():
    if 'embedding' in metric.name:
        print(f"{metric.name}: {metric.samples}")
```

### Grafana Queries

```promql
# SLO Latency
embedding_slo_latency_p95{slo_name="latency_p95"}

# Error Budget
embedding_slo_error_budget{slo_name="latency_p95"}

# Adaptive Quantization
embedding_adaptive_quantization_calibrated
embedding_adaptive_quantization_scale{dtype="int8"}

# Semantic Cache ANN
embedding_semantic_cache_ann_size{index_type="faiss"}

# Predictive Batch
embedding_predictive_batch_history_size
embedding_predictive_batch_model_trained

# Weighted GPU
embedding_weighted_gpu_weights{gpu_id="0"}
embedding_weighted_gpu_load{gpu_id="0"}
```

---

## üß™ –ü—Ä–∏–º–µ—Ä 8: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

### Unit —Ç–µ—Å—Ç—ã

```python
import pytest
from src.services.advanced_optimizations import (
    SLOTracker,
    AdaptiveQuantizer,
    SemanticCacheANN,
    PredictiveBatchOptimizer,
    MemoryAwareBatcher
)

def test_slo_tracker():
    tracker = SLOTracker()
    tracker.record_metric('latency_p95', 0.1)
    tracker.record_metric('availability', 1.0)
    
    violations = tracker.check_slo_violation()
    assert isinstance(violations, dict)

def test_adaptive_quantizer():
    quantizer = AdaptiveQuantizer(dtype="int8")
    embedding = [0.1, 0.2, 0.3, 0.4, 0.5]
    
    quantized, scale = quantizer.quantize(embedding)
    dequantized = quantizer.dequantize(quantized, scale)
    
    assert len(quantized) == len(embedding)
    assert isinstance(quantized[0], int)

def test_semantic_cache_ann():
    ann = SemanticCacheANN(index_type="linear", dimension=5)
    ann.add([0.1, 0.2, 0.3, 0.4, 0.5], "—Ç–µ–∫—Å—Ç 1")
    
    result = ann.search([0.11, 0.21, 0.31, 0.41, 0.51], threshold=0.95)
    assert result is not None

def test_predictive_batch_optimizer():
    optimizer = PredictiveBatchOptimizer()
    batch_size = optimizer.predict_optimal_batch_size(
        text_length=1000,
        available_memory=1024.0
    )
    assert 8 <= batch_size <= 256

def test_memory_aware_batcher():
    batcher = MemoryAwareBatcher(max_memory_mb=10)
    batch = batcher.add_text("—Ç–µ–∫—Å—Ç")
    assert batch is None  # –ë–∞—Ç—á –µ—â—ë –Ω–µ –≥–æ—Ç–æ–≤
    
    final_batch = batcher.flush()
    assert final_batch == ["—Ç–µ–∫—Å—Ç"]
```

---

## üìä –ü—Ä–∏–º–µ—Ä 9: –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```python
import time
from src.services.embedding_service import EmbeddingService

# –ë–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
service_basic = EmbeddingService(hybrid_mode=False)

# –° –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
os.environ["EMBEDDING_SEMANTIC_CACHE_ANN"] = "true"
os.environ["EMBEDDING_ADAPTIVE_QUANTIZATION"] = "true"
os.environ["EMBEDDING_PREDICTIVE_BATCH"] = "true"

service_optimized = EmbeddingService(hybrid_mode=True)

# –¢–µ—Å—Ç–∏—Ä—É–µ–º
texts = [f"—Ç–µ–∫—Å—Ç {i}" for i in range(100)]

# –ë–∞–∑–æ–≤—ã–π
start = time.time()
embeddings_basic = service_basic.encode(texts)
time_basic = time.time() - start

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
start = time.time()
embeddings_optimized = service_optimized.encode(texts)
time_optimized = time.time() - start

print(f"Basic: {time_basic:.3f}s")
print(f"Optimized: {time_optimized:.3f}s")
print(f"Speedup: {time_basic / time_optimized:.2f}x")
```

---

## üéõÔ∏è –ü—Ä–∏–º–µ—Ä 10: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

```python
import os

# SLO targets
os.environ["EMBEDDING_SLO_TRACKING"] = "true"
# Targets –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—é—Ç—Å—è –≤ –∫–æ–¥–µ SLOTracker

# Adaptive Quantization
os.environ["EMBEDDING_ADAPTIVE_QUANTIZATION"] = "true"
os.environ["EMBEDDING_QUANTIZATION_DTYPE"] = "int8"  # –∏–ª–∏ "int16"
os.environ["EMBEDDING_ADAPTIVE_QUANTIZATION_CALIBRATION_SAMPLES"] = "1000"

# Semantic Cache ANN
os.environ["EMBEDDING_SEMANTIC_CACHE_ANN"] = "true"
os.environ["EMBEDDING_SEMANTIC_CACHE_ANN_TYPE"] = "faiss"  # faiss, hnswlib, linear
os.environ["EMBEDDING_SEMANTIC_CACHE_SIZE"] = "500"
os.environ["EMBEDDING_SEMANTIC_THRESHOLD"] = "0.95"

# Predictive Batch
os.environ["EMBEDDING_PREDICTIVE_BATCH"] = "true"
os.environ["EMBEDDING_PREDICTIVE_BATCH_MAX_HISTORY"] = "1000"

# Memory-Aware Batching
os.environ["EMBEDDING_MEMORY_AWARE_BATCHING"] = "true"
os.environ["EMBEDDING_MAX_MEMORY_MB"] = "1024"

from src.services.embedding_service import EmbeddingService

service = EmbeddingService(hybrid_mode=True)
```

---

## üîó –°–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã

- [`HYBRID_CPU_GPU_MODE.md`](HYBRID_CPU_GPU_MODE.md) - –ë–∞–∑–æ–≤–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ
- [`HYBRID_CPU_GPU_BEST_PRACTICES.md`](HYBRID_CPU_GPU_BEST_PRACTICES.md) - –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏
- [`HYBRID_CPU_GPU_ADVANCED_RESEARCH.md`](HYBRID_CPU_GPU_ADVANCED_RESEARCH.md) - –£–≥–ª—É–±–ª—ë–Ω–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
- [`HYBRID_CPU_GPU_IMPLEMENTATION_ROADMAP.md`](HYBRID_CPU_GPU_IMPLEMENTATION_ROADMAP.md) - –ü–ª–∞–Ω –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

---

**–í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞:** 1.0.0  
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025-01-18  
**–°—Ç–∞—Ç—É—Å:** –ê–∫—Ç–∏–≤–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ

