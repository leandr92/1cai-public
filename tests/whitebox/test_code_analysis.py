"""
White-Box Tests - Анализ кода
"""

import pytest
import os
import subprocess
from pathlib import Path
import radon.complexity as radon_complexity
from radon.visitors import ComplexityVisitor
import sys

sys.path.insert(0, str(Path(__file__).parent.parent.parent))


def test_code_coverage_threshold():
    """
    White-box: Code coverage должен быть >90%
    """
    
    # Run coverage
    result = subprocess.run(
        ['pytest', '--cov=src', '--cov-report=term-missing', '--cov-fail-under=50'],
        capture_output=True,
        text=True
    )
    
    # For now, just check it runs
    # In production, enforce 90%
    print(result.stdout)
    
    # assert result.returncode == 0, "Coverage below threshold"


def test_cyclomatic_complexity():
    """
    White-box: Cyclomatic complexity анализ
    
    Target: Average complexity < 10
    """
    
    src_dir = Path(__file__).parent.parent.parent / 'src'
    
    complexities = []
    
    for py_file in src_dir.rglob('*.py'):
        if '__pycache__' in str(py_file):
            continue
        
        try:
            with open(py_file, 'r', encoding='utf-8') as f:
                code = f.read()
            
            visitor = ComplexityVisitor.from_code(code)
            
            for item in visitor.functions + visitor.methods:
                complexities.append({
                    'file': py_file.name,
                    'function': item.name,
                    'complexity': item.complexity
                })
        
        except Exception as e:
            # Skip files with syntax errors
            pass
    
    if complexities:
        avg_complexity = sum(c['complexity'] for c in complexities) / len(complexities)
        max_complexity = max(complexities, key=lambda x: x['complexity'])
        
        print(f"\n=== Cyclomatic Complexity ===")
        print(f"Total functions: {len(complexities)}")
        print(f"Average complexity: {avg_complexity:.2f}")
        print(f"Max complexity: {max_complexity['complexity']} ({max_complexity['function']} in {max_complexity['file']})")
        
        # Find high complexity functions
        high_complexity = [c for c in complexities if c['complexity'] > 15]
        
        if high_complexity:
            print(f"\nHigh complexity functions ({len(high_complexity)}):")
            for func in high_complexity[:10]:
                print(f"  - {func['function']}: {func['complexity']} ({func['file']})")
        
        assert avg_complexity < 15, f"Average complexity too high: {avg_complexity:.2f}"


def test_code_duplication():
    """
    White-box: Обнаружение дублирования кода
    """
    
    # Use Radon's raw metrics
    from radon.raw import analyze
    
    src_dir = Path(__file__).parent.parent.parent / 'src'
    
    metrics = []
    
    for py_file in src_dir.rglob('*.py'):
        if '__pycache__' in str(py_file):
            continue
        
        try:
            with open(py_file, 'r', encoding='utf-8') as f:
                code = f.read()
            
            analysis = analyze(code)
            
            metrics.append({
                'file': py_file.name,
                'loc': analysis.loc,
                'sloc': analysis.sloc,
                'comments': analysis.comments,
                'multi': analysis.multi,
                'blank': analysis.blank
            })
        
        except:
            pass
    
    if metrics:
        total_loc = sum(m['loc'] for m in metrics)
        total_sloc = sum(m['sloc'] for m in metrics)
        total_comments = sum(m['comments'] for m in metrics)
        
        comment_ratio = total_comments / total_sloc if total_sloc > 0 else 0
        
        print(f"\n=== Code Metrics ===")
        print(f"Total LOC: {total_loc}")
        print(f"Source LOC: {total_sloc}")
        print(f"Comments: {total_comments}")
        print(f"Comment ratio: {comment_ratio:.2%}")
        
        # At least 10% comments
        assert comment_ratio >= 0.05, f"Too few comments: {comment_ratio:.2%}"


def test_dead_code_detection():
    """
    White-box: Обнаружение неиспользуемого кода
    """
    
    # Use vulture for dead code detection
    result = subprocess.run(
        ['vulture', 'src/', '--min-confidence', '80'],
        capture_output=True,
        text=True
    )
    
    if result.stdout:
        dead_code_items = result.stdout.strip().split('\n')
        
        print(f"\n=== Dead Code Detection ===")
        print(f"Found {len(dead_code_items)} potential dead code items")
        
        # Allow some dead code (e.g., public APIs not yet used)
        assert len(dead_code_items) < 50, f"Too much dead code: {len(dead_code_items)} items"


def test_import_dependencies():
    """
    White-box: Анализ зависимостей между модулями
    """
    
    src_dir = Path(__file__).parent.parent.parent / 'src'
    
    imports = {}
    
    for py_file in src_dir.rglob('*.py'):
        if '__pycache__' in str(py_file):
            continue
        
        try:
            with open(py_file, 'r', encoding='utf-8') as f:
                code = f.read()
            
            # Simple import extraction
            module_imports = []
            for line in code.split('\n'):
                line = line.strip()
                if line.startswith('import ') or line.startswith('from '):
                    module_imports.append(line)
            
            imports[py_file.name] = module_imports
        
        except:
            pass
    
    # Check for circular dependencies (simplified)
    print(f"\n=== Import Dependencies ===")
    print(f"Analyzed {len(imports)} files")
    
    total_imports = sum(len(imps) for imps in imports.values())
    avg_imports = total_imports / len(imports) if imports else 0
    
    print(f"Total imports: {total_imports}")
    print(f"Avg imports per file: {avg_imports:.1f}")
    
    assert avg_imports < 20, f"Too many imports per file: {avg_imports:.1f}"


def test_function_length():
    """
    White-box: Длина функций
    
    Target: Average < 50 lines
    """
    
    from radon.visitors import ComplexityVisitor
    
    src_dir = Path(__file__).parent.parent.parent / 'src'
    
    function_lengths = []
    
    for py_file in src_dir.rglob('*.py'):
        if '__pycache__' in str(py_file):
            continue
        
        try:
            with open(py_file, 'r', encoding='utf-8') as f:
                code = f.read()
            
            visitor = ComplexityVisitor.from_code(code)
            
            for item in visitor.functions + visitor.methods:
                length = item.endline - item.lineno
                function_lengths.append({
                    'name': item.name,
                    'file': py_file.name,
                    'length': length
                })
        
        except:
            pass
    
    if function_lengths:
        avg_length = sum(f['length'] for f in function_lengths) / len(function_lengths)
        max_func = max(function_lengths, key=lambda x: x['length'])
        
        print(f"\n=== Function Length Analysis ===")
        print(f"Total functions: {len(function_lengths)}")
        print(f"Average length: {avg_length:.1f} lines")
        print(f"Longest: {max_func['name']} ({max_func['length']} lines in {max_func['file']})")
        
        # Find very long functions
        long_functions = [f for f in function_lengths if f['length'] > 100]
        
        if long_functions:
            print(f"\nVery long functions ({len(long_functions)}):")
            for func in long_functions[:5]:
                print(f"  - {func['name']}: {func['length']} lines ({func['file']})")
        
        assert avg_length < 100, f"Functions too long on average: {avg_length:.1f}"


if __name__ == '__main__':
    pytest.main([__file__, '-v', '-s'])


