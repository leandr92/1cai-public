# üóÑÔ∏è Greenplum vs –¢–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ - –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞

**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** 2024-11-05  
**–¢–∏–ø —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:** MPP Database (Greenplum) vs OLTP Database (PostgreSQL)  
**–ö–æ–Ω—Ç–µ–∫—Å—Ç:** Airflow + Greenplum –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö

---

## üéØ Executive Summary

### –ß—Ç–æ —Ç–∞–∫–æ–µ Greenplum?

**Greenplum Database** - –º–∞—Å—Å–∏–≤–Ω–æ-–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –°–£–ë–î (MPP), –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ PostgreSQL.

**–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
- üî¢ –û–±—Ä–∞–±–æ—Ç–∫–∞ **–ø–µ—Ç–∞–±–∞–π—Ç–æ–≤** –¥–∞–Ω–Ω—ã—Ö
- ‚ö° **–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ** –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ (100+ nodes)
- üìä **Column-oriented** storage (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏)
- üîÑ **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å** —Å PostgreSQL (SQL, —Ñ—É–Ω–∫—Ü–∏–∏, —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
- üí∞ **Open Source** (Apache License 2.0)

**Use case:** Data Warehouse, Business Intelligence, Big Data Analytics

---

### –¢–µ–∫—É—â–∞—è —Å–∏—Ç—É–∞—Ü–∏—è –≤ –ø—Ä–æ–µ–∫—Ç–µ:

**–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:** PostgreSQL 15.4
- üéØ **OLTP** (—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã)
- üì¶ 12 —Ç–∞–±–ª–∏—Ü –¥–ª—è operational data
- üìä 3 views –¥–ª—è –±–∞–∑–æ–≤–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
- üíæ –†–∞–∑–º–µ—Ä: ~10GB (–ø—Ä–æ–≥–Ω–æ–∑: 100GB —á–µ—Ä–µ–∑ –≥–æ–¥)

**–ê–Ω–∞–ª–∏—Ç–∏–∫–∞:**
- ‚ö†Ô∏è –ü—Ä–æ—Å—Ç—ã–µ analytics views –≤ PostgreSQL
- ‚ö†Ô∏è Grafana –¥–∞—à–±–æ—Ä–¥—ã (–º–µ—Ç—Ä–∏–∫–∏ –∏–∑ Prometheus)
- ‚ö†Ô∏è –ù–µ—Ç –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ Data Warehouse
- ‚ö†Ô∏è –ù–µ—Ç OLAP –∫—É–±–æ–≤

**–ü—Ä–æ–±–ª–µ–º—ã –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è:**
- ‚ùå –ü—Ä–∏ 10,000+ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã –±—É–¥—É—Ç –º–µ–¥–ª–µ–Ω–Ω—ã–µ
- ‚ùå –°–ª–æ–∂–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ (GROUP BY –Ω–∞ –º–∏–ª–ª–∏–æ–Ω–∞—Ö –∑–∞–ø–∏—Å–µ–π)
- ‚ùå –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∑–∞ –≥–æ–¥—ã ‚Üí GBs/TBs

---

## üÜö PostgreSQL vs Greenplum

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ

```mermaid
graph TB
    subgraph "PostgreSQL 15 (OLTP) - –¢–µ–∫—É—â–µ–µ"
        PG_MASTER["PostgreSQL Master<br/>Single Node<br/>All data on one server<br/>Max: ~1TB efficiently"]
        
        PG_REPLICA1["Read Replica 1<br/>Streaming replication<br/>Read-only"]
        PG_REPLICA2["Read Replica 2<br/>Read-only"]
        
        APP[Application] --> PG_MASTER
        APP --> PG_REPLICA1
        APP --> PG_REPLICA2
        
        PG_MASTER -.Replication.-> PG_REPLICA1
        PG_MASTER -.Replication.-> PG_REPLICA2
    end
    
    subgraph "Greenplum 7 (OLAP) - –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º–æ–µ"
        GP_MASTER["Greenplum Master<br/>Coordinator Node<br/>Query planning<br/>Metadata storage"]
        
        GP_SEG1["Segment 1<br/>Data subset 1<br/>Parallel processing"]
        GP_SEG2["Segment 2<br/>Data subset 2<br/>Parallel processing"]
        GP_SEG3["Segment 3<br/>Data subset 3<br/>Parallel processing"]
        GP_SEG4["Segment 4<br/>Data subset 4<br/>Parallel processing"]
        
        GP_MIRROR1["Mirror Segment 1<br/>Failover"]
        GP_MIRROR2["Mirror Segment 2<br/>Failover"]
        
        ANALYTICS[Analytics Queries] --> GP_MASTER
        
        GP_MASTER --> GP_SEG1
        GP_MASTER --> GP_SEG2
        GP_MASTER --> GP_SEG3
        GP_MASTER --> GP_SEG4
        
        GP_SEG1 -.Mirror.-> GP_MIRROR1
        GP_SEG2 -.Mirror.-> GP_MIRROR2
    end

    style PG_MASTER fill:#336791
    style GP_MASTER fill:#00a86b
    style GP_SEG1 fill:#00a86b
    style GP_SEG2 fill:#00a86b
```

---

## üìä –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | PostgreSQL 15 | Greenplum 7 | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ |
|----------------|---------------|-------------|----------------------|
| **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** | Single-node (—Å —Ä–µ–ø–ª–∏–∫–∞–º–∏) | MPP (distributed) | GP –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö |
| **–¢–∏–ø –Ω–∞–≥—Ä—É–∑–∫–∏** | OLTP (—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏) | OLAP (–∞–Ω–∞–ª–∏—Ç–∏–∫–∞) | GP –¥–ª—è reporting |
| **Data size sweet spot** | < 1TB | 10TB - 10PB | GP –ø—Ä–∏ 1TB+ |
| **–ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º** | Multi-core (16-64 cores) | Multi-node (100s nodes) | GP –ø—Ä–∏ > 1M records/sec |
| **Storage** | Row-oriented | Column-oriented (Append-Optimized) | GP –¥–ª—è –∫–æ–ª–æ–Ω–æ—á–Ω–æ–≥–æ |
| **Compression** | Basic (TOAST) | Advanced (zstd, RLE, dict) | GP: 5-10x compression |
| **Concurrent writes** | Excellent (MVCC) | Limited (AO tables) | PG –¥–ª—è OLTP |
| **Concurrent reads** | Good (16-32 connections) | Excellent (1000s queries) | GP –¥–ª—è BI |
| **Aggregations** | Good (single-node) | Excellent (parallel) | GP –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ |
| **Joins** | Good (hash/merge) | Excellent (redistribute) | GP –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö joins |
| **Indexing** | B-tree, GIN, GIST, etc | Limited (AO no indexes) | PG –¥–ª—è OLTP |
| **Partitioning** | Declarative (table inheritance) | Native (range, list) | –û–±–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç |
| **Cost** | Free (OSS) | Free (OSS) | –û–±–∞ –±–µ—Å–ø–ª–∞—Ç–Ω—ã |
| **Hardware** | 1 server (16GB+ RAM) | 4-100 servers | GP —Ç—Ä–µ–±—É–µ—Ç cluster |
| **Deployment** | Simple (Docker, K8s) | Complex (cluster management) | PG –ø—Ä–æ—â–µ |
| **SQL Compatibility** | 100% PostgreSQL | ~95% PostgreSQL | GP –ø–æ—á—Ç–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º |
| **Extensions** | All PostgreSQL extensions | Limited subset | PG –±–æ–ª–µ–µ –≥–∏–±–∫–∏–π |

---

## üîç –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞

### –°—Ü–µ–Ω–∞—Ä–∏–π 1: –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

**–ó–∞–¥–∞—á–∞:** –ü–æ—Å—á–∏—Ç–∞—Ç—å —Ç–æ–ø-100 —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≥–æ–¥ —Å –∞–≥—Ä–µ–≥–∞—Ü–∏—è–º–∏.

#### PostgreSQL (—Ç–µ–∫—É—â–µ–µ):

```sql
-- Table: requests (10M –∑–∞–ø–∏—Å–µ–π –∑–∞ –≥–æ–¥)
SELECT 
    query,
    COUNT(*) as total_requests,
    AVG(execution_time_ms) as avg_time,
    MAX(execution_time_ms) as max_time,
    COUNT(DISTINCT user_id) as unique_users,
    AVG(tokens_used) as avg_tokens
FROM requests
WHERE created_at >= NOW() - INTERVAL '1 year'
  AND status = 'success'
GROUP BY query
ORDER BY total_requests DESC
LIMIT 100;

-- Execution time: ~45-60 seconds (single-core aggregation)
-- Index: idx_requests_created_at (helps with WHERE)
-- RAM usage: ~2GB –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
```

**–ü—Ä–æ–±–ª–µ–º—ã:**
- ‚ùå 45-60 —Å–µ–∫—É–Ω–¥ - —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ –¥–ª—è dashboard
- ‚ùå –ù–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ production –ë–î (–º–æ–∂–µ—Ç –∑–∞–º–µ–¥–ª–∏—Ç—å OLTP –æ–ø–µ—Ä–∞—Ü–∏–∏)
- ‚ùå –ü—Ä–∏ 100M –∑–∞–ø–∏—Å–µ–π –±—É–¥–µ—Ç > 5 –º–∏–Ω—É—Ç

---

#### Greenplum (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞):

```sql
-- Distributed table: requests (10M –∑–∞–ø–∏—Å–µ–π, distributed by user_id)
SELECT 
    query,
    COUNT(*) as total_requests,
    AVG(execution_time_ms) as avg_time,
    MAX(execution_time_ms) as max_time,
    COUNT(DISTINCT user_id) as unique_users,
    AVG(tokens_used) as avg_tokens
FROM requests
WHERE created_at >= NOW() - INTERVAL '1 year'
  AND status = 'success'
GROUP BY query
ORDER BY total_requests DESC
LIMIT 100;

-- Execution time: ~2-5 seconds (parallel –Ω–∞ 16 segments)
-- Parallel execution –Ω–∞ –∫–∞–∂–¥–æ–º segment
-- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –Ω–∞ master
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ 2-5 —Å–µ–∫—É–Ω–¥ –≤–º–µ—Å—Ç–æ 45-60 (10-30x –±—ã—Å—Ç—Ä–µ–µ!)
- ‚úÖ –ù–µ –Ω–∞–≥—Ä—É–∂–∞–µ—Ç OLTP —Å–∏—Å—Ç–µ–º—É (–æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Ç–µ—Ä)
- ‚úÖ –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –ª–∏–Ω–µ–π–Ω–æ (–±–æ–ª—å—à–µ segments ‚Üí –±—ã—Å—Ç—Ä–µ–µ)

---

### –°—Ü–µ–Ω–∞—Ä–∏–π 2: Time-series –∞–Ω–∞–ª–∏—Ç–∏–∫–∞

**–ó–∞–¥–∞—á–∞:** –ü–æ—Å—á–∏—Ç–∞—Ç—å –ø–æ—á–∞—Å–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–æ –∫–∞–∂–¥–æ–º—É AI –∞–≥–µ–Ω—Ç—É –∑–∞ 3 –º–µ—Å—è—Ü–∞.

#### PostgreSQL:

```sql
-- 100M –∑–∞–ø–∏—Å–µ–π –∑–∞ 3 –º–µ—Å—è—Ü–∞
SELECT 
    DATE_TRUNC('hour', created_at) as hour,
    JSONB_EXTRACT_PATH_TEXT(response, 'agent_used') as agent,
    COUNT(*) as requests_count,
    AVG(execution_time_ms) as avg_execution_time,
    SUM(tokens_used) as total_tokens,
    COUNT(DISTINCT user_id) as unique_users,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY execution_time_ms) as p95_latency
FROM requests
WHERE created_at >= NOW() - INTERVAL '3 months'
GROUP BY 1, 2
ORDER BY 1 DESC, 2;

-- Records: 100M
-- Groups: ~2,160 hours √ó 8 agents = ~17,280 groups
-- Execution time: 5-10 minutes (!!!)
-- Temp disk usage: ~10GB
```

**–ü—Ä–æ–±–ª–µ–º—ã:**
- ‚ùå 5-10 –º–∏–Ω—É—Ç - –Ω–µ–ø—Ä–∏–≥–æ–¥–Ω–æ –¥–ª—è interactive dashboards
- ‚ùå –í—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
- ‚ùå –ë–ª–æ–∫–∏—Ä—É–µ—Ç –¥—Ä—É–≥–∏–µ –∑–∞–ø—Ä–æ—Å—ã

---

#### Greenplum:

```sql
-- Distributed table —Å partitioning –ø–æ created_at (monthly)
-- Column-oriented storage (AO tables)
SELECT 
    DATE_TRUNC('hour', created_at) as hour,
    JSONB_EXTRACT_PATH_TEXT(response, 'agent_used') as agent,
    COUNT(*) as requests_count,
    AVG(execution_time_ms) as avg_execution_time,
    SUM(tokens_used) as total_tokens,
    COUNT(DISTINCT user_id) as unique_users,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY execution_time_ms) as p95_latency
FROM requests
WHERE created_at >= NOW() - INTERVAL '3 months'
GROUP BY 1, 2
ORDER BY 1 DESC, 2;

-- Execution time: 5-15 seconds
-- –ü–æ—á–µ–º—É –±—ã—Å—Ç—Ä–µ–µ:
--   1. Partition elimination (—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ 3 –º–µ—Å—è—Ü–∞)
--   2. Column-oriented (—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏)
--   3. Parallel aggregation –Ω–∞ 16 segments
--   4. Compression (10x –º–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —á—Ç–µ–Ω–∏—è)
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ 5-15 —Å–µ–∫—É–Ω–¥ –≤–º–µ—Å—Ç–æ 5-10 –º–∏–Ω—É—Ç (30-100x –±—ã—Å—Ç—Ä–µ–µ!)
- ‚úÖ –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è real-time dashboards
- ‚úÖ –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –¥–æ –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤ –∑–∞–ø–∏—Å–µ–π

---

### –°—Ü–µ–Ω–∞—Ä–∏–π 3: ML Feature Engineering

**–ó–∞–¥–∞—á–∞:** –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ features –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π.

```sql
-- –°–æ–∑–¥–∞—Ç—å features –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è user churn
WITH user_stats AS (
    SELECT 
        user_id,
        COUNT(*) as total_requests,
        AVG(execution_time_ms) as avg_latency,
        MAX(created_at) as last_request_date,
        MIN(created_at) as first_request_date,
        COUNT(DISTINCT DATE(created_at)) as active_days,
        -- ... –µ—â–µ 20+ features
    FROM requests
    WHERE created_at >= NOW() - INTERVAL '6 months'
    GROUP BY user_id
),
user_sequences AS (
    SELECT 
        user_id,
        ARRAY_AGG(query ORDER BY created_at) as query_history,
        ARRAY_AGG(execution_time_ms ORDER BY created_at) as latency_history
        -- ... –µ—â–µ 10+ sequence features
    FROM requests
    WHERE created_at >= NOW() - INTERVAL '1 month'
    GROUP BY user_id
)
SELECT 
    u.user_id,
    -- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ features
    us.total_requests,
    us.avg_latency,
    EXTRACT(DAY FROM NOW() - us.last_request_date) as days_since_last_request,
    us.active_days,
    -- Sequence features
    ARRAY_LENGTH(uq.query_history, 1) as recent_query_count,
    -- ... –µ—â–µ 50+ features
FROM users u
LEFT JOIN user_stats us ON u.id = us.user_id
LEFT JOIN user_sequences uq ON u.id = uq.user_id;
```

**PostgreSQL:**
- Execution time: **10-20 –º–∏–Ω—É—Ç** (100M records aggregation)
- Memory usage: **8-16GB**
- –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ—á—å—é

**Greenplum:**
- Execution time: **30-60 —Å–µ–∫—É–Ω–¥** (parallel processing)
- Memory usage: **Distributed** (2GB per segment √ó 16 = 32GB total, –Ω–æ distributed)
- –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –≤ –ª—é–±–æ–µ –≤—Ä–µ–º—è

**–†–∞–∑–Ω–∏—Ü–∞:** 10-40x –±—ã—Å—Ç—Ä–µ–µ!

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: Hybrid PostgreSQL + Greenplum

### –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```mermaid
graph TB
    subgraph "OPERATIONAL LAYER (OLTP)"
        APP[1C AI Stack API<br/>FastAPI]
        
        PG_MASTER[(PostgreSQL Master<br/>OLTP Database<br/>Operational data<br/>Size: ~100GB)]
        
        PG_REPLICA[(PostgreSQL Replica<br/>Read-only<br/>For light analytics)]
    end
    
    subgraph "AIRFLOW ORCHESTRATION"
        AIRFLOW[Apache Airflow<br/>Workflow Orchestration]
        
        DAG_ETL[DAG: ETL Pipeline<br/>Schedule: Every 1 hour]
        DAG_ML[DAG: ML Pipeline<br/>Schedule: Daily]
        DAG_REPORT[DAG: Reporting<br/>Schedule: Daily]
    end
    
    subgraph "ANALYTICAL LAYER (OLAP)"
        GP_MASTER["Greenplum Master<br/>Coordinator<br/>Query planning"]
        
        GP_SEG1["Segment 1<br/>Data: 1/16<br/>8 cores, 16GB RAM"]
        GP_SEG2["Segment 2<br/>Data: 2/16<br/>8 cores, 16GB RAM"]
        GP_SEG3["... Segments 3-14 ..."]
        GP_SEG4["Segment 16<br/>Data: 16/16<br/>8 cores, 16GB RAM"]
        
        GP_STORAGE[("Column Storage<br/>Compressed 10x<br/>Append-Optimized")]
    end
    
    subgraph "VISUALIZATION LAYER"
        GRAFANA[Grafana<br/>Operational Metrics<br/>Real-time]
        
        BI_TOOL[Power BI / Tableau<br/>Business Analytics<br/>Historical data]
    end

    APP --> PG_MASTER
    APP --> PG_REPLICA
    
    PG_MASTER -.CDC/Logs.-> AIRFLOW
    
    AIRFLOW --> DAG_ETL
    AIRFLOW --> DAG_ML
    AIRFLOW --> DAG_REPORT
    
    DAG_ETL --> GP_MASTER
    DAG_ETL -.Load data.-> GP_SEG1
    DAG_ETL -.Load data.-> GP_SEG2
    DAG_ETL -.Load data.-> GP_SEG4
    
    GP_MASTER --> GP_SEG1
    GP_MASTER --> GP_SEG2
    GP_MASTER --> GP_SEG3
    GP_MASTER --> GP_SEG4
    
    GP_SEG1 --> GP_STORAGE
    GP_SEG2 --> GP_STORAGE
    GP_SEG4 --> GP_STORAGE
    
    PG_REPLICA --> GRAFANA
    GP_MASTER --> BI_TOOL
    
    DAG_ML -.Read features.-> GP_MASTER

    style AIRFLOW fill:#ff6b6b
    style GP_MASTER fill:#00a86b
```

---

## üîÑ Data Flow: OLTP ‚Üí OLAP

### Airflow ETL Pipeline –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from datetime import datetime, timedelta

with DAG(
    'postgres_to_greenplum_etl',
    schedule_interval='0 * * * *',  # Every hour
    start_date=datetime(2024, 1, 1),
    catchup=False,
) as dag:

    # Extract from PostgreSQL (operational DB)
    extract_incremental = PostgresOperator(
        task_id='extract_new_requests',
        postgres_conn_id='postgres_oltp',
        sql="""
            SELECT 
                id, user_id, query, response, model,
                tokens_used, execution_time_ms, status, created_at
            FROM requests
            WHERE created_at >= NOW() - INTERVAL '1 hour'
              AND created_at < DATE_TRUNC('hour', NOW());
        """,
        do_xcom_push=True,  # Pass data to next task
    )
    
    # Transform: Prepare for Greenplum
    transform_data = PythonOperator(
        task_id='transform_for_greenplum',
        python_callable=transform_to_greenplum_format,
        # Denormalize, add computed columns, etc
    )
    
    # Load to Greenplum (analytical DB)
    load_to_greenplum = PythonOperator(
        task_id='load_to_greenplum',
        python_callable=bulk_load_to_greenplum,
        # Use COPY for fast loading
    )
    
    # Refresh materialized views
    refresh_mv = PostgresOperator(
        task_id='refresh_materialized_views',
        postgres_conn_id='greenplum_olap',
        sql="""
            REFRESH MATERIALIZED VIEW mv_hourly_stats;
            REFRESH MATERIALIZED VIEW mv_daily_agent_usage;
            REFRESH MATERIALIZED VIEW mv_user_behavior;
        """
    )
    
    # Update metadata
    update_etl_log = PostgresOperator(
        task_id='log_etl_run',
        postgres_conn_id='postgres_oltp',
        sql="""
            INSERT INTO etl_runs (pipeline, records_processed, execution_time, status)
            VALUES ('postgres_to_greenplum', {{ ti.xcom_pull(task_ids='extract_new_requests') | length }}, 
                    {{ task_instance.duration }}, 'success');
        """
    )
    
    # Dependencies
    extract_incremental >> transform_data >> load_to_greenplum >> refresh_mv >> update_etl_log
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –î–∞–Ω–Ω—ã–µ –≤ Greenplum –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –∫–∞–∂–¥—ã–π —á–∞—Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!

---

## üìà Performance Comparison (Benchmarks)

### Test Dataset:
- **requests table:** 100M –∑–∞–ø–∏—Å–µ–π (1 –≥–æ–¥ –¥–∞–Ω–Ω—ã—Ö)
- **Size in PostgreSQL:** ~50GB (row-oriented)
- **Size in Greenplum:** ~5GB (column-oriented, compressed)

### Query 1: Simple aggregation

```sql
SELECT 
    DATE(created_at) as day,
    COUNT(*) as requests,
    AVG(execution_time_ms) as avg_time
FROM requests
WHERE created_at >= '2024-01-01'
GROUP BY DATE(created_at)
ORDER BY day;
```

| Database | Execution Time | Explanation |
|----------|---------------|-------------|
| PostgreSQL | 35-45 seconds | Single-node, sequential scan |
| PostgreSQL (with index) | 25-30 seconds | Index on created_at |
| **Greenplum (16 segments)** | **2-4 seconds** | Parallel scan, column storage |

**Speed-up: 10-20x** ‚ö°

---

### Query 2: Complex multi-table join with aggregations

```sql
SELECT 
    u.email,
    u.role,
    COUNT(r.id) as total_requests,
    SUM(r.tokens_used) as total_tokens,
    AVG(r.execution_time_ms) as avg_latency,
    COUNT(DISTINCT DATE(r.created_at)) as active_days,
    MAX(r.created_at) as last_activity,
    -- –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY r.execution_time_ms) as median_latency,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY r.execution_time_ms) as p95_latency
FROM users u
LEFT JOIN requests r ON u.id = r.user_id
WHERE r.created_at >= NOW() - INTERVAL '6 months'
GROUP BY u.id, u.email, u.role
HAVING COUNT(r.id) > 100
ORDER BY total_requests DESC;
```

| Database | Records Scanned | Execution Time | Temp Space |
|----------|----------------|----------------|------------|
| PostgreSQL | 50M (requests) + 10K (users) | 3-5 minutes | 5GB |
| **Greenplum** | Same, but parallel | **15-30 seconds** | 5GB distributed |

**Speed-up: 10-20x** ‚ö°

---

### Query 3: Window functions (–¥–ª—è ML features)

```sql
-- –í—ã—á–∏—Å–ª–∏—Ç—å rolling average –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
SELECT 
    user_id,
    query,
    execution_time_ms,
    AVG(execution_time_ms) OVER (
        PARTITION BY user_id 
        ORDER BY created_at 
        ROWS BETWEEN 10 PRECEDING AND CURRENT ROW
    ) as rolling_avg_10,
    LAG(execution_time_ms, 1) OVER (
        PARTITION BY user_id 
        ORDER BY created_at
    ) as prev_execution_time,
    ROW_NUMBER() OVER (
        PARTITION BY user_id 
        ORDER BY created_at DESC
    ) as request_rank
FROM requests
WHERE created_at >= NOW() - INTERVAL '1 month';
```

| Database | Execution Time | Notes |
|----------|----------------|-------|
| PostgreSQL | 2-3 minutes | Window function on 10M records |
| **Greenplum** | **10-20 seconds** | Parallel window functions per segment |

**Speed-up: 10-15x** ‚ö°

---

## üí∞ Cost Analysis

### Infrastructure Costs

#### PostgreSQL (—Ç–µ–∫—É—â–µ–µ):

**Single server:**
- 16 vCPU, 64GB RAM, 1TB SSD
- AWS RDS: ~$500/–º–µ—Å—è—Ü
- DigitalOcean: ~$240/–º–µ—Å—è—Ü
- Self-hosted: ~$100/–º–µ—Å—è—Ü (amortized)

**–° —Ä–µ–ø–ª–∏–∫–∞–º–∏ (+2):**
- Total: ~$1,500/–º–µ—Å—è—Ü (AWS)

---

#### Greenplum (4-node cluster):

**Master node:**
- 8 vCPU, 32GB RAM, 500GB SSD
- Cost: ~$200/–º–µ—Å—è—Ü

**Segment nodes (4x):**
- 16 vCPU, 64GB RAM, 2TB SSD each
- Cost: ~$500/–º–µ—Å—è—Ü √ó 4 = $2,000/–º–µ—Å—è—Ü

**Total cluster:** ~$2,200/–º–µ—Å—è—Ü

**–ò—Ç–æ–≥–æ —Å PostgreSQL (OLTP + OLAP):**
- PostgreSQL OLTP: $500/–º–µ—Å—è—Ü
- Greenplum OLAP: $2,200/–º–µ—Å—è—Ü
- **Total: $2,700/–º–µ—Å—è—Ü**

**–†–∞–∑–Ω–∏—Ü–∞:** +$1,200/–º–µ—Å—è—Ü vs —Ç–æ–ª—å–∫–æ PostgreSQL

---

### –ö–æ–≥–¥–∞ Greenplum –æ–∫—É–ø–∞–µ—Ç—Å—è?

**–¢–æ—á–∫–∞ –æ–∫—É–ø–∞–µ–º–æ—Å—Ç–∏:**

–ï—Å–ª–∏:
- –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã –∑–∞–Ω–∏–º–∞—é—Ç > 10 —á–∞—Å–æ–≤/–Ω–µ–¥–µ–ª—é —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
- 10 hours √ó 4 weeks √ó $50/hour = $2,000/–º–µ—Å—è—Ü
- Greenplum —ç–∫–æ–Ω–æ–º–∏—Ç 80% –≤—Ä–µ–º–µ–Ω–∏
- –≠–∫–æ–Ω–æ–º–∏—è: $1,600/–º–µ—Å—è—Ü

**ROI:** $1,600 - $1,200 = **+$400/–º–µ—Å—è—Ü profit**

**–î–ª—è –ø—Ä–æ–µ–∫—Ç–∞ 1C AI Stack:**
- –°–µ–π—á–∞—Å: –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ (–Ω–µ –æ–∫—É–ø–∞–µ—Ç—Å—è)
- –ü—Ä–∏ 1,000+ users: –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫—Ä–∏—Ç–∏—á–Ω–∞ (–æ–∫—É–ø–∞–µ—Ç—Å—è!)
- –ü—Ä–∏ 10,000+ users: Greenplum –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω

**–í—ã–≤–æ–¥:** Greenplum –Ω—É–∂–µ–Ω –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏, –Ω–µ —Å–µ–π—á–∞—Å.

---

## üéØ Airflow + Greenplum = Powerful Combo

### –ó–∞—á–µ–º –Ω—É–∂–Ω—ã –æ–±–∞?

```
Apache Airflow (Orchestration)
    ‚Üì
–£–ø—Ä–∞–≤–ª—è–µ—Ç ETL pipeline'–∞–º–∏
    ‚Üì
–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ PostgreSQL –≤ Greenplum
    ‚Üì
Greenplum (Analytics)
    ‚Üì
–ë—ã—Å—Ç—Ä—ã–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã
    ‚Üì
BI Dashboards, ML Features, Reports
```

**–ü—Ä–∏–º–µ—Ä –ø–æ–ª–Ω–æ–≥–æ —Å—Ç–µ–∫–∞:**

```mermaid
graph TB
    subgraph "Production App"
        API[FastAPI API]
        PG_OLTP[(PostgreSQL OLTP<br/>Operational data<br/>Real-time writes)]
    end
    
    subgraph "Airflow Orchestration"
        AIRFLOW[Airflow Scheduler]
        
        ETL_DAG["ETL DAG (hourly)<br/>PostgreSQL ‚Üí Greenplum"]
        ML_DAG["ML DAG (daily)<br/>Train on GP data"]
        REPORT_DAG["Report DAG (daily)<br/>Generate BI reports"]
    end
    
    subgraph "Analytics Platform"
        GP_CLUSTER[(Greenplum Cluster<br/>16 segments<br/>Analytical data<br/>Historical + aggregated)]
        
        MATERIALIZED["Materialized Views:<br/>- hourly_stats<br/>- daily_metrics<br/>- user_features"]
    end
    
    subgraph "Visualization"
        GRAFANA[Grafana<br/>Operational metrics<br/>Source: PostgreSQL]
        
        POWERBI[Power BI / Tableau<br/>Business analytics<br/>Source: Greenplum]
    end

    API --> PG_OLTP
    
    PG_OLTP -.CDC/Logical Replication.-> AIRFLOW
    
    AIRFLOW --> ETL_DAG
    AIRFLOW --> ML_DAG
    AIRFLOW --> REPORT_DAG
    
    ETL_DAG -.Incremental load.-> GP_CLUSTER
    
    GP_CLUSTER --> MATERIALIZED
    
    ML_DAG -.Read features.-> GP_CLUSTER
    REPORT_DAG -.Generate reports.-> GP_CLUSTER
    
    PG_OLTP --> GRAFANA
    GP_CLUSTER --> POWERBI

    style AIRFLOW fill:#ff6b6b
    style GP_CLUSTER fill:#00a86b
    style PG_OLTP fill:#336791
```

**–†–æ–ª—å –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞:**

1. **PostgreSQL** - –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (OLTP)
   - Users, sessions, real-time requests
   - Fast writes, fast lookups by ID
   - Small tables (<10M rows)

2. **Airflow** - –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è ETL
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Greenplum
   - ML pipeline'—ã
   - Reporting tasks

3. **Greenplum** - –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ (OLAP)
   - Historical data (–º–∏–ª–ª–∏–∞—Ä–¥—ã –∑–∞–ø–∏—Å–µ–π)
   - Complex aggregations
   - ML feature engineering
   - BI reporting

4. **BI Tools** - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
   - Power BI/Tableau –ø–æ–¥–∫–ª—é—á–µ–Ω—ã –∫ Greenplum
   - Fast queries –±–ª–∞–≥–æ–¥–∞—Ä—è GP

---

## üìã –ü–æ–ª–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ 3 —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | PostgreSQL | Greenplum | Apache Airflow |
|----------------|------------|-----------|----------------|
| **–¢–∏–ø** | OLTP Database | OLAP Database | Workflow Orchestrator |
| **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ** | –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ | –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ | –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∞–º–∏ |
| **Data Model** | Relational (ACID) | Relational (MPP) | N/A (orchestration) |
| **Storage** | Row-oriented | Column-oriented | N/A |
| **–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ** | Vertical (bigger server) | Horizontal (more nodes) | Horizontal (more workers) |
| **Concurrent writes** | Excellent (1000s TPS) | Limited (batch loads) | N/A |
| **Concurrent reads** | Good (100s) | Excellent (1000s) | N/A |
| **Query latency** | ms (point queries) | seconds (aggregations) | N/A |
| **Data size** | < 1TB sweet spot | 10TB+ sweet spot | N/A |
| **Compression** | Low (2x) | High (10x) | N/A |
| **Use in project** | Primary database | Analytics database | ETL orchestration |
| **Priority** | üî¥ Critical (already used) | üü° Important (future) | üü° Important (future) |
| **When to add** | ‚úÖ Already | When 1TB+ data | After launch (Q1 2025) |

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ

### –≠—Ç–∞–ø 1: –°–µ–π—á–∞—Å (–¥–æ launch)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PostgreSQL OLTP    ‚îÇ
‚îÇ   ----------------   ‚îÇ
‚îÇ   - All data         ‚îÇ
‚îÇ   - OLTP + Analytics ‚îÇ
‚îÇ   - Size: ~10GB      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è:**
- < 1,000 users
- < 1M requests/day
- < 100GB data

**–ü—Ä–æ–±–ª–µ–º –Ω–µ—Ç!** ‚úÖ

---

### –≠—Ç–∞–ø 2: –ü–æ—Å–ª–µ launch (1K-10K users) - Q1-Q2 2025

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Apache Airflow (–¥–æ–±–∞–≤–∏—Ç—å)      ‚îÇ
‚îÇ     ----------------------          ‚îÇ
‚îÇ     - ML Pipeline                   ‚îÇ
‚îÇ     - Data Sync                     ‚îÇ
‚îÇ     - Maintenance                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PostgreSQL OLTP    ‚îÇ
‚îÇ   ----------------   ‚îÇ
‚îÇ   - Operational data ‚îÇ
‚îÇ   - Size: ~100GB     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è:**
- 1,000-10,000 users
- 1M-10M requests/day
- 100GB-500GB data

**Airflow —É–ø—Ä–∞–≤–ª—è–µ—Ç –≤—Å–µ–º–∏ pipeline'–∞–º–∏** ‚úÖ

---

### –≠—Ç–∞–ø 3: –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ (10K+ users) - Q3-Q4 2025

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Apache Airflow Orchestration        ‚îÇ
‚îÇ        ---------------------------         ‚îÇ
‚îÇ        - ETL: PostgreSQL ‚Üí Greenplum       ‚îÇ
‚îÇ        - ML Pipeline on Greenplum data     ‚îÇ
‚îÇ        - Reporting pipelines               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PostgreSQL OLTP  ‚îÇ    ‚îÇ  Greenplum OLAP  ‚îÇ
‚îÇ ---------------  ‚îÇ    ‚îÇ  ---------------  ‚îÇ
‚îÇ - Operational    ‚îÇ    ‚îÇ - Analytics      ‚îÇ
‚îÇ - Real-time      ‚îÇ    ‚îÇ - Historical     ‚îÇ
‚îÇ - Size: ~200GB   ‚îÇ    ‚îÇ - ML Features    ‚îÇ
‚îÇ                  ‚îÇ    ‚îÇ - Size: ~2TB     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–î–ª—è:**
- 10,000-100,000+ users
- 10M-100M requests/day
- 500GB-5TB data

**Greenplum –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∞–Ω–∞–ª–∏—Ç–∏–∫—É** ‚úÖ

---

## üí° –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ Use Cases –¥–ª—è Greenplum

### Use Case 1: User Behavior Analytics

**–ó–∞–ø—Ä–æ—Å:** –ü–æ–Ω—è—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∑–∞ 6 –º–µ—Å—è—Ü–µ–≤ –ø–æ –∫–∞–∂–¥–æ–º—É —á–∞—Å—É –Ω–µ–¥–µ–ª–∏.

```sql
-- PostgreSQL: ~10 minutes –Ω–∞ 50M –∑–∞–ø–∏—Å–µ–π
-- Greenplum: ~20 seconds

SELECT 
    EXTRACT(DOW FROM created_at) as day_of_week,
    EXTRACT(HOUR FROM created_at) as hour_of_day,
    COUNT(*) as requests,
    COUNT(DISTINCT user_id) as active_users,
    AVG(execution_time_ms) as avg_latency,
    ARRAY_AGG(DISTINCT JSONB_EXTRACT_PATH_TEXT(response, 'agent_used')) as agents_used,
    -- Cohort analysis
    SUM(CASE WHEN user_registered_at >= created_at - INTERVAL '7 days' THEN 1 ELSE 0 END) as new_user_requests,
    SUM(CASE WHEN user_registered_at < created_at - INTERVAL '30 days' THEN 1 ELSE 0 END) as power_user_requests
FROM requests r
JOIN users u ON r.user_id = u.id
WHERE r.created_at >= NOW() - INTERVAL '6 months'
GROUP BY 1, 2
ORDER BY 1, 2;

-- Result: 7 days √ó 24 hours = 168 rows
-- Heavy aggregation!
```

**Greenplum:** –ò–¥–µ–∞–ª–µ–Ω –¥–ª—è —Ç–∞–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (30x –±—ã—Å—Ç—Ä–µ–µ)

---

### Use Case 2: ML Feature Store

**–ó–∞–¥–∞—á–∞:** –ì–µ–Ω–µ—Ä–∞—Ü–∏—è 100+ features –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è churn prediction.

```sql
CREATE TABLE ml_features.user_features_v1 AS
SELECT 
    u.id as user_id,
    
    -- –ë–∞–∑–æ–≤—ã–µ features
    COUNT(r.id) as total_requests,
    AVG(r.execution_time_ms) as avg_latency,
    STDDEV(r.execution_time_ms) as latency_stddev,
    
    -- –í—Ä–µ–º–µ–Ω–Ω—ã–µ features
    EXTRACT(DAY FROM NOW() - MAX(r.created_at)) as days_since_last_request,
    EXTRACT(DAY FROM MAX(r.created_at) - MIN(r.created_at)) as user_lifetime_days,
    COUNT(DISTINCT DATE(r.created_at)) as active_days,
    
    -- Usage pattern features
    MODE() WITHIN GROUP (ORDER BY EXTRACT(HOUR FROM r.created_at)) as most_active_hour,
    MODE() WITHIN GROUP (ORDER BY EXTRACT(DOW FROM r.created_at)) as most_active_day,
    
    -- Agent usage features
    COUNT(*) FILTER (WHERE response->>'agent_used' = 'Developer') as dev_agent_count,
    COUNT(*) FILTER (WHERE response->>'agent_used' = 'Architect') as arch_agent_count,
    -- ... –µ—â–µ 6 –∞–≥–µ–Ω—Ç–æ–≤
    
    -- Quality features
    AVG((response->>'confidence')::FLOAT) as avg_confidence,
    COUNT(*) FILTER (WHERE status = 'error') as error_count,
    COUNT(*) FILTER (WHERE execution_time_ms > 5000) as slow_requests,
    
    -- Sequence features (last 10 requests)
    ARRAY_AGG(query ORDER BY created_at DESC LIMIT 10) as recent_queries,
    ARRAY_AGG(execution_time_ms ORDER BY created_at DESC LIMIT 10) as recent_latencies,
    
    -- Growth features
    COUNT(*) FILTER (WHERE created_at >= NOW() - INTERVAL '7 days') as requests_last_7d,
    COUNT(*) FILTER (WHERE created_at >= NOW() - INTERVAL '30 days') as requests_last_30d,
    
    -- ... –µ—â–µ 70+ features
FROM users u
LEFT JOIN requests r ON u.id = r.user_id
WHERE r.created_at >= NOW() - INTERVAL '1 year'
GROUP BY u.id;

-- PostgreSQL: 15-30 minutes (100 features √ó 10K users √ó 100M requests)
-- Greenplum: 1-3 minutes (parallel processing)

-- Speed-up: 10-30x
```

**Greenplum Feature Store:**
- –û–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∫–∞–∂–¥—ã–π —á–∞—Å (via Airflow DAG)
- ML –º–æ–¥–µ–ª–∏ —á–∏—Ç–∞—é—Ç –æ—Ç—Ç—É–¥–∞ features
- –ë—ã—Å—Ç—Ä–æ–µ —á—Ç–µ–Ω–∏–µ –¥–ª—è inference

---

### Use Case 3: BI Reporting

**–ó–∞–¥–∞—á–∞:** –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π executive dashboard.

```sql
-- Executive Dashboard (10+ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤)

-- 1. Daily Active Users trend (last 30 days)
SELECT DATE(created_at), COUNT(DISTINCT user_id) FROM requests 
WHERE created_at >= NOW() - INTERVAL '30 days' GROUP BY 1;

-- 2. Top 20 users by usage
SELECT user_id, COUNT(*) FROM requests 
WHERE created_at >= NOW() - INTERVAL '30 days' GROUP BY 1 ORDER BY 2 DESC LIMIT 20;

-- 3. AI Agent usage distribution
SELECT agent, COUNT(*), AVG(latency) FROM agent_logs 
WHERE ... GROUP BY 1;

-- 4. Revenue by plan (if paid)
SELECT plan, SUM(amount), COUNT(DISTINCT user_id) FROM subscriptions ...;

-- 5. API endpoint performance
SELECT endpoint, COUNT(*), AVG(latency), P95(latency) FROM requests ...;

-- 6. Error analysis
SELECT error_type, COUNT(*), affected_users FROM errors ...;

-- 7. Geographic distribution
SELECT country, COUNT(DISTINCT user_id) FROM sessions ...;

-- 8. Feature adoption
SELECT feature, adoption_rate FROM feature_usage ...;

-- ... –µ—â–µ 5 –∑–∞–ø—Ä–æ—Å–æ–≤

-- PostgreSQL: 10 queries √ó 2 min = 20 –º–∏–Ω—É—Ç TOTAL
-- Greenplum: 10 queries √ó 5 sec = 50 —Å–µ–∫—É–Ω–¥ TOTAL
```

**Greenplum + Airflow:**
```python
# DAG –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ reporting
with DAG('executive_dashboard_refresh', schedule_interval='0 8 * * *') as dag:
    
    # Refresh –≤—Å–µ materialized views (parallel!)
    refresh_dau = PostgresOperator(
        task_id='refresh_dau_view',
        postgres_conn_id='greenplum',
        sql='REFRESH MATERIALIZED VIEW mv_daily_active_users;'
    )
    
    refresh_agent_usage = PostgresOperator(
        task_id='refresh_agent_usage',
        sql='REFRESH MATERIALIZED VIEW mv_agent_usage_stats;'
    )
    
    # ... –µ—â–µ 8 views
    
    # Generate dashboard data (after all views refreshed)
    generate_dashboard = PythonOperator(
        task_id='generate_dashboard_json',
        python_callable=export_dashboard_data,
        trigger_rule='none_failed',
    )
    
    # Parallel refresh
    [refresh_dau, refresh_agent_usage, ...] >> generate_dashboard
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** Dashboard –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∑–∞ 1 –º–∏–Ω—É—Ç—É –≤–º–µ—Å—Ç–æ 20!

---

## üìä –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —á—Ç–æ?

### PostgreSQL (OLTP) - –∏—Å–ø–æ–ª—å–∑—É–µ–º –°–ï–ô–ß–ê–° ‚úÖ

**–î–ª—è:**
- ‚úÖ Operational data (users, sessions, live requests)
- ‚úÖ Real-time writes (INSERT/UPDATE –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É)
- ‚úÖ Point lookups (SELECT * FROM users WHERE id = ?)
- ‚úÖ Small-medium aggregations (< 1M rows)
- ‚úÖ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (ACID required)

**–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:** < 500GB

**–¢–µ–∫—É—â–∏–π –ø—Ä–æ–µ–∫—Ç:** –ò–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç!

---

### Greenplum (OLAP) - –¥–æ–±–∞–≤–∏—Ç—å –ü–û–ó–ñ–ï

**–î–ª—è:**
- ‚úÖ Historical analytics (–¥–∞–Ω–Ω—ã–µ –∑–∞ –≥–æ–¥—ã)
- ‚úÖ Complex aggregations (100M+ rows)
- ‚úÖ BI reporting (slow-changing data)
- ‚úÖ ML feature engineering
- ‚úÖ Data Warehouse

**–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:** 1TB - 100TB+

**–ü—Ä–æ–µ–∫—Ç:** –ù—É–∂–µ–Ω –ø—Ä–∏ 10K+ users (—á–µ—Ä–µ–∑ 6-12 –º–µ—Å—è—Ü–µ–≤)

---

### Apache Airflow - –¥–æ–±–∞–≤–∏—Ç—å –°–ö–û–†–û

**–î–ª—è:**
- ‚úÖ ETL pipelines (PostgreSQL ‚Üí Greenplum)
- ‚úÖ ML pipelines (training, evaluation)
- ‚úÖ Data sync –º–µ–∂–¥—É —Å–∏—Å—Ç–µ–º–∞–º–∏
- ‚úÖ Scheduled reporting
- ‚úÖ Maintenance tasks

**–ü—Ä–æ–µ–∫—Ç:** –ü–æ–ª–µ–∑–µ–Ω —É–∂–µ —Å–µ–π—á–∞—Å, –∫—Ä–∏—Ç–∏—á–µ–Ω –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏

---

## üó∫Ô∏è Roadmap –¥–ª—è Data Infrastructure

### Q4 2024 (–°–µ–π—á–∞—Å) - MVP

```
Infrastructure:
- PostgreSQL 15 (OLTP) ‚úÖ
- Neo4j (Graph) ‚úÖ
- Qdrant (Vectors) ‚úÖ
- Elasticsearch (Search) ‚úÖ
- Redis (Cache) ‚úÖ

Analytics:
- Simple views in PostgreSQL ‚úÖ
- Grafana dashboards ‚úÖ

Status: ‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è launch
```

---

### Q1 2025 (After Launch) - Orchestration

```
Add:
+ Apache Airflow
  - ML Training Pipeline
  - Data Sync Pipeline
  - Maintenance Pipeline

Improve:
+ Better monitoring
+ Automated workflows
+ SLA tracking

Users: 100-1,000
Data: 10GB-100GB
Status: ‚úÖ Good for growth
```

---

### Q2-Q3 2025 (Growth) - Analytics Platform

```
Add:
+ Greenplum Cluster (4-16 nodes)
  - Data Warehouse
  - Historical data
  - ML Feature Store

+ BI Tools
  - Power BI / Tableau
  - Connected to Greenplum

+ Enhanced Airflow
  - PostgreSQL ‚Üí Greenplum ETL (hourly)
  - ML on Greenplum data
  - Automated BI reports

Users: 1,000-10,000
Data: 100GB-1TB
Status: ‚úÖ Ready for scale
```

---

### Q4 2025+ (Scale) - Enterprise Analytics

```
Scale:
+ Greenplum 32+ nodes
+ Multi-region deployment
+ Advanced ML on big data
+ Real-time streaming analytics

Users: 10,000-100,000+
Data: 1TB-10TB+
Status: ‚úÖ Enterprise-grade
```

---

## üíª –ü—Ä–∏–º–µ—Ä –º–∏–≥—Ä–∞—Ü–∏–∏: PostgreSQL ‚Üí Greenplum

### –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –≤ Greenplum

```sql
-- PostgreSQL (current)
CREATE TABLE requests (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES users(id),
    query TEXT,
    response JSONB,
    execution_time_ms INTEGER,
    created_at TIMESTAMP
);
CREATE INDEX idx_requests_user_created ON requests(user_id, created_at);

-- Greenplum (analytical copy)
CREATE TABLE requests_analytical (
    id UUID,
    user_id UUID,
    query TEXT,
    response JSONB,
    execution_time_ms INTEGER,
    created_at TIMESTAMP,
    
    -- Denormalized fields (–¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏)
    user_email TEXT,
    user_role TEXT,
    agent_used TEXT,
    query_type TEXT,
    tokens_used INTEGER,
    
    -- Computed fields
    hour_of_day INTEGER,
    day_of_week INTEGER,
    is_weekend BOOLEAN,
    created_date DATE
)
WITH (
    appendoptimized=true,      -- Column storage
    compresstype=zstd,          -- Compression
    compresslevel=5,
    orientation=column          -- Column-oriented!
)
DISTRIBUTED BY (user_id)        -- Distribute by user_id for join optimization
PARTITION BY RANGE (created_at) -- Monthly partitions
(
    START ('2024-01-01'::DATE)
    END ('2025-12-31'::DATE)
    EVERY (INTERVAL '1 month')
);

-- No indexes needed! Column storage handles it.
```

**–†–∞–∑–º–µ—Ä:**
- PostgreSQL (row): 50GB
- Greenplum (column, compressed): **5GB** (10x compression!)

---

### Airflow DAG –¥–ª—è ETL

```python
with DAG(
    'sync_requests_to_greenplum',
    schedule_interval='0 * * * *',  # Hourly
    start_date=datetime(2024, 1, 1),
) as dag:

    # Extract from PostgreSQL (last hour)
    extract = PythonOperator(
        task_id='extract_from_postgres',
        python_callable=extract_last_hour_requests,
    )
    
    # Transform: Denormalize + add computed fields
    transform = PythonOperator(
        task_id='transform_denormalize',
        python_callable=denormalize_and_compute_fields,
    )
    
    # Load to Greenplum (fast COPY)
    load = PythonOperator(
        task_id='load_to_greenplum',
        python_callable=bulk_load_to_gp,
        # Uses COPY FROM for 10-100MB/sec throughput
    )
    
    # Refresh materialized views
    refresh_views = PostgresOperator(
        task_id='refresh_analytical_views',
        postgres_conn_id='greenplum',
        sql="""
            REFRESH MATERIALIZED VIEW mv_hourly_requests;
            REFRESH MATERIALIZED VIEW mv_user_daily_stats;
        """
    )
    
    extract >> transform >> load >> refresh_views
```

**ETL throughput:**
- Extract: ~1M records/min from PostgreSQL
- Transform: ~2M records/min (Python)
- Load to Greenplum: ~5M records/min (COPY)

**Total:** 1 hour of data (10M records) –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∑–∞ ~5 –º–∏–Ω—É—Ç

---

## üé® –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: The Full Stack

```mermaid
graph TB
    subgraph "Users & Applications"
        USERS[End Users<br/>1C Developers]
        ADMIN[Admins & Analysts]
    end
    
    subgraph "Application Layer"
        TG[Telegram Bot]
        API[REST API]
        WEB[Web Portal]
    end
    
    subgraph "OLTP Layer (Real-time)"
        PG_OLTP[(PostgreSQL<br/>Operational DB<br/>Fast writes<br/>Point queries<br/>Size: ~200GB)]
    end
    
    subgraph "Orchestration Layer"
        AIRFLOW["Apache Airflow<br/>Scheduler + Workers<br/>-----------<br/>DAG 1: ML Pipeline<br/>DAG 2: ETL to Greenplum<br/>DAG 3: BI Reports<br/>DAG 4: Maintenance"]
    end
    
    subgraph "OLAP Layer (Analytics)"
        GP_CLUSTER[(Greenplum Cluster<br/>16 segments<br/>Analytical DB<br/>Complex queries<br/>Size: ~2TB)]
        
        MV["Materialized Views:<br/>- hourly_stats<br/>- user_behavior<br/>- agent_performance<br/>- ml_features"]
    end
    
    subgraph "ML Layer"
        ML_TRAIN[Model Training<br/>Features from GP]
        ML_FEATURE_STORE[Feature Store<br/>Greenplum tables]
    end
    
    subgraph "Visualization Layer"
        GRAFANA[Grafana<br/>Operational metrics<br/>PostgreSQL source]
        
        POWERBI[Power BI<br/>Business analytics<br/>Greenplum source]
    end

    USERS --> TG
    USERS --> API
    USERS --> WEB
    
    TG --> PG_OLTP
    API --> PG_OLTP
    WEB --> PG_OLTP
    
    PG_OLTP -.CDC.-> AIRFLOW
    
    AIRFLOW -.ETL Hourly.-> GP_CLUSTER
    AIRFLOW -.ML Daily.-> ML_TRAIN
    AIRFLOW -.Reports Daily.-> POWERBI
    
    GP_CLUSTER --> MV
    MV --> ML_FEATURE_STORE
    
    ML_FEATURE_STORE --> ML_TRAIN
    
    PG_OLTP --> GRAFANA
    GP_CLUSTER --> POWERBI
    
    ADMIN --> GRAFANA
    ADMIN --> POWERBI
    ADMIN --> AIRFLOW

    style PG_OLTP fill:#336791
    style GP_CLUSTER fill:#00a86b
    style AIRFLOW fill:#ff6b6b
```

**–¢—Ä–∏ –∫–∏—Ç–∞:**
1. **PostgreSQL** - –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (fast writes)
2. **Greenplum** - –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ (fast complex reads)
3. **Airflow** - –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è ETL –º–µ–∂–¥—É –Ω–∏–º–∏

---

## üìã –ò—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ 3 —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π

### –ú–∞—Ç—Ä–∏—Ü–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

| –ó–∞–¥–∞—á–∞ | PostgreSQL | Greenplum | Airflow | –õ—É—á—à–∏–π –≤—ã–±–æ—Ä |
|--------|------------|-----------|---------|--------------|
| User CRUD operations | ‚úÖ Perfect | ‚ùå Not suitable | N/A | PostgreSQL |
| Real-time requests logging | ‚úÖ Perfect | ‚ùå Too slow | N/A | PostgreSQL |
| Point queries (by ID) | ‚úÖ Perfect | ‚ö†Ô∏è Slower | N/A | PostgreSQL |
| Simple aggregations (< 1M rows) | ‚úÖ Good | ‚ö†Ô∏è Overkill | N/A | PostgreSQL |
| Complex aggregations (10M+ rows) | ‚ö†Ô∏è Slow | ‚úÖ Perfect | N/A | Greenplum |
| Time-series analytics | ‚ö†Ô∏è Slow | ‚úÖ Perfect | N/A | Greenplum |
| ML feature engineering | ‚ö†Ô∏è Very slow | ‚úÖ Perfect | N/A | Greenplum |
| BI reporting (100M+ rows) | ‚ùå Too slow | ‚úÖ Perfect | N/A | Greenplum |
| ETL orchestration | N/A | N/A | ‚úÖ Perfect | Airflow |
| ML pipeline orchestration | N/A | N/A | ‚úÖ Perfect | Airflow |
| Workflow visualization | N/A | N/A | ‚úÖ Perfect | Airflow |
| Task scheduling | ‚ö†Ô∏è pg_cron | N/A | ‚úÖ Perfect | Airflow |

---

## üí° –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### Hybrid Architecture (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

**3-tier –ø–æ–¥—Ö–æ–¥:**

```
Tier 1: OLTP (PostgreSQL)
- Operational data
- Real-time transactions
- Size: < 500GB

Tier 2: Orchestration (Airflow)
- ETL pipelines
- ML pipelines
- Task scheduling

Tier 3: OLAP (Greenplum)
- Analytics
- BI reporting
- Data Warehouse
- Size: 1TB-100TB
```

---

### Timeline –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

#### –°–µ–π—á–∞—Å (Q4 2024):
```
‚úÖ PostgreSQL only
Status: Sufficient –¥–ª—è < 1K users
```

#### Q1 2025:
```
+ Apache Airflow
Status: Better workflows –∏ automation
```

#### Q3 2025:
```
+ Greenplum (–µ—Å–ª–∏ 10K+ users –∏ 500GB+ data)
Status: Enterprise-grade analytics
```

---

## üí∞ Cost-Benefit –¥–ª—è Greenplum

### –ö–æ–≥–¥–∞ –ù–ï –Ω—É–∂–µ–Ω Greenplum:

- < 10,000 users
- < 10M requests/day
- < 500GB data
- –ü—Ä–æ—Å—Ç—ã–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã
- –ë—é–¥–∂–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω

**–í—ã–≤–æ–¥:** **–ù–ï –ù–£–ñ–ï–ù –°–ï–ô–ß–ê–°** –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ 1C AI Stack ‚úÖ

---

### –ö–æ–≥–¥–∞ –ù–£–ñ–ï–ù Greenplum:

- 10,000+ users
- 100M+ requests/day
- 1TB+ data
- –°–ª–æ–∂–Ω—ã–µ BI dashboard'—ã
- ML –Ω–∞ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–∞—Ö
- –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–∫–æ—Ä–æ—Å—Ç–∏ analytics queries

**–í—ã–≤–æ–¥:** –ù—É–∂–µ–Ω –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏ (6-12 –º–µ—Å—è—Ü–µ–≤)

---

## ‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–µ –≤—ã–≤–æ–¥—ã

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –≤–Ω–µ–¥—Ä–µ–Ω–∏—è:

**1. Apache Airflow** - üî¥ HIGH Priority
- **–ö–æ–≥–¥–∞:** Q1 2025 (–ø–æ—Å–ª–µ launch)
- **–ó–∞—á–µ–º:** Orchestration –≤—Å–µ—Ö pipeline'–æ–≤
- **ROI:** 550% –≤ –≥–æ–¥ 1
- **Cost:** $5,760 –≥–æ–¥ 1 (one-time + infrastructure)
- **Benefit:** $37,500/year (time savings)

**2. Greenplum** - üü° MEDIUM Priority
- **–ö–æ–≥–¥–∞:** Q3 2025 (–ø—Ä–∏ 10K+ users)
- **–ó–∞—á–µ–º:** Fast analytics –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- **ROI:** 15-30% –ø—Ä–∏ 1TB+ data
- **Cost:** $26,400/year (infrastructure)
- **Benefit:** $30,000+/year (analyst time savings + better insights)

**3. –¢–µ–∫—É—â–∏–π PostgreSQL** - ‚úÖ KEEP
- **–ö–æ–≥–¥–∞:** –í—Å–µ–≥–¥–∞ (OLTP)
- **–ó–∞—á–µ–º:** Operational database
- **–°—Ç–∞—Ç—É—Å:** –û—Ç–ª–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç

---

### Recommended Architecture Evolution:

```
Phase 1 (Now - Q4 2024):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PostgreSQL    ‚îÇ ‚Üê Single database
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Phase 2 (Q1 2025):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PostgreSQL    ‚îÇ ‚Üê OLTP
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üï
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Airflow       ‚îÇ ‚Üê Orchestration
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Phase 3 (Q3 2025):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PostgreSQL    ‚îÇ ‚Üê OLTP
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üï
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Airflow       ‚îÇ ‚Üê Orchestration (ETL)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üï
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Greenplum     ‚îÇ ‚Üê OLAP
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –°–µ–π—á–∞—Å (Q4 2024):
‚úÖ **–û—Å—Ç–∞–≤–∏—Ç—å PostgreSQL** - –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç  
‚ùå **–ù–ï –≤–Ω–µ–¥—Ä—è—Ç—å Greenplum** - –ø—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω–æ  
‚≠ï **–ò–∑—É—á–∏—Ç—å Airflow** - –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å—Å—è

### Q1 2025:
‚úÖ **–í–Ω–µ–¥—Ä–∏—Ç—å Airflow** - –¥–ª—è ML –∏ ETL pipeline'–æ–≤  
‚≠ï **–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å —Ä–æ—Å—Ç –¥–∞–Ω–Ω—ã—Ö** - –≥–æ—Ç–æ–≤–∏—Ç—å—Å—è –∫ Greenplum  
‚ùå **–ü–æ–∫–∞ –Ω–µ Greenplum** - –µ—â–µ —Ä–∞–Ω–æ

### Q3 2025 (–µ—Å–ª–∏ —Ä–æ—Å—Ç –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—Å—è):
‚úÖ **–í–Ω–µ–¥—Ä–∏—Ç—å Greenplum** - –¥–ª—è analytics  
‚úÖ **Airflow –¥–ª—è ETL** - PostgreSQL ‚Üí Greenplum  
‚úÖ **BI Tools** - Power BI/Tableau

---

## üìä –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è)

| –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –¢–∏–ø | –ö–æ–≥–¥–∞ –≤–Ω–µ–¥—Ä—è—Ç—å | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç | ROI | –°–ª–æ–∂–Ω–æ—Å—Ç—å |
|------------|-----|----------------|-----------|-----|-----------|
| **PostgreSQL** | OLTP DB | ‚úÖ Already | üî¥ Critical | N/A | üü¢ Low |
| **Apache Airflow** | Workflow Orchestrator | Q1 2025 | üü° High | 550% | üü° Medium |
| **Greenplum** | OLAP DB | Q3 2025 (–ø—Ä–∏ 10K+ users) | üü¢ Medium | 15-30% | üî¥ High |

---

**–ò—Ç–æ–≥–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**

1. **PostgreSQL** - ‚úÖ Keep (already perfect for OLTP)
2. **Airflow** - ‚úÖ Add in Q1 2025 (high ROI, important for workflows)
3. **Greenplum** - ‚è≥ Consider in Q3 2025 (when data grows to 1TB+)

**Focus now:** Apache Airflow (–±–æ–ª–µ–µ –∞–∫—Ç—É–∞–ª–µ–Ω –∏ –Ω—É–∂–µ–Ω —Ä–∞–Ω—å—à–µ)

---

**–°–æ–∑–¥–∞–Ω–æ:** 2024-11-05  
**–°—Ç–∞—Ç—É—Å:** –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç (–Ω–µ –∫–æ–º–º–∏—Ç–∏—Ç—Å—è)  
**–î–ª—è:** –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è

