# Интеграционные тесты для end-to-end потоков данных

Данная директория содержит комплексные интеграционные тесты для проверки end-to-end потоков данных между всеми компонентами системы AI Assistant для 1C разработки.

## Структура тестов

### 1. End-to-End потоки данных (`test_end_to_end_flows.py`)

#### Покрываемые сценарии:

**1.1 UX/UI → API Gateway → AI Assistant → Risk Management → ML System**
- Полный поток от пользовательского запроса до машинного обучения
- Проверка маршрутизации через API Gateway
- Анализ требований AI Assistant
- Оценка рисков системой управления рисками
- Предсказания ML системы

**1.2 ML System → Metrics Collection → Analytics Dashboard**
- Поток данных от ML предсказаний до визуализации
- Сбор и обработка метрик производительности
- Генерация аналитических панелей
- Создание интерактивных визуализаций

**1.3 AI Assistant → ML Prediction → Risk Assessment → Recommendations**
- Интеллектуальный анализ проектов
- Интеграция между AI, ML и системой рисков
- Генерация рекомендаций на основе комплексного анализа

### 2. Тесты производительности и надежности

#### 2.1 Производительность (`TestPerformanceAndReliability`)
- **Конкурентные пользовательские потоки**: Тестирование системы под нагрузкой 10+ параллельных пользователей
- **Устойчивость к всплескам нагрузки**: Тестирование при 50+ запросах в секунду в течение 30 секунд
- **Согласованность данных**: Проверка целостности данных между компонентами при высокой нагрузке
- **Восстановление после отказов**: Тестирование поведения системы при сбоях компонентов

## Конфигурация и фикстуры

### Основные фикстуры (`conftest.py`)

- **`audit_logger`**: Детальное логирование всех этапов тестирования
- **`integration_test_config`**: Конфигурация таймаутов и порогов производительности
- **`system_state_simulator`**: Симуляция состояния системы для тестирования
- **`data_consistency_checker`**: Проверка согласованности данных между компонентами
- **`load_test_executor`**: Исполнитель нагрузочных тестов

### Мок-компоненты

- **`mock_ux_ui_component`**: Имитация пользовательского интерфейса
- **`mock_api_gateway`**: Имитация API Gateway с аутентификацией и маршрутизацией
- **`mock_ai_assistant`**: Имитация AI ассистента с анализом требований
- **`mock_risk_management`**: Имитация системы управления рисками
- **`mock_ml_system`**: Имитация ML системы предсказаний
- **`mock_metrics_collector`**: Имитация системы сбора метрик
- **`mock_analytics_dashboard`**: Имитация аналитической панели

## Запуск тестов

### Базовый запуск
```bash
# Запуск всех интеграционных тестов
pytest src/tests/integration/ -v

# Запуск только end-to-end тестов
pytest src/tests/integration/test_end_to_end_flows.py -v

# Запуск тестов производительности
pytest src/tests/integration/ -m performance -v
```

### Запуск с параметрами
```bash
# Запуск с увеличенным таймаутом
pytest src/tests/integration/ --timeout=300 -v

# Запуск с детальным выводом
pytest src/tests/integration/ -v -s --tb=long

# Запуск только медленных тестов
pytest src/tests/integration/ -m slow -v
```

### Запуск конкретного теста
```bash
# Тест полного UX/UI потока
pytest src/tests/integration/test_end_to_end_flows.py::TestEndToEndDataFlows::test_ux_ui_to_ml_system_complete_flow -v

# Тест производительности конкурентных потоков
pytest src/tests/integration/test_end_to_end_flows.py::TestPerformanceAndReliability::test_concurrent_user_flows_performance -v

# Тест восстановления после сбоев
pytest src/tests/integration/test_end_to_end_flows.py::TestPerformanceAndReliability::test_recovery_after_component_failure -v
```

## Критерии качества

### Производительность
- **Время отклика end-to-end потока**: < 5 секунд
- **Среднее время отклика компонентов**: < 1 секунда
- **Пропускная способность**: > 100 запросов/секунду
- **Время восстановления после сбоя**: < 10 секунд

### Надежность
- **Успешность запросов**: > 90%
- **Согласованность данных**: > 95%
- **Устойчивость к нагрузке**: 10+ параллельных пользователей
- **Коэффициент восстановления**: > 80%

### Функциональность
- **Покрытие компонентов**: 100% основных компонентов системы
- **Валидация данных**: Полная проверка структуры и целостности
- **Обработка ошибок**: Корректная обработка всех типов ошибок
- **Интеграционные сценарии**: Все ключевые пользовательские сценарии

## Логирование и отчетность

### Аудит тестирования
Все тесты ведут детальный аудит в файле `integration_logs/end_to_end_tests.log`:

```json
{
  "level": "TEST_START",
  "test": "test_name",
  "params": {...},
  "timestamp": "2025-10-30T12:01:36Z"
}
```

### Метрики производительности
Собираются следующие метрики:
- Время отклика каждого компонента
- Общая пропускная способность системы
- Коэффициент успешности запросов
- Потребление ресурсов (CPU, память)
- Согласованность данных между компонентами

## Добавление новых тестов

### Структура нового теста
```python
@pytest.mark.asyncio
@pytest.mark.integration
async def test_new_integration_flow(
    mock_component_1,
    mock_component_2, 
    audit_logger
):
    """Описание нового интеграционного теста."""
    test_name = "new_integration_flow"
    params = {"test_type": "integration"}
    
    audit_logger.log_test_start(test_name, params)
    
    try:
        # Выполнение тестовых шагов
        result_1 = await mock_component_1.perform_action()
        result_2 = await mock_component_2.process_data(result_1)
        
        # Проверки результатов
        assert result_2["status"] == "success"
        
        audit_logger.log_test_result(
            test_name, "SUCCESS", duration, details
        )
        
    except Exception as e:
        audit_logger.log_error(test_name, e, params)
        raise
```

### Добавление нового мок-компонента
```python
@pytest.fixture
def mock_new_component():
    """Мок нового компонента системы."""
    component_mock = AsyncMock()
    component_mock.perform_action.return_value = {
        "status": "success",
        "data": {"result": "expected"}
    }
    return component_mock
```

## Расширение тестового покрытия

### Новые сценарии
Для добавления новых сценариев:

1. **Определите поток данных** между компонентами
2. **Создайте мок-компоненты** для имитации внешних систем
3. **Настройте тестовые данные** в фикстурах
4. **Реализуйте проверки** производительности и надежности
5. **Добавьте логирование** всех промежуточных шагов

### Критерии включения в тестовый набор
- Критически важная бизнес-логика
- Интеграция между основными компонентами
- Сценарии с высокими требованиями к производительности
- Восстановление после отказов системы
- Согласованность данных между компонентами

## Устранение неполадок

### Часто встречающиеся проблемы

**1. Таймауты тестов**
```bash
# Увеличение таймаута для конкретного теста
pytest src/tests/integration/ --timeout=600 -v
```

**2. Недостаточно ресурсов для нагрузочного тестирования**
- Уменьшите количество параллельных запросов в фикстуре `load_test_scenarios`
- Увеличьте интервалы между запросами

**3. Неконсистентность мок-данных**
- Проверьте соответствие структур данных между мок-компонентами
- Убедитесь в корректности тестовых данных

**4. Проблемы с логированием**
- Проверьте права доступа к директории `integration_logs/`
- Убедитесь в корректности путей к файлам логов

### Диагностика проблем

**Включение детального вывода:**
```bash
pytest src/tests/integration/ -v -s --tb=long --capture=no
```

**Проверка конфигурации:**
```python
# Добавьте в тест для диагностики
print(f"Тестовая конфигурация: {integration_test_config}")
print(f"Состояние системы: {system_state_simulator.get_system_health()}")
```

## Рекомендации по разработке

1. **Изоляция тестов**: Каждый тест должен быть независимым
2. **Чистые фикстуры**: Используйте `@pytest.fixture(scope="function")` для изоляции
3. **Описательные имена**: Используйте понятные имена тестов и параметров
4. **Покрытие граничных случаев**: Тестируйте как успешные, так и ошибочные сценарии
5. **Документирование**: Подробно документируйте сложные тестовые сценарии
6. **Производительность**: Следите за временем выполнения тестов
7. **Надежность**: Тестируйте восстановление после различных типов сбоев

## Заключение

Данный набор интеграционных тестов обеспечивает комплексную проверку всей системы AI Assistant для 1C разработки. Тесты покрывают как функциональные требования, так и нефункциональные характеристики производительности и надежности.

Регулярное выполнение этих тестов позволяет:
- Обнаруживать регрессии в интеграции компонентов
- Обеспечивать соблюдение требований производительности
- Подтверждать надежность системы в различных условиях
- Поддерживать качество при развитии функциональности