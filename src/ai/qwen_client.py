"""
Qwen3-Coder Client - Real integration with Ollama
Stage 2: AI Integration (REAL IMPLEMENTATION)
"""

import aiohttp
import logging
from typing import Dict, Any, Optional, List
import json

logger = logging.getLogger(__name__)


class QwenCoderClient:
    """Client for Qwen3-Coder via Ollama"""
    
    def __init__(self, 
                 ollama_url: str = "http://localhost:11434",
                 model: str = "qwen2.5-coder:7b"):
        """
        Initialize Qwen3-Coder client
        
        Args:
            ollama_url: Ollama server URL
            model: Model name (qwen2.5-coder:7b or qwen2.5-coder:32b)
        """
        self.ollama_url = ollama_url
        self.model = model
        self.timeout = aiohttp.ClientTimeout(total=60)
    
    async def check_model_loaded(self) -> bool:
        """Check if model is loaded in Ollama"""
        try:
            async with aiohttp.ClientSession(timeout=self.timeout) as session:
                async with session.get(f"{self.ollama_url}/api/tags") as response:
                    if response.status == 200:
                        data = await response.json()
                        models = [m['name'] for m in data.get('models', [])]
                        return self.model in models
        except Exception as e:
            logger.error(f"Error checking model: {e}")
        return False
    
    async def generate_code(self, 
                           prompt: str, 
                           context: Optional[Dict[str, Any]] = None,
                           temperature: float = 0.7,
                           max_tokens: int = 2000) -> Dict[str, Any]:
        """
        Generate BSL code based on prompt
        
        Args:
            prompt: Description of what to generate
            context: Additional context (module, configuration, etc.)
            temperature: Creativity (0-1)
            max_tokens: Maximum response length
            
        Returns:
            Dictionary with generated code and metadata
        """
        try:
            # Build full prompt
            full_prompt = self._build_prompt(prompt, context)
            
            async with aiohttp.ClientSession(timeout=self.timeout) as session:
                async with session.post(
                    f"{self.ollama_url}/api/generate",
                    json={
                        "model": self.model,
                        "prompt": full_prompt,
                        "stream": False,
                        "options": {
                            "temperature": temperature,
                            "num_predict": max_tokens
                        }
                    }
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        return {
                            'code': self._extract_code(data['response']),
                            'full_response': data['response'],
                            'model': self.model,
                            'tokens': data.get('eval_count', 0)
                        }
                    else:
                        logger.error(f"Ollama error: {response.status}")
                        return {'error': f'HTTP {response.status}'}
                        
        except Exception as e:
            logger.error(f"Code generation error: {e}")
            return {'error': str(e)}
    
    async def optimize_code(self, 
                           code: str,
                           context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Optimize existing BSL code
        
        Args:
            code: Original BSL code
            context: Additional context (dependencies, etc.)
            
        Returns:
            Dictionary with optimized code and explanation
        """
        prompt = f"""Оптимизируй этот код на языке BSL (1С:Предприятие):

```bsl
{code}
```

Требования:
- Улучши производительность
- Улучши читаемость
- Следуй best practices 1С
- Сохрани функциональность
- Добавь комментарии

Верни:
1. Оптимизированный код
2. Список изменений
3. Объяснение улучшений"""

        if context and context.get('dependencies'):
            prompt += f"\n\nЗависимости функции:\n{context['dependencies']}"
        
        result = await self.generate_code(prompt, context)
        
        if 'error' not in result:
            # Parse optimization result
            response = result['full_response']
            
            return {
                'optimized_code': self._extract_code(response),
                'explanation': self._extract_explanation(response),
                'improvements': self._extract_improvements(response),
                'model': self.model
            }
        else:
            return result
    
    async def explain_code(self, code: str) -> Dict[str, Any]:
        """
        Explain BSL code
        
        Args:
            code: BSL code to explain
            
        Returns:
            Explanation dictionary
        """
        prompt = f"""Объясни этот код на языке BSL (1С:Предприятие):

```bsl
{code}
```

Объясни:
1. Что делает код
2. Как работает алгоритм
3. Какие API 1С используются
4. Возможные проблемы
5. Рекомендации по улучшению"""

        result = await self.generate_code(prompt)
        
        if 'error' not in result:
            return {
                'explanation': result['full_response'],
                'model': self.model
            }
        else:
            return result
    
    async def generate_function(self,
                               description: str,
                               function_name: str,
                               parameters: List[Dict[str, str]],
                               return_type: Optional[str] = None) -> Dict[str, Any]:
        """
        Generate specific function
        
        Args:
            description: What function should do
            function_name: Name for the function
            parameters: List of parameters with types
            return_type: Return type
            
        Returns:
            Generated function code
        """
        params_str = ", ".join([
            f"{p['name']}" + (f" // {p.get('type', '')}" if p.get('type') else "")
            for p in parameters
        ])
        
        prompt = f"""Создай функцию на языке BSL (1С:Предприятие):

Имя: {function_name}
Параметры: {params_str}
{f'Возвращает: {return_type}' if return_type else ''}

Описание:
{description}

Требования:
- Следуй стандартам кодирования 1С
- Добавь комментарии
- Обработай ошибки
- Оптимизируй производительность

Верни только код функции."""

        result = await self.generate_code(prompt)
        
        if 'error' not in result:
            return {
                'code': result['code'],
                'full_response': result['full_response'],
                'function_name': function_name
            }
        else:
            return result
    
    def _build_prompt(self, prompt: str, context: Optional[Dict] = None) -> str:
        """Build full prompt with context"""
        full_prompt = "Ты эксперт по разработке на платформе 1С:Предприятие.\n\n"
        
        if context:
            if context.get('configuration'):
                full_prompt += f"Конфигурация: {context['configuration']}\n"
            if context.get('module'):
                full_prompt += f"Модуль: {context['module']}\n"
            if context.get('object_type'):
                full_prompt += f"Тип объекта: {context['object_type']}\n"
            full_prompt += "\n"
        
        full_prompt += prompt
        
        return full_prompt
    
    def _extract_code(self, response: str) -> str:
        """Extract code from response"""
        # Try to find code blocks
        if "```" in response:
            # Extract from markdown code block
            parts = response.split("```")
            if len(parts) >= 2:
                code_block = parts[1]
                # Remove language identifier if present
                lines = code_block.strip().split('\n')
                if lines[0].lower() in ['bsl', '1c', 'onec']:
                    return '\n'.join(lines[1:])
                return code_block.strip()
        
        # Return full response if no code block found
        return response.strip()
    
    def _extract_explanation(self, response: str) -> str:
        """Extract explanation from response"""
        # Try to find explanation section
        if "Объяснение" in response or "Изменения" in response:
            # Find explanation part
            parts = response.split('\n\n')
            for part in parts:
                if any(word in part for word in ['Объяснение', 'Изменения', 'Улучшения']):
                    return part
        
        return "См. полный ответ"
    
    def _extract_improvements(self, response: str) -> List[str]:
        """Extract list of improvements"""
        improvements = []
        
        # Look for numbered or bulleted lists
        lines = response.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith(('1.', '2.', '3.', '-', '•', '*')):
                improvements.append(line.lstrip('123456789.-•* '))
        
        return improvements if improvements else ["См. объяснение"]





