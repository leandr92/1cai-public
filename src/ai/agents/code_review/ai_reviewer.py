"""
AI Code Reviewer - –≥–ª–∞–≤–Ω—ã–π orchestrator
–ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç review
"""

import os
import json
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime

from src.ai.agents.code_review.bsl_parser import BSLParser
from src.ai.agents.code_review.security_scanner import SecurityScanner
from src.ai.agents.code_review.performance_analyzer import PerformanceAnalyzer
from src.ai.agents.code_review.best_practices_checker import BestPracticesChecker

logger = logging.getLogger(__name__)


class AICodeReviewer:
    """
    AI Code Reviewer
    
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π review BSL –∫–æ–¥–∞ —Å:
    - Security scanning
    - Performance analysis
    - Best practices checking
    - AI-powered suggestions
    """
    
    def __init__(self):
        self.parser = BSLParser()
        self.security_scanner = SecurityScanner()
        self.performance_analyzer = PerformanceAnalyzer()
        self.best_practices_checker = BestPracticesChecker()
        
        # LLM –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        self.llm_available = False
        try:
            # TODO: Integration with OpenAI or local LLM
            self.llm_api_key = os.getenv("OPENAI_API_KEY", "")
            if self.llm_api_key:
                self.llm_available = True
        except:
            pass
        
        logger.info("AI Code Reviewer initialized")
    
    async def review_code(
        self,
        code: str,
        filename: str = "unknown.bsl"
    ) -> Dict[str, Any]:
        """
        Review –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        
        Args:
            code: BSL –∫–æ–¥
            filename: –ò–º—è —Ñ–∞–π–ª–∞
        
        Returns:
            –î–µ—Ç–∞–ª—å–Ω—ã–π review —Å issues –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        logger.info(f"Reviewing file: {filename}")
        
        # 1. Parse code
        try:
            ast = self.parser.parse_file(code)
        except Exception as e:
            logger.error(f"Parsing error: {e}")
            return {
                'error': 'Failed to parse code',
                'details': str(e)
            }
        
        # 2. Run all scanners
        security_issues = self.security_scanner.scan(code, ast)
        performance_issues = self.performance_analyzer.analyze(code, ast)
        bp_issues = self.best_practices_checker.check(code, ast)
        
        # 3. AI suggestions (if available)
        ai_suggestions = []
        if self.llm_available:
            ai_suggestions = await self._ai_deep_review(code, ast)
        
        # 4. Aggregate results
        all_issues = security_issues + performance_issues + bp_issues + ai_suggestions
        
        # 5. Calculate metrics
        metrics = self._calculate_metrics(all_issues, ast)
        
        # 6. Determine overall status
        overall_status = self._determine_status(all_issues)
        
        # 7. Generate summary
        summary = self._generate_summary(all_issues, metrics, overall_status)
        
        return {
            'filename': filename,
            'overall_status': overall_status,
            'summary': summary,
            'metrics': metrics,
            'issues': {
                'security': security_issues,
                'performance': performance_issues,
                'best_practices': bp_issues,
                'ai_suggestions': ai_suggestions
            },
            'total_issues': len(all_issues),
            'reviewed_at': datetime.now().isoformat()
        }
    
    async def review_pull_request(
        self,
        files_changed: List[Dict[str, str]]
    ) -> Dict[str, Any]:
        """
        Review —Ü–µ–ª–æ–≥–æ Pull Request
        
        Args:
            files_changed: [
                {'filename': 'Module.bsl', 'content': '...'}
            ]
        
        Returns:
            Aggregated review –¥–ª—è –≤—Å–µ–≥–æ PR
        """
        logger.info(f"Reviewing PR with {len(files_changed)} files")
        
        file_reviews = []
        all_issues = []
        
        # Review –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
        for file_data in files_changed:
            if not file_data['filename'].endswith('.bsl'):
                continue
            
            review = await self.review_code(
                code=file_data['content'],
                filename=file_data['filename']
            )
            
            if 'error' not in review:
                file_reviews.append(review)
                all_issues.extend(review.get('issues', {}).get('security', []))
                all_issues.extend(review.get('issues', {}).get('performance', []))
                all_issues.extend(review.get('issues', {}).get('best_practices', []))
        
        # Overall metrics
        overall_metrics = {
            'files_reviewed': len(file_reviews),
            'total_issues': len(all_issues),
            'critical': sum(1 for i in all_issues if i.get('severity') == 'CRITICAL'),
            'high': sum(1 for i in all_issues if i.get('severity') == 'HIGH'),
            'medium': sum(1 for i in all_issues if i.get('severity') == 'MEDIUM'),
            'low': sum(1 for i in all_issues if i.get('severity') == 'LOW')
        }
        
        # Overall status
        if overall_metrics['critical'] > 0:
            overall_status = 'CHANGES_REQUESTED'
        elif overall_metrics['high'] > 3:
            overall_status = 'CHANGES_REQUESTED'
        elif overall_metrics['total_issues'] > 0:
            overall_status = 'COMMENTED'
        else:
            overall_status = 'APPROVED'
        
        # Generate PR summary
        pr_summary = self._generate_pr_summary(file_reviews, overall_metrics, overall_status)
        
        return {
            'overall_status': overall_status,
            'summary': pr_summary,
            'file_reviews': file_reviews,
            'metrics': overall_metrics,
            'reviewed_at': datetime.now().isoformat()
        }
    
    async def _ai_deep_review(self, code: str, ast: Dict) -> List[Dict]:
        """AI –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç LLM)"""
        # Placeholder –¥–ª—è LLM integration
        # TODO: Integrate with OpenAI GPT-4 or local LLM
        return []
    
    def _calculate_metrics(self, issues: List[Dict], ast: Dict) -> Dict:
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞"""
        return {
            'total_issues': len(issues),
            'critical': sum(1 for i in issues if i.get('severity') == 'CRITICAL'),
            'high': sum(1 for i in issues if i.get('severity') == 'HIGH'),
            'medium': sum(1 for i in issues if i.get('severity') == 'MEDIUM'),
            'low': sum(1 for i in issues if i.get('severity') == 'LOW'),
            'complexity': ast.get('total_complexity', 0),
            'loc': ast.get('loc', 0),
            'functions_count': ast.get('functions_count', 0)
        }
    
    def _determine_status(self, issues: List[Dict]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ —Å—Ç–∞—Ç—É—Å–∞"""
        critical_count = sum(1 for i in issues if i.get('severity') == 'CRITICAL')
        high_count = sum(1 for i in issues if i.get('severity') == 'HIGH')
        
        if critical_count > 0:
            return 'CHANGES_REQUESTED'
        elif high_count > 3:
            return 'CHANGES_REQUESTED'
        elif len(issues) > 0:
            return 'COMMENTED'
        else:
            return 'APPROVED'
    
    def _generate_summary(
        self,
        issues: List[Dict],
        metrics: Dict,
        status: str
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è summary"""
        
        status_emoji = {
            'APPROVED': '‚úÖ',
            'COMMENTED': 'üí¨',
            'CHANGES_REQUESTED': '‚ö†Ô∏è'
        }
        
        summary = f'''
## {status_emoji.get(status, 'üîç')} AI Code Review

**Status:** {status}

### üìä Metrics
- **Total Issues:** {metrics['total_issues']}
  - üî¥ Critical: {metrics['critical']}
  - üü† High: {metrics['high']}
  - üü° Medium: {metrics['medium']}
  - üü¢ Low: {metrics['low']}

- **Code Complexity:** {metrics['complexity']}
- **Lines of Code:** {metrics['loc']}
- **Functions:** {metrics['functions_count']}
'''
        
        if metrics['critical'] > 0:
            summary += '''
### ‚ö†Ô∏è CRITICAL Issues Found!

–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏!
–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø—Ä–∞–≤—å—Ç–µ –ø–µ—Ä–µ–¥ merge.
'''
        
        if metrics['total_issues'] == 0:
            summary += '''
### ‚ú® Excellent Code Quality!

–ö–æ–¥ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—Å–µ–º best practices! üéâ
–ù–µ—Ç –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –∑–∞–º–µ—á–∞–Ω–∏–π.
'''
        
        return summary
    
    def _generate_pr_summary(
        self,
        file_reviews: List[Dict],
        metrics: Dict,
        status: str
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è summary –¥–ª—è PR"""
        
        status_emoji = {
            'APPROVED': '‚úÖ',
            'COMMENTED': 'üí¨',
            'CHANGES_REQUESTED': '‚ö†Ô∏è'
        }
        
        summary = f'''
## {status_emoji.get(status, 'üîç')} AI Code Review Summary

**Overall Status:** {status}

### üìä Review Metrics
- **Files Reviewed:** {metrics['files_reviewed']}
- **Total Issues Found:** {metrics['total_issues']}

**By Severity:**
- üî¥ Critical: {metrics['critical']}
- üü† High: {metrics['high']}  
- üü° Medium: {metrics['medium']}
- üü¢ Low: {metrics['low']}
'''
        
        if metrics['critical'] > 0:
            summary += '\n### ‚ö†Ô∏è Action Required\n\n'
            summary += '–ù–∞–π–¥–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. Merge –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è.\n'
        
        elif metrics['total_issues'] == 0:
            summary += '\n### ‚ú® Great Job!\n\n'
            summary += '–ö–æ–¥ –æ—Ç–ª–∏—á–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞! –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã. üéâ\n'
        
        return summary


