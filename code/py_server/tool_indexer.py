"""
Tool Indexer

–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ MCP tools –≤ Qdrant –¥–ª—è semantic search
–ü–æ–∑–≤–æ–ª—è–µ—Ç –∞–≥–µ–Ω—Ç–∞–º –Ω–∞—Ö–æ–¥–∏—Ç—å –Ω—É–∂–Ω—ã–µ tools –ø–æ —Å–º—ã—Å–ª—É –∑–∞–ø—Ä–æ—Å–∞
"""

import logging
from typing import List, Dict, Any, Optional
import hashlib
import json

logger = logging.getLogger(__name__)


class ToolIndexer:
    """
    –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è MCP tools –≤ Qdrant –¥–ª—è semantic search
    
    –ü–æ–∑–≤–æ–ª—è–µ—Ç –∞–≥–µ–Ω—Ç–∞–º:
    - –ò—Å–∫–∞—Ç—å tools –ø–æ semantic query ("1c metadata tools")
    - –ó–∞–≥—Ä—É–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ tools (progressive disclosure)
    - –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ server
    - –ü–æ–ª—É—á–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏
    
    Usage:
        indexer = ToolIndexer(qdrant_url="http://localhost:6333")
        
        # –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å tools
        await indexer.index_tools(all_tools)
        
        # –ü–æ–∏—Å–∫
        results = await indexer.search_tools(
            query="get 1C configuration",
            server="1c",
            limit=5
        )
    """
    
    def __init__(
        self,
        qdrant_url: str = "http://localhost:6333",
        collection_name: str = "mcp_tools",
        embedding_model: str = "text-embedding-ada-002"
    ):
        """
        Args:
            qdrant_url: URL Qdrant server
            collection_name: –ò–º—è collection –¥–ª—è tools
            embedding_model: –ú–æ–¥–µ–ª—å –¥–ª—è embeddings
        """
        self.qdrant_url = qdrant_url
        self.collection_name = collection_name
        self.embedding_model = embedding_model
        
        # Lazy init (—Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ)
        self._client = None
        self._embedding_service = None
    
    @property
    def client(self):
        """Lazy initialization Qdrant client"""
        if self._client is None:
            try:
                from qdrant_client import QdrantClient
                self._client = QdrantClient(url=self.qdrant_url)
                logger.info(f"Connected to Qdrant at {self.qdrant_url}")
            except ImportError:
                logger.error("qdrant-client not installed. Run: pip install qdrant-client")
                raise
            except Exception as e:
                logger.error(f"Failed to connect to Qdrant: {e}")
                raise
        
        return self._client
    
    def _ensure_collection(self):
        """–°–æ–∑–¥–∞—Ç—å collection –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        from qdrant_client.models import Distance, VectorParams
        
        try:
            self.client.get_collection(self.collection_name)
            logger.info(f"Collection '{self.collection_name}' already exists")
        except:
            logger.info(f"Creating collection '{self.collection_name}'...")
            
            self.client.create_collection(
                collection_name=self.collection_name,
                vectors_config=VectorParams(
                    size=1536,  # OpenAI ada-002 embedding size
                    distance=Distance.COSINE
                )
            )
            
            logger.info(f"‚úÖ Collection '{self.collection_name}' created")
    
    async def index_tools(self, tools: List[Dict[str, Any]]):
        """
        –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ tools –≤ Qdrant
        
        Args:
            tools: –°–ø–∏—Å–æ–∫ tool definitions
        """
        from qdrant_client.models import PointStruct
        
        # Ensure collection exists
        self._ensure_collection()
        
        logger.info(f"Indexing {len(tools)} tools...")
        
        points = []
        
        for tool in tools:
            # –°–æ–∑–¥–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è embedding
            text = self._tool_to_text(tool)
            
            # –ü–æ–ª—É—á–∏—Ç—å embedding
            embedding = await self._get_embedding(text)
            
            # –°–æ–∑–¥–∞—Ç—å point
            point_id = self._generate_id(tool['name'])
            
            point = PointStruct(
                id=point_id,
                vector=embedding,
                payload={
                    'name': tool['name'],
                    'server': tool.get('server', 'unknown'),
                    'description': tool.get('description', ''),
                    'input_schema': tool.get('inputSchema', {}),
                    'output_schema': tool.get('outputSchema', {}),
                    'full_definition': tool,
                    'indexed_at': self._get_timestamp(),
                }
            )
            
            points.append(point)
        
        # Batch upload to Qdrant
        self.client.upsert(
            collection_name=self.collection_name,
            points=points
        )
        
        logger.info(f"‚úÖ Indexed {len(tools)} tools in Qdrant")
    
    async def search_tools(
        self,
        query: str,
        server: Optional[str] = None,
        detail_level: str = "name_and_description",
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Semantic search –¥–ª—è tools
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å ("get 1C configuration metadata")
            server: –§–∏–ª—å—Ç—Ä –ø–æ server ("1c", "neo4j", etc.)
            detail_level: 
                - "name_only": —Ç–æ–ª—å–∫–æ –∏–º—è –∏ server
                - "name_and_description": –∏–º—è, server, description
                - "full": –ø–æ–ª–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ tool
            limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö tools —Å relevance score
        """
        
        # –ü–æ–ª—É—á–∏—Ç—å embedding –¥–ª—è query
        query_embedding = await self._get_embedding(query)
        
        # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å filter
        query_filter = None
        if server:
            from qdrant_client.models import Filter, FieldCondition, MatchValue
            
            query_filter = Filter(
                must=[
                    FieldCondition(
                        key="server",
                        match=MatchValue(value=server)
                    )
                ]
            )
        
        # Search –≤ Qdrant
        results = self.client.search(
            collection_name=self.collection_name,
            query_vector=query_embedding,
            limit=limit,
            query_filter=query_filter
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ detail_level
        formatted = []
        
        for result in results:
            payload = result.payload
            
            if detail_level == "name_only":
                formatted.append({
                    'name': payload['name'],
                    'server': payload['server'],
                    'score': result.score,
                })
            
            elif detail_level == "name_and_description":
                formatted.append({
                    'name': payload['name'],
                    'server': payload['server'],
                    'description': payload['description'],
                    'score': result.score,
                })
            
            else:  # "full"
                formatted.append({
                    **payload['full_definition'],
                    'score': result.score,
                })
        
        logger.info(
            f"Found {len(formatted)} tools for query '{query}' "
            f"(server: {server or 'all'})"
        )
        
        return formatted
    
    def _tool_to_text(self, tool: Dict[str, Any]) -> str:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å tool definition –≤ —Ç–µ–∫—Å—Ç –¥–ª—è embedding
        
        –°–æ–∑–¥–∞—ë–º rich description –≤–∫–ª—é—á–∞—è:
        - Name
        - Description
        - Parameters
        - Server
        """
        
        parts = [
            f"Tool: {tool['name']}",
            f"Server: {tool.get('server', 'unknown')}",
            f"Description: {tool.get('description', 'No description')}",
        ]
        
        # –î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        input_schema = tool.get('inputSchema', {})
        if 'properties' in input_schema:
            properties = input_schema['properties']
            param_descriptions = []
            
            for param_name, param_schema in properties.items():
                param_desc = param_schema.get('description', param_name)
                param_type = param_schema.get('type', 'any')
                param_descriptions.append(f"{param_name} ({param_type}): {param_desc}")
            
            parts.append("Parameters:\n  " + "\n  ".join(param_descriptions))
        
        return '\n'.join(parts)
    
    async def _get_embedding(self, text: str) -> List[float]:
        """
        –ü–æ–ª—É—á–∏—Ç—å embedding –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        
        Supports:
        - OpenAI API (text-embedding-ada-002)
        - Local model (sentence-transformers)
        """
        
        if self._embedding_service is None:
            # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å OpenAI
            try:
                import openai
                self._embedding_service = 'openai'
                logger.info("Using OpenAI for embeddings")
            except ImportError:
                # Fallback –Ω–∞ local model
                try:
                    from sentence_transformers import SentenceTransformer
                    self._embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
                    self._embedding_service = 'local'
                    logger.info("Using local model for embeddings")
                except ImportError:
                    logger.error(
                        "No embedding service available. "
                        "Install: pip install openai OR pip install sentence-transformers"
                    )
                    raise
        
        # Get embedding
        if self._embedding_service == 'openai':
            return await self._get_openai_embedding(text)
        else:
            return await self._get_local_embedding(text)
    
    async def _get_openai_embedding(self, text: str) -> List[float]:
        """–ü–æ–ª—É—á–∏—Ç—å embedding —á–µ—Ä–µ–∑ OpenAI API"""
        import openai
        
        response = await openai.Embedding.acreate(
            model=self.embedding_model,
            input=text
        )
        
        return response['data'][0]['embedding']
    
    async def _get_local_embedding(self, text: str) -> List[float]:
        """–ü–æ–ª—É—á–∏—Ç—å embedding —á–µ—Ä–µ–∑ local model"""
        embedding = self._embedding_model.encode(text)
        return embedding.tolist()
    
    def _generate_id(self, tool_name: str) -> int:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å numeric ID –∏–∑ –∏–º–µ–Ω–∏ tool"""
        # MD5 hash ‚Üí integer
        hash_hex = hashlib.md5(tool_name.encode()).hexdigest()[:8]
        return int(hash_hex, 16)
    
    def _get_timestamp(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π timestamp"""
        from datetime import datetime
        return datetime.now().isoformat()


# Example usage
if __name__ == "__main__":
    import asyncio
    
    async def test_indexer():
        print("=" * 60)
        print("–¢–µ—Å—Ç Tool Indexer")
        print("=" * 60)
        
        # Mock tools
        tools = [
            {
                'name': 'get_configuration',
                'server': '1c',
                'description': '–ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ 1–°',
                'inputSchema': {
                    'properties': {
                        'name': {'type': 'string', 'description': '–ò–º—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏'}
                    }
                }
            },
            {
                'name': 'run_cypher',
                'server': 'neo4j',
                'description': '–í—ã–ø–æ–ª–Ω–∏—Ç—å Cypher –∑–∞–ø—Ä–æ—Å –≤ Neo4j',
                'inputSchema': {
                    'properties': {
                        'query': {'type': 'string', 'description': 'Cypher query'}
                    }
                }
            },
            {
                'name': 'search',
                'server': 'qdrant',
                'description': '–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –≤ Qdrant',
                'inputSchema': {
                    'properties': {
                        'query': {'type': 'string', 'description': 'Search query'}
                    }
                }
            }
        ]
        
        # Initialize indexer
        try:
            indexer = ToolIndexer()
            
            print("\nüì¶ Indexing tools...")
            await indexer.index_tools(tools)
            
            print("\nüîç Searching tools...")
            
            # Test search
            results = await indexer.search_tools(
                query="get 1C configuration metadata",
                limit=3
            )
            
            print(f"\nFound {len(results)} tools:")
            for i, tool in enumerate(results, 1):
                print(f"{i}. {tool['name']} (server: {tool['server']}, score: {tool['score']:.2f})")
                print(f"   {tool['description']}")
            
            print("\n‚úÖ Test passed!")
            
        except Exception as e:
            print(f"\n‚ö†Ô∏è  Test skipped (Qdrant not available): {e}")
            print("   Install: pip install qdrant-client")
            print("   Or start Qdrant: docker run -p 6333:6333 qdrant/qdrant")
    
    asyncio.run(test_indexer())


