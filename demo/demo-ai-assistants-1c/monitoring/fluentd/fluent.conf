# Fluentd конфигурация для агрегации логов

<system>
  @type http
  port 9880
  bind 0.0.0.0
  
  # CORS настройки
  cors_allow_origins ["*"]
  cors_expose_headers ["*"]
  cors_request_headers ["Authorization, content-type"]
  cors_access_control_allow_credentials false
</system>

# Входные источники логов
<source>
  @type forward
  port 24224
  bind 0.0.0.0
  
  # Поддержка compression
  <transport tcp>
    compression gzip
  </transport>
</source>

<source>
  @type udp
  port 5170
  tag docker.logs
  
  <parse>
    @type json
    time_format %Y-%m-%dT%H:%M:%S.%NZ
  </parse>
</source>

<source>
  @type tcp
  port 5171
  tag application.logs
  
  <parse>
    @type json
    time_format %Y-%m-%dT%H:%M:%S.%NZ
  </parse>
</source>

<source>
  @type tail
  @id demo_logs
  path /var/log/demo/*.log
  tag demo.logs
  
  <parse>
    @type multi_format
    <pattern>
      format json
    </pattern>
    <pattern>
      format /^(?<time>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3})\s+\[(?<level>[\w]+)\]\s+(?<message>.+)$/
      time_format %Y-%m-%d %H:%M:%S,%L
    </pattern>
    <pattern>
      format /^(?<timestamp>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}Z)\s+(?<level>[\w]+)\s+(?<message>.+)$/
      time_format %Y-%m-%dT%H:%M:%S.%L%z
    </pattern>
  </parse>
</source>

# Фильтры для обработки логов
<filter docker.**>
  @type parser
  key_name message
  reserve_data true
  <parse>
    @type json
  </parse>
</filter>

<filter application.**>
  @type record_transformer
  <record>
    service "#{ENV['SERVICE_NAME'] || 'unknown'}"
    environment "#{ENV['ENVIRONMENT'] || 'development'}"
    hostname "#{Socket.gethostname}"
    correlation_id "#{SecureRandom.uuid}"
    timestamp "#{Time.now.to_i}"
  </record>
</filter>

<filter demo.logs>
  @type geoip
  geoip_lookup_key client_ip
  geoip_database /usr/share/GeoIP/GeoLite2-City.mmdb
</filter>

# Машрутизация логов в зависимости от источника
<match docker.**>
  @type copy
  
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    index_name demo-docker-logs-${ENV['ES_INDEX_PREFIX'] || 'dev'}-%{+YYYY.MM.dd}
    type_name _doc
    
    <buffer>
      @type file
      path /var/log/fluentd-docker-buffer
      flush_thread_count 2
      flush_interval 5s
      chunk_limit_size 2M
      queue_limit_length 8
      retry_max_interval 30
      retry_forever true
    </buffer>
    
    <format>
      @type json
    </format>
    
    # Connection настройки
    request_timeout 30s
    include_tag_key true
    tag_key @log_name
    
    # Игнорирование ошибок SSL для разработки
    ssl_verify false
  </store>
  
  <store>
    @type stdout
    output_type json
  </store>
</match>

<match application.**>
  @type copy
  
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    index_name demo-application-logs-${ENV['ES_INDEX_PREFIX'] || 'dev'}-%{+YYYY.MM.dd}
    type_name _doc
    
    <buffer>
      @type file
      path /var/log/fluentd-application-buffer
      flush_thread_count 2
      flush_interval 5s
      chunk_limit_size 2M
      queue_limit_length 8
      retry_max_interval 30
      retry_forever true
    </buffer>
    
    <format>
      @type json
    </format>
    
    request_timeout 30s
    include_tag_key true
    tag_key @log_name
    ssl_verify false
  </store>
  
  <store>
    @type stdout
    output_type json
  </store>
</match>

<match demo.logs>
  @type copy
  
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    index_name demo-demo-logs-${ENV['ES_INDEX_PREFIX'] || 'dev'}-%{+YYYY.MM.dd}
    type_name _doc
    
    <buffer>
      @type file
      path /var/log/fluentd-demo-buffer
      flush_thread_count 2
      flush_interval 5s
      chunk_limit_size 2M
      queue_limit_length 8
      retry_max_interval 30
      retry_forever true
    </buffer>
    
    <format>
      @type json
    </format>
    
    request_timeout 30s
    include_tag_key true
    tag_key @log_name
    ssl_verify false
  </store>
</match>

# Алерты для критических логов
<match {application.**,demo.**}>
  @type copy
  
  <store>
    # Пересылка критических событий в AlertManager
    @type http
    endpoint http://alertmanager:9093/api/v1/alerts
    http_method post
    content_type json
    
    <json_content>
      {
        "alerts": [{
          "labels": {
            "alertname": "CriticalLogAlert",
            "severity": "critical",
            "service": "#{service}",
            "environment": "#{environment}",
            "message": "#{message}",
            "level": "#{level}"
          },
          "annotations": {
            "description": "#{level} message from #{service}: #{message}",
            "runbook_url": "https://wiki.company.com/runbooks/log-alerts"
          },
          "startsAt": "#{timestamp}",
          "generatorURL": "fluentd://#{hostname}"
        }]
      }
    </json_content>
    
    <buffer>
      @type file
      path /var/log/fluentd-alerts-buffer
      flush_thread_count 1
      flush_interval 60s
      chunk_limit_size 1M
      queue_limit_length 4
      retry_max_interval 300
      retry_forever false
    </buffer>
  </store>
</match>

# Health check endpoint
<source>
  @type monitor_agent
  bind 0.0.0.0
  port 24220
</source>

# System metrics
<source>
  @type cpu
  tag system.cpu
  pid_file /var/run/fluentd-fluent.pid
</source>

<source>
  @type memory
  tag system.memory
</source>

# Логи Fluentd
<match fluent.**>
  @type stdout
</match>

# Глобальные настройки
<system>
  # Рабочая директория
  workers 2
  worker_id 0
  
  # Максимальное количество записей в buffer
  max_queue_size 10000
  
  # Graceful shutdown
  suppress_config_dump false
</system>

# Основные плагины
<require>
  @type geoip
</require>