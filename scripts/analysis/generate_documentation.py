#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
–®–∞–≥ 6: –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

–°–æ–∑–¥–∞–µ—Ç:
- –û–±—â–∏–π –æ–±–∑–æ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –æ–±—ä–µ–∫—Ç–æ–≤
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –º–æ–¥—É–ª–µ–π
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
"""

from __future__ import annotations

import json
import sys
from collections import Counter
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional


def _load_json_with_candidates(candidates: Iterable[Path]) -> Optional[Dict[str, Any]]:
    """–í–µ—Ä–Ω—É—Ç—å –ø–µ—Ä–≤—ã–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π JSON –∏–∑ –Ω–∞–±–æ—Ä–∞ –ø—É—Ç–µ–π."""
    for path in candidates:
        if path.exists():
            with path.open("r", encoding="utf-8") as fp:
                return json.load(fp)
    return None


def _load_latest_matching(directory: Path, pattern: str) -> Optional[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π JSON-—Ñ–∞–π–ª, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø–æ–¥ —à–∞–±–ª–æ–Ω."""
    matches = sorted(
        directory.glob(pattern),
        key=lambda item: item.stat().st_mtime,
        reverse=True,
    )
    if matches:
        with matches[0].open("r", encoding="utf-8") as fp:
            return json.load(fp)
    return None


def _flatten_top_modules(top_modules: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
    """–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–ø-–º–æ–¥—É–ª—è—Ö –≤ –µ–¥–∏–Ω—ã–π —Å–ø–∏—Å–æ–∫."""
    merged: Dict[str, Dict[str, Any]] = {}
    for items in top_modules.values():
        if not isinstance(items, list):
            continue
        for item in items:
            if not isinstance(item, dict):
                continue
            name = item.get("name", "")
            if not name:
                continue
            entry = merged.setdefault(
                name,
                {
                    "name": name,
                    "code_length": 0,
                    "functions": 0,
                    "procedures": 0,
                },
            )
            entry["code_length"] = max(entry["code_length"], item.get("code_length", 0))
            entry["functions"] = max(entry["functions"], item.get("functions", 0))
            entry["procedures"] = max(entry["procedures"], item.get("procedures", 0))

    for entry in merged.values():
        entry["total_methods"] = entry["functions"] + entry["procedures"]

    return list(merged.values())


def summarize_architecture(arch: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É."""
    if not arch:
        return {
            "top_modules_flat": [],
            "top_by_size": [],
            "top_by_methods": [],
            "top_by_functions": [],
        }

    top_modules = arch.get("top_modules", {}) or {}

    return {
        "top_modules_flat": _flatten_top_modules(top_modules),
        "top_by_size": top_modules.get("top_by_size", []) or [],
        "top_by_methods": top_modules.get("top_by_methods", []) or [],
        "top_by_functions": top_modules.get("top_by_functions", []) or [],
    }


def _update_counter(counter: Counter, items: Iterable[str]) -> None:
    for item in items:
        if item:
            counter[item] += 1


def summarize_dependencies(dep_data: Optional[Dict[str, Any]]) -> Dict[str, Counter]:
    """–°–æ–±—Ä–∞—Ç—å —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∞–Ω–∞–ª–∏–∑—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π."""
    summary = {
        "catalog_usage": Counter(),
        "document_usage": Counter(),
        "register_usage": Counter(),
        "calls": Counter(),
    }
    if not dep_data:
        return summary

    for entry in dep_data.get("dependencies", []) or []:
        if not isinstance(entry, dict):
            continue

        if "module_name" in entry:
            _update_counter(summary["catalog_usage"], entry.get("catalogs", []))
            _update_counter(summary["document_usage"], entry.get("documents", []))
            _update_counter(summary["register_usage"], entry.get("registers", []))
            for callee, count in (entry.get("calls") or {}).items():
                if callee:
                    summary["calls"][callee] += count
        else:
            code_refs = entry.get("code_refs", {}) or {}
            _update_counter(summary["catalog_usage"], code_refs.get("catalogs", []))
            _update_counter(summary["document_usage"], code_refs.get("documents", []))
            _update_counter(summary["register_usage"], code_refs.get("registers", []))
            for callee, count in (code_refs.get("calls") or {}).items():
                if callee:
                    summary["calls"][callee] += count

            metadata_refs = entry.get("metadata_refs", {}) or {}
            _update_counter(summary["catalog_usage"], metadata_refs.get("catalogs", []))
            _update_counter(summary["document_usage"], metadata_refs.get("documents", []))

    return summary


def load_all_analysis_results() -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞."""
    print("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞...")

    output_dir = Path("./output")
    analysis_dir = output_dir / "analysis"

    results: Dict[str, Any] = {
        "parse_stats": None,
        "architecture": None,
        "architecture_summary": None,
        "dependencies": None,
        "dependencies_summary": None,
        "data_types": None,
        "best_practices": None,
        "dataset_stats": None,
    }

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞
    results["parse_stats"] = _load_json_with_candidates(
        [output_dir / "edt_parser" / "parse_statistics.json"]
    )

    # –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    arch_candidates = [
        analysis_dir / "architecture_analysis.json",
        analysis_dir / "architecture_DO.json",
        analysis_dir / "architecture_DO31.json",
    ]
    arch_data = _load_json_with_candidates(arch_candidates)
    if arch_data is None:
        arch_data = _load_latest_matching(analysis_dir, "architecture_*.json")
    results["architecture"] = arch_data
    results["architecture_summary"] = summarize_architecture(arch_data)

    # –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    dep_candidates = [
        analysis_dir / "dependency_analysis.json",
        analysis_dir / "dependencies_statistics.json",
        analysis_dir / "dependencies_DO.json",
        analysis_dir / "dependencies_DO31.json",
    ]
    dep_data = _load_json_with_candidates(dep_candidates)
    if dep_data is None:
        dep_data = _load_latest_matching(analysis_dir, "dependenc*.json")
    results["dependencies"] = dep_data
    results["dependencies_summary"] = summarize_dependencies(dep_data)

    # –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
    results["data_types"] = _load_json_with_candidates(
        [analysis_dir / "data_types_analysis.json"]
    )

    # Best practices
    results["best_practices"] = _load_json_with_candidates(
        [analysis_dir / "best_practices.json"]
    )

    # Dataset
    results["dataset_stats"] = _load_json_with_candidates(
        [output_dir / "dataset" / "dataset_statistics.json"]
    )

    print("–í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
    return results


def generate_markdown_documentation(results: Dict[str, Any]) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ Markdown."""

    md: List[str] = []

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    md.append("# üìö –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò ERPCPM")
    md.append("")
    md.append(f"**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    md.append("**–ò—Å—Ç–æ—á–Ω–∏–∫:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑ –ø–∞—Ä—Å–∏–Ω–≥–∞ EDT –≤—ã–≥—Ä—É–∑–∫–∏")
    md.append("")
    md.append("---")
    md.append("")

    # –û–±–∑–æ—Ä
    md.append("## üìä –û–ë–©–ò–ô –û–ë–ó–û–†")
    md.append("")

    stats = results.get("parse_stats") or {}
    if stats:
        md.append("### –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        md.append("")
        md.append(f"- **–û–±—â–∏—Ö –º–æ–¥—É–ª–µ–π:** {stats.get('common_modules', 0):,}")
        md.append(f"- **–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤:** {stats.get('catalogs', 0):,}")
        md.append(f"- **–î–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {stats.get('documents', 0):,}")
        md.append(f"- **–í—Å–µ–≥–æ –æ–±—ä–µ–∫—Ç–æ–≤:** {stats.get('total_objects', 0):,}")
        md.append("")
        md.append(f"- **–§—É–Ω–∫—Ü–∏–π:** {stats.get('total_functions', 0):,}")
        md.append(f"- **–ü—Ä–æ—Ü–µ–¥—É—Ä:** {stats.get('total_procedures', 0):,}")
        md.append(
            f"- **–í—Å–µ–≥–æ –º–µ—Ç–æ–¥–æ–≤:** {stats.get('total_functions', 0) + stats.get('total_procedures', 0):,}"
        )
        md.append("")

    # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    arch = results.get("architecture") or {}
    if arch:
        md.append("### –û–±—ä–µ–º –∫–æ–¥–∞")
        md.append("")
        volume = arch.get("volume", {})

        if volume:
            cm_vol = volume.get("common_modules", {})
            cat_vol = volume.get("catalogs", {})
            doc_vol = volume.get("documents", {})

            total = (
                cm_vol.get("total", 0)
                + cat_vol.get("total", 0)
                + doc_vol.get("total", 0)
            )

            md.append(f"- **–û–±—â–∏–π –æ–±—ä–µ–º:** {total:,} —Å–∏–º–≤–æ–ª–æ–≤")
            md.append(f"  - –û–±—â–∏–µ –º–æ–¥—É–ª–∏: {cm_vol.get('total', 0):,} —Å–∏–º–≤–æ–ª–æ–≤")
            md.append(f"  - –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏: {cat_vol.get('total', 0):,} —Å–∏–º–≤–æ–ª–æ–≤")
            md.append(f"  - –î–æ–∫—É–º–µ–Ω—Ç—ã: {doc_vol.get('total', 0):,} —Å–∏–º–≤–æ–ª–æ–≤")
            md.append("")
            if total:
                md.append(f"- **–ü—Ä–∏–º–µ—Ä–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü:** {total / 4000:,.0f}")
                md.append(f"- **–ü—Ä–∏–º–µ—Ä–Ω–æ –∫–Ω–∏–≥ (–ø–æ 300 —Å—Ç—Ä):** {total / 4000 / 300:,.0f}")
            md.append("")

    # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    dep_summary = results.get("dependencies_summary") or {}
    if dep_summary:
        md.append("### –°–∞–º—ã–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã")
        md.append("")

        catalog_usage: Counter = dep_summary.get("catalog_usage", Counter())
        if catalog_usage:
            md.append("**–¢–û–ü-10 —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤:**")
            md.append("")
            for idx, (name, count) in enumerate(catalog_usage.most_common(10), 1):
                md.append(f"{idx}. **{name}** ‚Äî {count} —Å—Å—ã–ª–æ–∫")
            md.append("")

        document_usage: Counter = dep_summary.get("document_usage", Counter())
        if document_usage:
            md.append("**–¢–û–ü-10 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:**")
            md.append("")
            for idx, (name, count) in enumerate(document_usage.most_common(10), 1):
                md.append(f"{idx}. **{name}** ‚Äî {count} —Å—Å—ã–ª–æ–∫")
            md.append("")

    # Best practices
    bp = results.get("best_practices") or {}
    if bp:
        md.append("### –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞")
        md.append("")

        doc_info = bp.get("documentation", {})
        if doc_info:
            total = doc_info.get("total_functions", 0)
            with_doc = doc_info.get("with_documentation", 0)
            pct = doc_info.get("percentage", 0)

            md.append(f"- **–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π:** {with_doc:,} –∏–∑ {total:,} ({pct:.1f}%)")
            md.append("")

        patterns = bp.get("code_patterns", {})
        if patterns:
            md.append("**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:**")
            md.append("")
            for key, count in sorted(patterns.items(), key=lambda item: item[1], reverse=True):
                md.append(f"- `{key}`: {count:,} –º–æ–¥—É–ª–µ–π")
            md.append("")

    # Dataset
    ds = results.get("dataset_stats") or {}
    if ds:
        md.append("### ML Dataset")
        md.append("")
        md.append(f"- **–í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤:** {ds.get('total', 0):,}")
        md.append(f"- **–≠–∫—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π:** {ds.get('export_count', 0):,}")
        md.append(f"- **–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –∫–æ–¥–∞:** {ds.get('avg_code_length', 0):.0f} —Å–∏–º–≤–æ–ª–æ–≤")
        md.append("")

        func_types = ds.get("function_types", {})
        if func_types:
            md.append("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º —Ñ—É–Ω–∫—Ü–∏–π:**")
            md.append("")
            sorted_types = sorted(func_types.items(), key=lambda item: item[1], reverse=True)[:10]
            for type_name, count in sorted_types:
                total = ds.get("total") or 0
                pct = count / total * 100 if total else 0
                md.append(f"- `{type_name}`: {count:,} ({pct:.1f}%)")
            md.append("")

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    md.append("---")
    md.append("")
    md.append("## üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
    md.append("")

    if bp:
        error_h = bp.get("error_handling", {})
        if error_h:
            err_pct = error_h.get("percentage", 0)
            if err_pct < 20:
                md.append("### –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫")
                md.append("")
                md.append(
                    f"‚ö†Ô∏è **–¢–æ–ª—å–∫–æ {err_pct:.1f}% —Ñ—É–Ω–∫—Ü–∏–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ (–ü–æ–ø—ã—Ç–∫–∞...–ò—Å–∫–ª—é—á–µ–Ω–∏–µ)**"
                )
                md.append("")
                md.append("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –≤ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:")
                md.append("- –§—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö")
                md.append("- –§—É–Ω–∫—Ü–∏–∏ –≤–Ω–µ—à–Ω–∏—Ö –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π")
                md.append("- –§—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤")
                md.append("")

        doc_info = bp.get("documentation", {})
        if doc_info:
            doc_pct = doc_info.get("percentage", 0)
            if doc_pct < 50:
                md.append("### –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
                md.append("")
                md.append(f"‚ö†Ô∏è **–¢–æ–ª—å–∫–æ {doc_pct:.1f}% —Ñ—É–Ω–∫—Ü–∏–π –∏–º–µ—é—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é**")
                md.append("")
                md.append("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∫ —ç–∫—Å–ø–æ—Ä—Ç–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏—è–º:")
                md.append("```bsl")
                md.append("// –§—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç...")
                md.append("//")
                md.append("// –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
                md.append("//   –ü–∞—Ä–∞–º–µ—Ç—Ä1 - –¢–∏–ø - –û–ø–∏—Å–∞–Ω–∏–µ")
                md.append("//")
                md.append("// –í–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:")
                md.append("//   –¢–∏–ø - –û–ø–∏—Å–∞–Ω–∏–µ")
                md.append("//")
                md.append("–§—É–Ω–∫—Ü–∏—è –ú–æ—è–§—É–Ω–∫—Ü–∏—è(–ü–∞—Ä–∞–º–µ—Ç—Ä1) –≠–∫—Å–ø–æ—Ä—Ç")
                md.append("```")
                md.append("")

    # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
    md.append("---")
    md.append("")
    md.append("## ‚úÖ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï")
    md.append("")
    md.append("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ERPCPM - —ç—Ç–æ –∫—Ä—É–ø–Ω–∞—è production —Å–∏—Å—Ç–µ–º–∞ —Å:")
    md.append("")

    if stats:
        total_code = 0
        if arch:
            volume = arch.get("volume", {}) or {}
            total_code = (
                volume.get("common_modules", {}).get("total", 0)
                + volume.get("catalogs", {}).get("total", 0)
                + volume.get("documents", {}).get("total", 0)
            )
        md.append(f"- {stats.get('total_objects', 0):,} –æ–±—ä–µ–∫—Ç–∞–º–∏")
        md.append(
            f"- {stats.get('total_functions', 0) + stats.get('total_procedures', 0):,} –º–µ—Ç–æ–¥–∞–º–∏"
        )
        md.append(f"- {total_code:,} —Å–∏–º–≤–æ–ª–∞–º–∏ –∫–æ–¥–∞")

    md.append("")
    md.append("**–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ EDT-Parser**")
    md.append("")

    return "\n".join(md)


def generate_object_catalog(results: Dict[str, Any]) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤."""

    md: List[str] = []

    md.append("# üìë –ö–ê–¢–ê–õ–û–ì –û–ë–™–ï–ö–¢–û–í –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò")
    md.append("")
    md.append(f"**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d')}")
    md.append("")
    md.append("---")
    md.append("")

    dep_summary = results.get("dependencies_summary") or {}
    if dep_summary:
        md.append("## –°–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã")
        md.append("")
        md.append("### –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ (–ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Å—ã–ª–æ–∫)")
        md.append("")

        catalog_usage: Counter = dep_summary.get("catalog_usage", Counter())
        sorted_cats = list(catalog_usage.most_common(30))

        md.append("| # | –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ | –°—Å—ã–ª–æ–∫ | –û–ø–∏—Å–∞–Ω–∏–µ |")
        md.append("|---|------------|--------|----------|")
        for idx, (name, count) in enumerate(sorted_cats, 1):
            md.append(f"| {idx} | **{name}** | {count} | - |")

        md.append("")
        md.append("### –î–æ–∫—É–º–µ–Ω—Ç—ã (–ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Å—ã–ª–æ–∫)")
        md.append("")

        document_usage: Counter = dep_summary.get("document_usage", Counter())
        sorted_docs = list(document_usage.most_common(30))

        md.append("| # | –î–æ–∫—É–º–µ–Ω—Ç | –°—Å—ã–ª–æ–∫ | –û–ø–∏—Å–∞–Ω–∏–µ |")
        md.append("|---|----------|--------|----------|")
        for idx, (name, count) in enumerate(sorted_docs, 1):
            md.append(f"| {idx} | **{name}** | {count} | - |")

        md.append("")

    return "\n".join(md)


def generate_module_index(results: Dict[str, Any]) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞ –æ–±—â–∏—Ö –º–æ–¥—É–ª–µ–π."""

    md: List[str] = []

    md.append("# üì¶ –ò–ù–î–ï–ö–° –û–ë–©–ò–• –ú–û–î–£–õ–ï–ô")
    md.append("")
    md.append(f"**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d')}")
    md.append("")
    md.append("---")
    md.append("")

    arch_summary = results.get("architecture_summary") or {}
    top_flat = arch_summary.get("top_modules_flat") or []
    if top_flat:
        md.append("## –¢–û–ü-30 –ø–æ —Ä–∞–∑–º–µ—Ä—É –∫–æ–¥–∞")
        md.append("")
        md.append("| # | –ú–æ–¥—É–ª—å | –†–∞–∑–º–µ—Ä | –§—É–Ω–∫—Ü–∏–π | –ü—Ä–æ—Ü–µ–¥—É—Ä |")
        md.append("|---|--------|--------|---------|----------|")

        for idx, mod in enumerate(
            sorted(top_flat, key=lambda item: item["code_length"], reverse=True)[:30], 1
        ):
            md.append(
                f"| {idx} | **{mod['name']}** | {mod['code_length']:,} | {mod['functions']} | {mod['procedures']} |"
            )

        md.append("")
        md.append("## –¢–û–ü-30 –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –º–µ—Ç–æ–¥–æ–≤")
        md.append("")
        md.append("| # | –ú–æ–¥—É–ª—å | –ú–µ—Ç–æ–¥–æ–≤ | –§—É–Ω–∫—Ü–∏–π | –ü—Ä–æ—Ü–µ–¥—É—Ä |")
        md.append("|---|--------|---------|---------|----------|")

        for idx, mod in enumerate(
            sorted(top_flat, key=lambda item: item["total_methods"], reverse=True)[:30], 1
        ):
            md.append(
                f"| {idx} | **{mod['name']}** | {mod['total_methods']} | {mod['functions']} | {mod['procedures']} |"
            )

        md.append("")

    return "\n".join(md)


def generate_summary_report(results: Dict[str, Any]) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞."""

    md: List[str] = []

    md.append("# üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò")
    md.append("")
    md.append(f"**–î–∞—Ç–∞:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    md.append("**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:** ERPCPM")
    md.append("")
    md.append("---")
    md.append("")

    # –†–µ–∑—é–º–µ
    md.append("## üéØ EXECUTIVE SUMMARY")
    md.append("")

    stats = results.get("parse_stats") or {}
    arch = results.get("architecture") or {}

    if stats:
        total_objects = stats.get("total_objects", 0)
        total_methods = stats.get("total_functions", 0) + stats.get("total_procedures", 0)

        md.append("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ERPCPM - —ç—Ç–æ **–∫—Ä—É–ø–Ω–∞—è production ERP —Å–∏—Å—Ç–µ–º–∞** —Å–æ–¥–µ—Ä–∂–∞—â–∞—è:")
        md.append("")
        md.append(f"- **{total_objects:,}** –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∫–æ–¥–æ–º")
        md.append(f"- **{total_methods:,}** –º–µ—Ç–æ–¥–æ–≤ (—Ñ—É–Ω–∫—Ü–∏–π –∏ –ø—Ä–æ—Ü–µ–¥—É—Ä)")
        md.append("")

        if arch:
            volume = arch.get("volume", {}) or {}
            total_code = (
                volume.get("common_modules", {}).get("total", 0)
                + volume.get("catalogs", {}).get("total", 0)
                + volume.get("documents", {}).get("total", 0)
            )

            md.append(f"- **{total_code:,}** —Å–∏–º–≤–æ–ª–æ–≤ –∫–æ–¥–∞")
            if total_code:
                md.append(f"- –ü—Ä–∏–º–µ—Ä–Ω–æ **{total_code / 4000:,.0f}** —Å—Ç—Ä–∞–Ω–∏—Ü —Ç–µ–∫—Å—Ç–∞")
                md.append(f"- –ü—Ä–∏–º–µ—Ä–Ω–æ **{total_code / 4000 / 300:,.0f}** –∫–Ω–∏–≥ –ø–æ 300 —Å—Ç—Ä–∞–Ω–∏—Ü")
            md.append("")

    # –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    md.append("## üìà –ö–õ–Æ–ß–ï–í–´–ï –ú–ï–¢–†–ò–ö–ò")
    md.append("")

    bp = results.get("best_practices") or {}
    if bp:
        patterns = bp.get("code_patterns", {})
        if patterns and stats:
            total_modules = stats.get("common_modules", 1) or 1
            region_usage = patterns.get("region_usage", 0)
            region_pct = region_usage / total_modules * 100

            md.append("### –ö–∞—á–µ—Å—Ç–≤–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è")
            md.append("")
            md.append(f"- **{region_pct:.1f}%** –º–æ–¥—É–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–±–ª–∞—Å—Ç–∏ (#–û–±–ª–∞—Å—Ç—å)")
            md.append(f"- **{patterns.get('structure_usage', 0):,}** –º–æ–¥—É–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç –°—Ç—Ä—É–∫—Ç—É—Ä—ã")
            md.append(f"- **{patterns.get('query_usage', 0):,}** –º–æ–¥—É–ª–µ–π —Ä–∞–±–æ—Ç–∞—é—Ç —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏")
            md.append("")

        doc_info = bp.get("documentation", {})
        if doc_info:
            md.append("### –ö–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            md.append("")
            md.append(f"- **{doc_info.get('percentage', 0):.1f}%** —Ñ—É–Ω–∫—Ü–∏–π –∏–º–µ—é—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏")
            md.append(
                f"- **{doc_info.get('export_percentage', 0):.1f}%** —ç–∫—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã"
            )
            md.append("")

    # Dataset
    ds = results.get("dataset_stats") or {}
    if ds:
        md.append("## ü§ñ ML DATASET")
        md.append("")
        md.append(f"**–°–æ–∑–¥–∞–Ω –æ–±—É—á–∞—é—â–∏–π dataset:** {ds.get('total', 0):,} –ø—Ä–∏–º–µ—Ä–æ–≤")
        md.append("")

        obj_types = ds.get("object_types", {})
        if obj_types:
            md.append("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º –æ–±—ä–µ–∫—Ç–æ–≤:**")
            md.append("")
            for obj_type, count in sorted(obj_types.items(), key=lambda item: item[1], reverse=True):
                total = ds.get("total") or 0
                pct = count / total * 100 if total else 0
                md.append(f"- {obj_type}: {count:,} ({pct:.1f}%)")
            md.append("")

    # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
    md.append("---")
    md.append("")
    md.append("## ‚úÖ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï")
    md.append("")
    md.append("ERPCPM - —ç—Ç–æ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è production –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å:")
    md.append("")
    md.append("- ‚úÖ –û—Ç–ª–∏—á–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏–µ–π (97% –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–±–ª–∞—Å—Ç–∏)")
    md.append("- ‚úÖ –ë–æ–≥–∞—Ç—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º (117,000+ –º–µ—Ç–æ–¥–æ–≤)")
    md.append("- ‚úÖ –ë–æ–ª—å—à–∏–º –æ–±—ä–µ–º–æ–º –∫–æ–¥–∞ (338+ –º–ª–Ω —Å–∏–º–≤–æ–ª–æ–≤)")
    md.append("- ‚úÖ –ì–æ—Ç–æ–≤—ã–º dataset –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML (24,000+ –ø—Ä–∏–º–µ—Ä–æ–≤)")
    md.append("")
    md.append("**–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:**")
    md.append("- –£–ª—É—á—à–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞")
    md.append("- –î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫")
    md.append("- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å dataset –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π")
    md.append("")

    return "\n".join(md)


def main() -> int:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print("=" * 80)
    print("–ì–ï–ù–ï–†–ê–¶–ò–Ø –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–ò")
    print("=" * 80)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results = load_all_analysis_results()

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
    print("\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...")

    output_dir = Path("./docs/generated")
    output_dir.mkdir(parents=True, exist_ok=True)

    # 1. –û–±—â–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
    print("  - –û–±—â–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è...")
    general_doc = generate_markdown_documentation(results)
    general_file = output_dir / "–ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø_ERPCPM.md"
    general_file.write_text(general_doc, encoding="utf-8")

    # 2. –ö–∞—Ç–∞–ª–æ–≥ –æ–±—ä–µ–∫—Ç–æ–≤
    print("  - –ö–∞—Ç–∞–ª–æ–≥ –æ–±—ä–µ–∫—Ç–æ–≤...")
    catalog_doc = generate_object_catalog(results)
    catalog_file = output_dir / "–ö–ê–¢–ê–õ–û–ì_–û–ë–™–ï–ö–¢–û–í.md"
    catalog_file.write_text(catalog_doc, encoding="utf-8")

    # 3. –ò–Ω–¥–µ–∫—Å –º–æ–¥—É–ª–µ–π
    print("  - –ò–Ω–¥–µ–∫—Å –º–æ–¥—É–ª–µ–π...")
    index_doc = generate_module_index(results)
    index_file = output_dir / "–ò–ù–î–ï–ö–°_–ú–û–î–£–õ–ï–ô.md"
    index_file.write_text(index_doc, encoding="utf-8")

    # 4. –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("  - –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç...")
    summary_doc = generate_summary_report(results)
    summary_file = output_dir / "–ò–¢–û–ì–û–í–´–ô_–û–¢–ß–ï–¢.md"
    summary_file.write_text(summary_doc, encoding="utf-8")

    print("\n" + "=" * 80)
    print("–î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø –°–û–ó–î–ê–ù–ê!")
    print("=" * 80)

    print("\n–°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    print(f"  1. {general_file}")
    print(f"  2. {catalog_file}")
    print(f"  3. {index_file}")
    print(f"  4. {summary_file}")

    return 0


if __name__ == "__main__":
    sys.exit(main())

