#!/usr/bin/env python3
"""
Graph Neural Network Parser –¥–ª—è BSL –∫–æ–¥–∞
–†–ï–í–û–õ–Æ–¶–ò–û–ù–ù–ê–Ø –°–û–ë–°–¢–í–ï–ù–ù–ê–Ø –¢–ï–•–ù–û–õ–û–ì–ò–Ø

–ò–Ω–Ω–æ–≤–∞—Ü–∏—è:
- –ö–æ–¥ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –∫–∞–∫ –ì–†–ê–§, –∞ –Ω–µ —Ç–µ–∫—Å—Ç
- GNN –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –≥—Ä–∞—Ñ–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
- –ü–æ–Ω–∏–º–∞–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç

–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
- CodeGraph: –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–æ–¥–∞ –∫–∞–∫ –≥—Ä–∞—Ñ–∞
- GraphConvLayer: –°–≤–µ—Ä—Ç–∫–∞ –Ω–∞ –≥—Ä–∞—Ñ–∞—Ö
- CodeGNN: –ü–æ–ª–Ω–∞—è GNN –º–æ–¥–µ–ª—å

–í–µ—Ä—Å–∏—è: 1.0.0 Revolutionary
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import numpy as np


class NodeType(Enum):
    """–¢–∏–ø—ã —É–∑–ª–æ–≤ –≤ Code Graph"""
    FUNCTION = "function"
    PROCEDURE = "procedure"
    VARIABLE = "variable"
    EXPRESSION = "expression"
    API_CALL = "api_call"
    CONDITION = "condition"
    LOOP = "loop"


class EdgeType(Enum):
    """–¢–∏–ø—ã —Ä—ë–±–µ—Ä –≤ Code Graph"""
    CALLS = "calls"              # –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏
    DATA_FLOW = "data_flow"      # –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö
    CONTROL_FLOW = "control_flow" # –ü–æ—Ç–æ–∫ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    DEFINES = "defines"          # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    USES = "uses"                # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π


@dataclass
class CodeNode:
    """–£–∑–µ–ª –≥—Ä–∞—Ñ–∞ –∫–æ–¥–∞"""
    id: int
    type: NodeType
    name: str
    code_snippet: str
    line_number: int
    features: np.ndarray = None


@dataclass
class CodeEdge:
    """–†–µ–±—Ä–æ –≥—Ä–∞—Ñ–∞ –∫–æ–¥–∞"""
    from_node: int
    to_node: int
    type: EdgeType
    weight: float = 1.0


class CodeGraph:
    """
    –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–æ–¥–∞ –∫–∞–∫ –≥—Ä–∞—Ñ–∞
    
    Nodes:
    - –§—É–Ω–∫—Ü–∏–∏/–ø—Ä–æ—Ü–µ–¥—É—Ä—ã
    - –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    - –í—ã—Ä–∞–∂–µ–Ω–∏—è
    - API –≤—ã–∑–æ–≤—ã
    
    Edges:
    - –í—ã–∑–æ–≤—ã —Ñ—É–Ω–∫—Ü–∏–π
    - Data flow
    - Control flow
    - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è/–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    """
    
    def __init__(self):
        self.nodes: List[CodeNode] = []
        self.edges: List[CodeEdge] = []
        self.node_id_counter = 0
    
    def add_node(
        self,
        node_type: NodeType,
        name: str,
        code_snippet: str = "",
        line_number: int = 0
    ) -> int:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–∞ –≤ –≥—Ä–∞—Ñ"""
        node = CodeNode(
            id=self.node_id_counter,
            type=node_type,
            name=name,
            code_snippet=code_snippet,
            line_number=line_number
        )
        self.nodes.append(node)
        self.node_id_counter += 1
        return node.id
    
    def add_edge(
        self,
        from_node: int,
        to_node: int,
        edge_type: EdgeType,
        weight: float = 1.0
    ):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–±—Ä–∞"""
        edge = CodeEdge(
            from_node=from_node,
            to_node=to_node,
            type=edge_type,
            weight=weight
        )
        self.edges.append(edge)
    
    def get_adjacency_matrix(self) -> torch.Tensor:
        """–ú–∞—Ç—Ä–∏—Ü–∞ —Å–º–µ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è GNN"""
        n = len(self.nodes)
        adj = torch.zeros((n, n))
        
        for edge in self.edges:
            adj[edge.from_node, edge.to_node] = edge.weight
        
        return adj
    
    def get_node_features(self) -> torch.Tensor:
        """–ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —É–∑–ª–æ–≤"""
        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç—ã–µ features (–≤ production - embeddings)
        features = []
        for node in self.nodes:
            # One-hot encoding —Ç–∏–ø–∞ —É–∑–ª–∞
            feat = [0.0] * len(NodeType)
            feat[list(NodeType).index(node.type)] = 1.0
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥—Ä—É–≥–∏–µ features
            feat.append(node.line_number / 1000.0)  # Normalized
            feat.append(len(node.name) / 100.0)
            
            features.append(feat)
        
        return torch.tensor(features, dtype=torch.float32)


class GraphConvLayer(nn.Module):
    """
    Graph Convolutional Layer
    
    –°–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è (–Ω–µ –∫–æ–ø–∏—Ä—É–µ–º PyG!)
    
    Message passing:
    h_i' = œÉ(W * Œ£(h_j / sqrt(deg_i * deg_j)))
    
    –ì–¥–µ:
    - h_i - embedding —É–∑–ª–∞ i
    - h_j - embeddings —Å–æ—Å–µ–¥–µ–π
    - W - learnable weights
    - œÉ - activation
    """
    
    def __init__(self, in_features: int, out_features: int):
        super().__init__()
        
        self.in_features = in_features
        self.out_features = out_features
        
        # Learnable transformation
        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))
        self.bias = nn.Parameter(torch.Tensor(out_features))
        
        # Initialization
        nn.init.xavier_uniform_(self.weight)
        nn.init.zeros_(self.bias)
    
    def forward(
        self,
        node_features: torch.Tensor,
        adjacency: torch.Tensor
    ) -> torch.Tensor:
        """
        Graph convolution
        
        Args:
            node_features: [num_nodes, in_features]
            adjacency: [num_nodes, num_nodes]
        
        Returns:
            Updated features: [num_nodes, out_features]
        """
        # Degree normalization
        degree = adjacency.sum(dim=1, keepdim=True)
        degree = torch.clamp(degree, min=1.0)  # Avoid division by zero
        
        norm_adj = adjacency / torch.sqrt(degree * degree.T)
        
        # Aggregation
        aggregated = torch.matmul(norm_adj, node_features)
        
        # Transformation
        output = torch.matmul(aggregated, self.weight) + self.bias
        
        # Activation
        output = F.relu(output)
        
        return output


class CodeGraphNeuralNetwork(nn.Module):
    """
    –ü–æ–ª–Ω–∞—è GNN –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∞
    
    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    - Input: Code graph
    - GCN layers (message passing)
    - Global pooling
    - Output: Graph-level embedding
    
    –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - Code understanding
    - Similarity search
    - Intent classification
    - Quality prediction
    """
    
    def __init__(
        self,
        input_dim: int = 10,
        hidden_dim: int = 128,
        output_dim: int = 256,
        num_layers: int = 4
    ):
        super().__init__()
        
        # GCN layers
        self.layers = nn.ModuleList()
        
        # First layer
        self.layers.append(GraphConvLayer(input_dim, hidden_dim))
        
        # Hidden layers
        for _ in range(num_layers - 2):
            self.layers.append(GraphConvLayer(hidden_dim, hidden_dim))
        
        # Output layer
        self.layers.append(GraphConvLayer(hidden_dim, output_dim))
        
        # Dropout
        self.dropout = nn.Dropout(0.1)
        
        # Global pooling
        self.pool = nn.Linear(output_dim, output_dim)
        
        # Classification heads
        self.intent_head = nn.Linear(output_dim, 10)  # 10 intents
        self.quality_head = nn.Linear(output_dim, 1)
    
    def forward(
        self,
        node_features: torch.Tensor,
        adjacency: torch.Tensor
    ) -> Dict[str, torch.Tensor]:
        """
        Forward pass
        
        Args:
            node_features: [num_nodes, input_dim]
            adjacency: [num_nodes, num_nodes]
        
        Returns:
            {
                'node_embeddings': [num_nodes, output_dim],
                'graph_embedding': [output_dim],
                'intent_logits': [10],
                'quality_score': [1]
            }
        """
        h = node_features
        
        # GCN layers with message passing
        for i, layer in enumerate(self.layers):
            h = layer(h, adjacency)
            
            # Dropout (except last layer)
            if i < len(self.layers) - 1:
                h = self.dropout(h)
        
        # Node embeddings
        node_embeddings = h
        
        # Global pooling (graph-level)
        graph_embedding = h.mean(dim=0)
        graph_embedding = self.pool(graph_embedding)
        
        # Task-specific heads
        intent_logits = self.intent_head(graph_embedding)
        quality_score = torch.sigmoid(self.quality_head(graph_embedding))
        
        return {
            'node_embeddings': node_embeddings,
            'graph_embedding': graph_embedding,
            'intent_logits': intent_logits,
            'quality_score': quality_score
        }


class GraphBasedBSLParser:
    """
    –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è Graph-based –ø–∞—Ä—Å–∏–Ω–≥–∞
    
    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
        parser = GraphBasedBSLParser()
        result = parser.parse(code)
    """
    
    def __init__(self, model_path: str = None):
        # GNN model
        self.gnn = CodeGraphNeuralNetwork()
        
        # Load weights –µ—Å–ª–∏ –µ—Å—Ç—å
        if model_path:
            self.gnn.load_state_dict(torch.load(model_path))
        
        self.gnn.eval()
        
        # Device
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.gnn.to(self.device)
    
    def parse(self, code: str) -> Dict[str, Any]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–¥–∞ —á–µ—Ä–µ–∑ GNN
        
        Process:
        1. Code ‚Üí Graph
        2. Graph ‚Üí GNN
        3. GNN ‚Üí Understanding
        """
        # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–¥ –≤ –≥—Ä–∞—Ñ
        graph = self.code_to_graph(code)
        
        # 2. –ü–æ–ª—É—á–∞–µ–º features
        node_features = graph.get_node_features().to(self.device)
        adjacency = graph.get_adjacency_matrix().to(self.device)
        
        # 3. GNN forward
        with torch.no_grad():
            output = self.gnn(node_features, adjacency)
        
        # 4. –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        intent_idx = output['intent_logits'].argmax().item()
        intent = list(NodeType)[intent_idx] if intent_idx < len(NodeType) else "utility"
        
        quality = output['quality_score'].item()
        
        result = {
            'graph': graph,
            'node_embeddings': output['node_embeddings'].cpu().numpy(),
            'graph_embedding': output['graph_embedding'].cpu().numpy(),
            'intent': intent,
            'quality_score': quality,
            'num_nodes': len(graph.nodes),
            'num_edges': len(graph.edges)
        }
        
        return result
    
    def code_to_graph(self, code: str) -> CodeGraph:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ BSL –∫–æ–¥–∞ –≤ –≥—Ä–∞—Ñ
        
        –°–æ–∑–¥–∞–µ–º —É–∑–ª—ã –¥–ª—è:
        - –ö–∞–∂–¥–æ–π —Ñ—É–Ω–∫—Ü–∏–∏/–ø—Ä–æ—Ü–µ–¥—É—Ä—ã
        - –ö–∞–∂–¥–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        - –í–∞–∂–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
        
        –°–æ–∑–¥–∞–µ–º —Ä—ë–±—Ä–∞ –¥–ª—è:
        - –í—ã–∑–æ–≤–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π
        - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        - Control flow
        """
        graph = CodeGraph()
        
        # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ Neural Parser)
        lines = code.split('\n')
        
        current_function_id = None
        
        for line_num, line in enumerate(lines):
            line_stripped = line.strip()
            
            # Detect function
            if '–§—É–Ω–∫—Ü–∏—è' in line or '–ü—Ä–æ—Ü–µ–¥—É—Ä–∞' in line:
                import re
                match = re.search(r'(–§—É–Ω–∫—Ü–∏—è|–ü—Ä–æ—Ü–µ–¥—É—Ä–∞)\s+([\w–ê-–Ø–∞-—è]+)', line)
                if match:
                    func_name = match.group(2)
                    node_id = graph.add_node(
                        NodeType.FUNCTION,
                        func_name,
                        line_stripped,
                        line_num
                    )
                    current_function_id = node_id
            
            # Detect variable
            if '–ü–µ—Ä–µ–º' in line or '=' in line:
                match = re.search(r'([\w–ê-–Ø–∞-—è]+)\s*=', line)
                if match:
                    var_name = match.group(1)
                    var_id = graph.add_node(
                        NodeType.VARIABLE,
                        var_name,
                        line_stripped,
                        line_num
                    )
                    
                    # Edge: function defines variable
                    if current_function_id is not None:
                        graph.add_edge(
                            current_function_id,
                            var_id,
                            EdgeType.DEFINES
                        )
            
            # Detect API call
            if any(api in line for api in ['–ó–∞–ø—Ä–æ—Å', '–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏', '–î–æ–∫—É–º–µ–Ω—Ç—ã']):
                api_id = graph.add_node(
                    NodeType.API_CALL,
                    "API_Call",
                    line_stripped,
                    line_num
                )
                
                # Edge: function uses API
                if current_function_id is not None:
                    graph.add_edge(
                        current_function_id,
                        api_id,
                        EdgeType.USES
                    )
        
        return graph
    
    def visualize_graph(self, graph: CodeGraph, output_path: str = "code_graph.png"):
        """
        –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞ –∫–æ–¥–∞
        
        –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ (—Ç—Ä–µ–±—É–µ—Ç networkx + matplotlib)
        """
        try:
            import networkx as nx
            import matplotlib.pyplot as plt
            
            G = nx.DiGraph()
            
            # Add nodes
            for node in graph.nodes:
                G.add_node(
                    node.id,
                    label=f"{node.name}\n({node.type.value})",
                    type=node.type.value
                )
            
            # Add edges
            for edge in graph.edges:
                G.add_edge(
                    edge.from_node,
                    edge.to_node,
                    type=edge.type.value
                )
            
            # Draw
            pos = nx.spring_layout(G)
            
            # Color nodes by type
            node_colors = {
                'function': 'lightgreen',
                'procedure': 'lightblue',
                'variable': 'yellow',
                'api_call': 'red'
            }
            
            colors = [
                node_colors.get(G.nodes[n]['type'], 'gray')
                for n in G.nodes()
            ]
            
            plt.figure(figsize=(12, 8))
            nx.draw(
                G, pos,
                node_color=colors,
                with_labels=True,
                labels={n: G.nodes[n]['label'] for n in G.nodes()},
                node_size=1000,
                font_size=8,
                arrows=True
            )
            
            plt.title("Code Graph Visualization")
            plt.savefig(output_path, dpi=150, bbox_inches='tight')
            print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
            
        except ImportError:
            print("[WARN] networkx/matplotlib not installed, skipping visualization")


# Example usage
if __name__ == "__main__":
    print("=" * 70)
    print("GRAPH NEURAL NETWORK PARSER - Revolutionary")
    print("=" * 70)
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –∫–æ–¥
    test_code = """
    –§—É–Ω–∫—Ü–∏—è –ü–æ–ª—É—á–∏—Ç—å–ö–ª–∏–µ–Ω—Ç–æ–≤() –≠–∫—Å–ø–æ—Ä—Ç
        
        –ó–∞–ø—Ä–æ—Å = –ù–æ–≤—ã–π –ó–∞–ø—Ä–æ—Å;
        –ó–∞–ø—Ä–æ—Å.–¢–µ–∫—Å—Ç = "–í–´–ë–†–ê–¢–¨ * –ò–ó –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫.–ö–ª–∏–µ–Ω—Ç—ã";
        
        –†–µ–∑—É–ª—å—Ç–∞—Ç = –ó–∞–ø—Ä–æ—Å.–í—ã–ø–æ–ª–Ω–∏—Ç—å();
        –í–æ–∑–≤—Ä–∞—Ç –†–µ–∑—É–ª—å—Ç–∞—Ç;
        
    –ö–æ–Ω–µ—Ü–§—É–Ω–∫—Ü–∏–∏
    
    –§—É–Ω–∫—Ü–∏—è –û–±—Ä–∞–±–æ—Ç–∞—Ç—å–ö–ª–∏–µ–Ω—Ç–∞(–ö–ª–∏–µ–Ω—Ç)
        
        –î–∞–Ω–Ω—ã–µ = –ü–æ–ª—É—á–∏—Ç—å–ö–ª–∏–µ–Ω—Ç–æ–≤();
        
        –î–ª—è –ö–∞–∂–¥–æ–≥–æ –≠–ª–µ–º–µ–Ω—Ç –ò–∑ –î–∞–Ω–Ω—ã–µ –¶–∏–∫–ª
            –ï—Å–ª–∏ –≠–ª–µ–º–µ–Ω—Ç.–ö–æ–¥ = –ö–ª–∏–µ–Ω—Ç –¢–æ–≥–¥–∞
                –í–æ–∑–≤—Ä–∞—Ç –≠–ª–µ–º–µ–Ω—Ç;
            –ö–æ–Ω–µ—Ü–ï—Å–ª–∏;
        –ö–æ–Ω–µ—Ü–¶–∏–∫–ª–∞;
        
    –ö–æ–Ω–µ—Ü–§—É–Ω–∫—Ü–∏–∏
    """
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    parser = GraphBasedBSLParser()
    
    # –ü–∞—Ä—Å–∏–º –≤ –≥—Ä–∞—Ñ
    result = parser.parse(test_code)
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"–£–∑–ª–æ–≤ –≤ –≥—Ä–∞—Ñ–µ: {result['num_nodes']}")
    print(f"–†—ë–±–µ—Ä –≤ –≥—Ä–∞—Ñ–µ: {result['num_edges']}")
    print(f"Intent: {result['intent']}")
    print(f"Quality: {result['quality_score']:.2f}")
    
    print(f"\nüå≥ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≥—Ä–∞—Ñ–∞:")
    graph = result['graph']
    for node in graph.nodes:
        print(f"  [{node.type.value}] {node.name} (line {node.line_number})")
    
    print(f"\nüîó –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:")
    for edge in graph.edges:
        from_node = graph.nodes[edge.from_node]
        to_node = graph.nodes[edge.to_node]
        print(f"  {from_node.name} --[{edge.type.value}]--> {to_node.name}")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    print(f"\nüìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞...")
    parser.visualize_graph(graph, "code_graph.png")
    
    print("\n" + "=" * 70)
    print("‚ú® Graph-based –ø–∞—Ä—Å–∏–Ω–≥ complete!")
    print("=" * 70)




