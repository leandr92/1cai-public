# Vectorize Content Edge Function

Функция для векторизации контента через OpenAI API с разбиением на чанки и обновлением базы данных.

## Возможности

- ✅ Разбиение контента на чанки (по умолчанию 1000 токенов)
- ✅ Генерация embeddings через OpenAI API
- ✅ Обновление записей в `its_1c_knowledge_base` с векторами
- ✅ Батчевая обработка больших объемов данных
- ✅ Полная валидация входных данных
- ✅ CORS заголовки
- ✅ Обработка ошибок API
- ✅ Поддержка русского языка

## Требования к окружению

Необходимо настроить переменные окружения:

```bash
OPENAI_API_KEY=your_openai_api_key_here
SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key
```

## API Endpoint

```
POST https://cdisushwdolpuvripuov.supabase.co/functions/v1/vectorize-content
```

## Параметры запроса

| Параметр | Тип | Обязательный | Описание | По умолчанию |
|----------|-----|-------------|----------|-------------|
| `content_ids` | array | Нет* | Массив ID записей для векторизации | - |
| `content_text` | string | Нет* | Прямой текст для векторизации | - |
| `chunk_size` | number | Нет | Размер чанка в токенах (100-4000) | 1000 |
| `batch_size` | number | Нет | Размер батча для обработки (1-50) | 10 |
| `model` | string | Нет | Модель OpenAI для embeddings | text-embedding-3-small |

*Необходимо указать либо `content_ids`, либо `content_text`

## Примеры использования

### 1. Векторизация конкретных записей по ID

```json
{
  "content_ids": ["id1", "id2", "id3"],
  "chunk_size": 1000,
  "batch_size": 5
}
```

### 2. Векторизация прямого текста

```json
{
  "content_text": "1С:Предприятие 8.3 - это современная платформа для автоматизации...",
  "chunk_size": 800,
  "batch_size": 3
}
```

### 3. Полная векторизация с кастомными параметрами

```json
{
  "content_ids": ["record1", "record2", "record3"],
  "chunk_size": 1500,
  "batch_size": 15,
  "model": "text-embedding-3-large"
}
```

## Ответ функции

### Успешный ответ (200)

```json
{
  "success": true,
  "data": {
    "total_items": 5,
    "processed": 5,
    "errors": 0,
    "error_details": [],
    "chunk_size": 1000,
    "batch_size": 10,
    "model": "text-embedding-3-small"
  },
  "message": "Векторизация завершена. Обработано: 5, Ошибок: 0"
}
```

### Ошибка валидации (500)

```json
{
  "error": {
    "code": "VECTORIZATION_FAILED",
    "message": "Размер чанка должен быть от 100 до 4000 токенов"
  }
}
```

## Структура сохранения векторов

Векторы сохраняются в поле `vectors` таблицы `its_1c_knowledge_base`:

```json
{
  "total_chunks": 3,
  "model": "text-embedding-3-small",
  "updated_at": "2025-11-02T11:32:46.000Z",
  "chunks": [
    {
      "index": 0,
      "content": "Первый чанк контента...",
      "vector": [0.1, 0.2, 0.3, ...],
      "size": 150
    },
    {
      "index": 1,
      "content": "Второй чанк контента...",
      "vector": [0.4, 0.5, 0.6, ...],
      "size": 200
    }
  ]
}
```

Также обновляются поля:
- `vectorization_status`: "completed"
- `updated_at`: текущее время

## Особенности обработки

1. **Разбиение на чанки**: Текст разбивается по предложениям и абзацам для сохранения семантической целостности
2. **Батчевая обработка**: Записи обрабатываются группами для оптимизации производительности
3. **Rate Limiting**: Добавлены задержки между батчами для избежания превышения лимитов API
4. **Обработка ошибок**: Продолжается обработка остальных чанков при ошибке отдельного чанка
5. **Логирование**: Подробные логи для отладки и мониторинга

## Лимиты и ограничения

- Максимальный размер чанка: 4000 токенов
- Минимальный размер чанка: 100 токенов
- Максимальный размер батча: 50 записей
- Минимальный размер батча: 1 запись
- Поддерживаемые модели OpenAI: text-embedding-3-small, text-embedding-3-large

## Развертывание

Функция автоматически развернута и готова к использованию по адресу:
`https://cdisushwdolpuvripuov.supabase.co/functions/v1/vectorize-content`