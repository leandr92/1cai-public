from __future__ import annotations

import argparse
import json
from dataclasses import dataclass, asdict
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional
from uuid import uuid4

import httpx
import yaml
from rich.console import Console
from rich.table import Table

from security.agent_framework.runtime import (
    SecurityAgent,
    generate_html_report,
    generate_markdown_report,
)
from security.agent_framework.presets import (
    copy_preset_to,
    get_preset_path,
    list_presets,
)
from security.agent_framework.publishers import (
    ConfluencePublishError,
    S3PublishError,
    publish_to_confluence,
    send_ticket_webhook,
    upload_to_s3,
)


DEFAULT_MANAGER_URL = "http://localhost:9100"
DEFAULT_PROFILE = "web-api"
console = Console()


@dataclass
class RunSpec:
    targets: List[str]
    instruction: Optional[str] = None
    profile: Optional[str] = None


def load_config_data(path: str) -> Dict[str, Any]:
    config_path = Path(path)
    if not config_path.exists():
        raise FileNotFoundError(f"Config file not found: {path}")

    text = config_path.read_text(encoding="utf-8")
    if config_path.suffix.lower() in {".json"}:
        data = json.loads(text)
    else:
        data = yaml.safe_load(text)

    if not isinstance(data, dict):
        raise ValueError("Config file must contain a mapping at the top level.")
    return data


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        prog="security-cli",
        description="Internal security testing CLI.",
    )
    parser.add_argument("--config", help="Path to YAML/JSON config file.")
    parser.add_argument(
        "--format",
        choices=("human", "json"),
        default="human",
        help="Output format for local execution results.",
    )

    subparsers = parser.add_subparsers(dest="command", required=True)

    run_parser = subparsers.add_parser("run", help="Execute security scan.")
    run_parser.add_argument("-t", "--target", action="append", dest="targets")
    run_parser.add_argument("-i", "--instruction", help="Custom instructions for the scan.")
    run_parser.add_argument("-p", "--profile", help="Profile (web-api, repo-static, ...).")
    run_parser.add_argument(
        "--manager-url",
        default=DEFAULT_MANAGER_URL,
        help=f"Sandbox manager base URL (default: {DEFAULT_MANAGER_URL}).",
    )
    run_parser.add_argument("--run-id", help="Custom run identifier (UUID generated by default).")
    run_parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Print payload without submitting to sandbox manager.",
    )
    run_parser.add_argument(
        "--local",
        action="store_true",
        help="Execute locally without contacting sandbox manager.",
    )
    run_parser.add_argument(
        "--submit",
        action="store_true",
        help="ĞŸĞ¾ÑĞ»Ğµ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ÑĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ¿ĞµÑĞ¾Ñ‡Ğ½Ğ¸Ñ†.",
    )
    run_parser.add_argument(
        "--output",
        help="Path to save JSON results (local mode only).",
    )
    run_parser.add_argument(
        "--markdown",
        help="Path to save Markdown summary (local mode only).",
    )
    run_parser.add_argument(
        "--html",
        help="Path to save HTML report (local mode only).",
    )
    run_parser.add_argument(
        "--knowledge-base",
        help="Append JSON payload to specified JSONL file (knowledge base sync).",
    )
    run_parser.add_argument(
        "--publish-dir",
        help="Copy generated HTML/Markdown reports into directory (e.g. portal).",
    )
    run_parser.add_argument(
        "--publish-url-base",
        help="Base URL corresponding to publish-dir (Slack notifications will use it).",
    )
    run_parser.add_argument(
        "--slack-webhook",
        help="Slack webhook URL for notifications.",
    )
    run_parser.add_argument(
        "--tickets-dir",
        help="Directory to write ticket JSONs for high/critical findings.",
    )
    run_parser.add_argument("--ticket-webhook", help="Webhook URL to create tickets automatically.")
    run_parser.add_argument(
        "--ticket-prefix",
        help="Optional prefix for generated ticket titles.",
    )
    run_parser.add_argument(
        "--neo4j-url",
        help="Neo4j HTTP endpoint, e.g. http://localhost:7474.",
    )
    run_parser.add_argument("--neo4j-user", help="Neo4j username.")
    run_parser.add_argument("--neo4j-password", help="Neo4j password.")
    run_parser.add_argument(
        "--neo4j-database",
        default="neo4j",
        help="Neo4j database name (default: neo4j).",
    )
    run_parser.add_argument("--s3-bucket", help="S3 bucket to upload reports.")
    run_parser.add_argument("--s3-prefix", help="S3 key prefix.")
    run_parser.add_argument("--s3-region", help="S3 region.")
    run_parser.add_argument("--s3-endpoint", help="S3 custom endpoint (MinIO, etc).")
    run_parser.add_argument("--s3-access-key", help="S3 access key.")
    run_parser.add_argument("--s3-secret-key", help="S3 secret key.")
    run_parser.add_argument("--confluence-url", help="Confluence base URL.")
    run_parser.add_argument("--confluence-user", help="Confluence user/email.")
    run_parser.add_argument("--confluence-token", help="Confluence API token.")
    run_parser.add_argument("--confluence-space", help="Confluence space key.")
    run_parser.add_argument("--confluence-parent", help="Confluence parent page ID.")

    preset_parser = subparsers.add_parser("preset", help="Work with built-in presets.")
    preset_parser.add_argument("name", nargs="?", help="Preset name to copy/show.")
    preset_parser.add_argument(
        "--output",
        help="Destination path. Defaults to current directory if not provided.",
    )
    preset_parser.add_argument("--list", action="store_true", help="List available presets.")
    preset_parser.add_argument(
        "--show", action="store_true", help="Print preset content to stdout instead of copying."
    )

    subparsers.add_parser("list-modules", help="List available modules.")
    report_parser = subparsers.add_parser("report", help="Show last run summary (stub).")
    report_parser.add_argument("--run-id", help="ID of run to show (defaults to last).")

    preliminary_args, _ = parser.parse_known_args()
    config_data: Dict[str, Any] = {}
    if getattr(preliminary_args, "config", None):
        config_data = load_config_data(preliminary_args.config)

    args = parser.parse_args()

    if config_data and args.command == "run":
        sentinel = object()
        defaults = {
            action.dest: action.default
            for action in parser._actions
            if action.dest not in (None, argparse.SUPPRESS)
        }
        for key, value in config_data.items():
            if not hasattr(args, key):
                continue
            if key == "targets":
                current = getattr(args, "targets", None)
                if not current:
                    if isinstance(value, (list, tuple)):
                        setattr(args, "targets", list(value))
                    else:
                        setattr(args, "targets", [value])
                continue

            default_value = defaults.get(key, sentinel)
            current_value = getattr(args, key)
            if default_value is sentinel or current_value == default_value:
                if key in {"local", "submit", "dry_run"}:
                    setattr(args, key, bool(value))
                else:
                    setattr(args, key, value)

    if args.command == "run":
        if not getattr(args, "targets", None):
            raise SystemExit("ĞĞµ Ğ·Ğ°Ğ´Ğ°Ğ½Ñ‹ Ñ†ĞµĞ»Ğ¸ (--target Ğ¸Ğ»Ğ¸ targets Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğµ).")
        if isinstance(args.targets, str):
            args.targets = [args.targets]
        else:
            args.targets = list(args.targets)

    return args


def handle_run(args: argparse.Namespace) -> int:
    profile = args.profile or DEFAULT_PROFILE
    spec = RunSpec(targets=args.targets, instruction=args.instruction, profile=profile)
    run_id = args.run_id or uuid4().hex

    if args.local:
        return handle_local_run(args, spec, run_id)

    payload = asdict(spec)

    print("âš™ï¸  Preparing run submission:")
    print(json.dumps({"run_id": run_id, **payload}, indent=2, ensure_ascii=False))

    if args.dry_run:
        print("ğŸ§ª Dry-run mode: payload not sent.")
        return 0

    try:
        response = httpx.post(
            f"{args.manager_url.rstrip('/')}/runs/{run_id}",
            json=payload,
            timeout=10.0,
        )
        response.raise_for_status()
    except httpx.HTTPError as exc:
        print(f"âŒ Failed to submit run to sandbox manager: {exc}")
        return 1

    print("âœ… Run accepted by sandbox manager:")
    print(json.dumps(response.json(), indent=2, ensure_ascii=False))
    return 0


def handle_list_modules() -> int:
    from security.agent_framework.runtime.modules import PROFILE_MODULES

    print("ğŸ“¦ Available profiles and modules:")
    for profile, modules in PROFILE_MODULES.items():
        titles = ", ".join(module.name for module in modules)
        print(f"- {profile}: {titles}")
    return 0


def handle_report(args: argparse.Namespace) -> int:
    run_id = args.run_id or "<last-run>"
    print(f"ğŸ“ Reports subsystem not yet implemented. Requested run: {run_id}")
    return 0


def handle_preset(args: argparse.Namespace) -> int:
    if args.list or not args.name:
        print("ğŸ“¦ Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¿Ñ€ĞµÑĞµÑ‚Ñ‹:")
        for preset_name in list_presets():
            print(f"- {preset_name}")
        if not args.name:
            return 0 if args.list else 1
        print()

    try:
        preset_path = get_preset_path(args.name)
    except KeyError:
        print(f"âŒ ĞŸÑ€ĞµÑĞµÑ‚ '{args.name}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½.")
        return 1

    if args.show:
        print(preset_path.read_text(encoding="utf-8"))
        return 0

    destination = Path(args.output) if args.output else Path.cwd() / preset_path.name
    destination_path = copy_preset_to(args.name, destination)
    print(f"âœ… ĞŸÑ€ĞµÑĞµÑ‚ '{args.name}' ÑĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ² {destination_path}")
    return 0


def render_human(results: List[dict]) -> None:
    for entry in results:
        console.rule(f"[bold cyan]{entry['target']}[/bold cyan] ({entry['profile']})")
        table = Table(title="Findings", show_lines=True)
        table.add_column("Severity")
        table.add_column("Title")
        table.add_column("Description", overflow="fold")
        table.add_column("Evidence", overflow="fold")

        if entry["findings"]:
            for finding in entry["findings"]:
                table.add_row(
                    finding["severity"],
                    finding["title"],
                    finding["description"],
                    finding.get("evidence") or "",
                )
        else:
            table.add_row("-", "ĞĞµÑ‚ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼", "", "")

        console.print(table)
        if entry["notes"]:
            console.print("\n[bold]Notes:[/bold]")
            for note in entry["notes"]:
                console.print(f"- {note}")
        console.print()


def severity_score(severity: str) -> int:
    order = {"critical": 4, "high": 3, "medium": 2, "low": 1}
    return order.get(severity.lower(), 0)


def compute_severity_counts(results: List[dict]) -> Dict[str, int]:
    counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
    for entry in results:
        for finding in entry.get("findings", []):
            sev = (finding.get("severity") or "").lower()
            if sev in counts:
                counts[sev] += 1
    return counts


def handle_local_run(args: argparse.Namespace, spec: RunSpec, run_id: str) -> int:
    profile = spec.profile or DEFAULT_PROFILE
    agent = SecurityAgent(profile=profile)
    targets = spec.targets or args.targets or []
    aggregated: List[dict] = []
    max_severity = 0
    generated_at = datetime.now(timezone.utc).isoformat()

    markdown_content: Optional[str] = None
    html_content: Optional[str] = None
    confluence_link: Optional[str] = None

    if args.dry_run:
        print("ğŸ§ª Dry-run mode (local). Execution skipped.")
        print(json.dumps({"run_id": run_id, **asdict(spec)}, indent=2, ensure_ascii=False))
        return 0

    if args.submit:
        try:
            register_payload = {
                "targets": targets,
                "instruction": spec.instruction,
                "profile": profile,
            }
            response = httpx.post(
                f"{args.manager_url.rstrip('/')}/runs/{run_id}",
                json=register_payload,
                timeout=10.0,
            )
            response.raise_for_status()
            print("ğŸ“¨ Run registered in sandbox manager.")
        except httpx.HTTPError as exc:
            print(f"âŒ Failed to register run in sandbox manager: {exc}")
            return 1

    for target in targets:
        result = agent.run(target)
        findings = [
            {
                "title": finding.title,
                "severity": finding.severity,
                "description": finding.description,
                "evidence": finding.evidence,
            }
            for finding in result.findings
        ]
        aggregated.append(
            {
                "target": target,
                "profile": profile,
                "findings": findings,
                "notes": result.notes,
            }
        )
        for finding in result.findings:
            max_severity = max(max_severity, severity_score(finding.severity))

    payload = {
        "run_id": run_id,
        "generated_at": generated_at,
        "profile": profile,
        "results": aggregated,
    }
    severity_counts = compute_severity_counts(aggregated)

    if args.output:
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with output_path.open("w", encoding="utf-8") as fh:
            json.dump(payload, fh, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ² {output_path}")
    if args.markdown:
        markdown_path = Path(args.markdown)
        markdown_path.parent.mkdir(parents=True, exist_ok=True)
        markdown_content = generate_markdown_report(payload)
        markdown_path.write_text(markdown_content, encoding="utf-8")
        print(f"ğŸ—’ï¸  Markdown-Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½ Ğ² {markdown_path}")
    if args.html:
        html_path = Path(args.html)
        html_path.parent.mkdir(parents=True, exist_ok=True)
        html_content = generate_html_report(payload)
        html_path.write_text(html_content, encoding="utf-8")
        print(f"ğŸ“° HTML-Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½ Ğ² {html_path}")

    if args.knowledge_base:
        from security.agent_framework.integrations import append_to_jsonl

        kb_path = append_to_jsonl(args.knowledge_base, payload)
        print(f"ğŸ“š Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ² knowledge base: {kb_path}")

    if args.publish_dir:
        publish_dir = Path(args.publish_dir)
        publish_dir.mkdir(parents=True, exist_ok=True)
        if markdown_content is None:
            markdown_content = generate_markdown_report(payload)
        if html_content is None:
            html_content = generate_html_report(payload)
        md_publish_path = publish_dir / f"{run_id}.md"
        html_publish_path = publish_dir / f"{run_id}.html"
        md_publish_path.write_text(markdown_content, encoding="utf-8")
        html_publish_path.write_text(html_content, encoding="utf-8")
        update_portal_index(
            publish_dir,
            run_id,
            payload,
            severity_counts,
            md_publish_path,
            html_publish_path,
        )
        print(f"ğŸš€ ĞÑ‚Ñ‡Ñ‘Ñ‚Ñ‹ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ñ‹ Ğ² {publish_dir}")
    else:
        md_publish_path = Path(args.markdown) if args.markdown else None
        html_publish_path = Path(args.html) if args.html else None

    if args.s3_bucket and html_publish_path and md_publish_path:
        try:
            upload_to_s3(
                args.s3_bucket,
                html_path=html_publish_path,
                md_path=md_publish_path,
                prefix=args.s3_prefix,
                region=args.s3_region,
                endpoint=args.s3_endpoint,
                access_key=args.s3_access_key,
                secret_key=args.s3_secret_key,
            )
            print("â˜ï¸  ĞÑ‚Ñ‡Ñ‘Ñ‚Ñ‹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ² S3/MinIO.")
        except S3PublishError as exc:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ² S3: {exc}")
            return 1

    if args.confluence_url and html_content:
        missing = [
            name
            for name in ("confluence_user", "confluence_token", "confluence_space")
            if not getattr(args, name)
        ]
        if missing:
            print(f"âš ï¸  Confluence Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ñ‹: {', '.join(missing)}. ĞŸÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ°.")
        else:
            try:
                confluence_link = publish_to_confluence(
                    url=args.confluence_url,
                    user=args.confluence_user,
                    token=args.confluence_token,
                    space=args.confluence_space,
                    parent_id=args.confluence_parent,
                    title=f"Security Report {run_id}",
                    html_content=html_content,
                )
                print(f"ğŸ“„ ĞÑ‚Ñ‡Ñ‘Ñ‚ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½ Ğ² Confluence: {confluence_link}")
            except ConfluencePublishError as exc:
                print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ² Confluence: {exc}")
                return 1

    if args.slack_webhook:
        try:
            summary = build_slack_summary(
                payload,
                max_severity,
                severity_counts=severity_counts,
                html_publish_url=build_publish_url(args.publish_url_base, html_publish_path),
                confluence_url=confluence_link,
            )
            response = httpx.post(
                args.slack_webhook,
                json={"text": summary},
                timeout=10.0,
            )
            response.raise_for_status()
            print("ğŸ’¬ Slack ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾.")
        except httpx.HTTPError as exc:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Slack ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ñ: {exc}")
            return 1

    if args.neo4j_url:
        if not (args.neo4j_user and args.neo4j_password):
            print("âš ï¸  ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ñ‹ ÑƒÑ‡ĞµÑ‚Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Neo4j; ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ°.")
        else:
            from security.agent_framework.integrations import push_results_to_neo4j
            from security.agent_framework.integrations.neo4j import Neo4jSyncError

            try:
                push_results_to_neo4j(
                    payload,
                    url=args.neo4j_url,
                    user=args.neo4j_user,
                    password=args.neo4j_password,
                    database=args.neo4j_database,
                )
                print("ğŸ—ƒï¸  Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ğ² Neo4j.")
            except Neo4jSyncError as exc:
                print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ Neo4j: {exc}")
                return 1

    if args.tickets_dir:
        tickets_dir = Path(args.tickets_dir)
        tickets_dir.mkdir(parents=True, exist_ok=True)
        tickets_path = tickets_dir / f"{run_id}.json"
        tickets = build_ticket_payload(payload, severity_counts, args.ticket_prefix)
        if tickets:
            tickets_path.write_text(json.dumps(tickets, indent=2, ensure_ascii=False), encoding="utf-8")
            print(f"ğŸ« Ğ¡Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ñ‚Ğ¸ĞºĞµÑ‚Ñ‹: {tickets_path}")

            if args.ticket_webhook:
                try:
                    send_ticket_webhook(webhook_url=args.ticket_webhook, tickets=tickets)
                    print("ğŸ“¨ Ğ¢Ğ¸ĞºĞµÑ‚Ñ‹ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ñ‡ĞµÑ€ĞµĞ· webhook.")
                except Exception as exc:  # pragma: no cover - network failure
                    print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Ñ‚Ğ¸ĞºĞµÑ‚Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· webhook: {exc}")
                    return 1

    if args.format == "json":
        print(json.dumps(payload, indent=2, ensure_ascii=False))
    else:
        render_human(aggregated)

    if args.submit:
        try:
            response = httpx.post(
                f"{args.manager_url.rstrip('/')}/runs/{run_id}/complete",
                json=payload,
                timeout=10.0,
            )
            response.raise_for_status()
            print("ğŸ“¤ Results submitted to sandbox manager.")
        except httpx.HTTPError as exc:
            print(f"âŒ Failed to submit results to sandbox manager: {exc}")
            return 1

    if max_severity >= severity_score("critical"):
        return 3
    if max_severity >= severity_score("high"):
        return 2
    if max_severity >= severity_score("medium"):
        return 1
    return 0


def update_portal_index(
    publish_dir: Path,
    run_id: str,
    payload: Dict[str, Any],
    severity_counts: Dict[str, int],
    md_path: Path,
    html_path: Path,
) -> None:
    index_json = publish_dir / "index.json"
    if index_json.exists():
        index_data = json.loads(index_json.read_text(encoding="utf-8"))
    else:
        index_data = {"runs": []}

    index_data.setdefault("runs", [])
    index_data["runs"].append(
        {
            "run_id": run_id,
            "generated_at": payload.get("generated_at"),
            "profile": payload.get("profile"),
            "severity": severity_counts,
            "html": html_path.name,
            "markdown": md_path.name,
        }
    )

    index_json.write_text(json.dumps(index_data, indent=2, ensure_ascii=False), encoding="utf-8")
    (publish_dir / "index.html").write_text(
        generate_portal_index_html(index_data["runs"]),
        encoding="utf-8",
    )
    (publish_dir / "neo4j_dashboard.cypher").write_text(
        generate_neo4j_dashboard_script(),
        encoding="utf-8",
    )


def generate_portal_index_html(runs: List[Dict[str, Any]]) -> str:
    rows = []
    severity_order = ["critical", "high", "medium", "low"]
    for run in reversed(runs):
        counts = run.get("severity", {})
        counts_str = " | ".join(f"{name}:{counts.get(name, 0)}" for name in severity_order)
        rows.append(
            f"<tr>"
            f"<td>{run.get('generated_at')}</td>"
            f"<td>{run.get('profile')}</td>"
            f"<td>{counts_str}</td>"
            f"<td><a href=\"{run.get('html')}\">HTML</a> | <a href=\"{run.get('markdown')}\">MD</a></td>"
            f"</tr>"
        )

    table_body = "\n".join(rows) or "<tr><td colspan='4'>No runs yet</td></tr>"
    return f"""<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Security Reports</title>
  <style>
    body {{
      font-family: Arial, sans-serif;
      padding: 1.5rem;
      background: #f4f6f8;
    }}
    h1 {{
      color: #1f2933;
    }}
    table {{
      width: 100%;
      border-collapse: collapse;
      background: #fff;
      box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }}
    th, td {{
      padding: 0.6rem 0.8rem;
      border-bottom: 1px solid #e5e7eb;
      text-align: left;
    }}
    th {{
      background: #111827;
      color: #f9fafb;
    }}
  </style>
</head>
<body>
  <h1>Security Reports</h1>
  <table>
    <thead>
      <tr>
        <th>Date</th>
        <th>Profile</th>
        <th>Severity</th>
        <th>Reports</th>
      </tr>
    </thead>
    <tbody>
      {table_body}
    </tbody>
  </table>
</body>
</html>"""


def generate_neo4j_dashboard_script() -> str:
    return """// Load data aggregated by the security agent
MATCH (run:SecurityRun)-[:HAS_FINDING]->(finding:SecurityFinding)-[:FOR_TARGET]->(target:SecurityTarget)
RETURN run.run_id AS runId,
       run.profile AS profile,
       finding.severity AS severity,
       target.name AS target
ORDER BY runId DESC, severity DESC;

// Example: count findings per target
MATCH (run:SecurityRun)-[:HAS_FINDING]->(finding:SecurityFinding)-[:FOR_TARGET]->(target:SecurityTarget)
RETURN target.name AS target, finding.severity AS severity, COUNT(*) AS total
ORDER BY total DESC;
"""


def build_ticket_payload(
    payload: Dict[str, Any],
    severity_counts: Dict[str, int],
    ticket_prefix: Optional[str],
) -> List[Dict[str, Any]]:
    prefix = f"{ticket_prefix.strip()} " if ticket_prefix else ""
    tickets = []
    for entry in payload.get("results", []):
        target = entry.get("target")
        for finding in entry.get("findings", []):
            severity = (finding.get("severity") or "").lower()
            if severity not in {"critical", "high"}:
                continue
            tickets.append(
                {
                    "title": f"{prefix}{finding.get('title')}",
                    "severity": severity,
                    "target": target,
                    "description": finding.get("description"),
                    "evidence": finding.get("evidence"),
                    "run_id": payload.get("run_id"),
                }
            )
    return tickets


def build_publish_url(base: Optional[str], path: Optional[Path]) -> Optional[str]:
    if not base or not path:
        return None
    return f"{base.rstrip('/')}/{path.name}"


def build_slack_summary(
    payload: Dict[str, Any],
    max_severity: int,
    *,
    severity_counts: Dict[str, int],
    html_publish_url: Optional[str] = None,
    confluence_url: Optional[str] = None,
) -> str:
    severity_order = ["low", "medium", "high", "critical"]
    severity_emojis = {
        "critical": "ğŸ›‘",
        "high": "ğŸš¨",
        "medium": "âš ï¸",
        "low": "â„¹ï¸",
    }

    lines = [
        f"*Security Scan*: `{payload.get('profile', 'n/a')}`",
        f"*Run ID*: `{payload.get('run_id', 'n/a')}`",
        f"*Max severity*: {['ğŸŸ¢','ğŸŸ¡','ğŸŸ ','ğŸ”´'][max_severity] if max_severity < 4 else 'ğŸ”´'}",
        " | ".join(
            f"{severity_emojis[name]} {name.title()}: {severity_counts.get(name, 0)}"
            for name in severity_order
        ),
    ]

    top_findings = []
    for entry in payload.get("results", []):
        for finding in entry.get("findings", []):
            top_findings.append(
                f"{severity_emojis.get(finding.get('severity', '').lower(), 'â€¢')} "
                f"{finding.get('title')} ({entry.get('target')})"
            )
    if top_findings:
        lines.append("*Findings:*")
        lines.extend(f"â€¢ {line}" for line in top_findings[:5])

    links = []
    if html_publish_url:
        links.append(f"<{html_publish_url}|HTML>")
    if confluence_url:
        links.append(f"<{confluence_url}|Confluence>")
    if links:
        lines.append("Ğ¡ÑÑ‹Ğ»ĞºĞ¸: " + ", ".join(links))

    return "\n".join(lines)


def main() -> int:
    args = parse_args()
    if args.command == "run":
        return handle_run(args)
    if args.command == "preset":
        return handle_preset(args)
    if args.command == "list-modules":
        return handle_list_modules()
    if args.command == "report":
        return handle_report(args)

    print("Unknown command")
    return 1


if __name__ == "__main__":
    raise SystemExit(main())

